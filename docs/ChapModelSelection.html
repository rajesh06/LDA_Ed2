<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Model Selection and Estimation | Loss Data Analytics</title>
  <meta name="description" content="Chapter 5 Model Selection and Estimation | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Model Selection and Estimation | Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 5 Model Selection and Estimation | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="github-repo" content="https://github.com/openacttexts/Loss-Data-Analytics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Model Selection and Estimation | Loss Data Analytics" />
  
  <meta name="twitter:description" content="Chapter 5 Model Selection and Estimation | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ChapSeverity.html"/>
<link rel="next" href="ChapAggLossModels.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<script>
function markdownConverterEWF() {  
//Create showdown markdown converter
var converter = new showdown.Converter();
converter.setOption('ghCompatibleHeaderId', true);
survey
    .onTextMarkdown
    .add(function (survey, options) {
        //convert the markdown text to html
        var str = converter.makeHtml(options.text);
        //remove root paragraphs <p></p>
        str = str.substring(3);
        str = str.substring(0, str.length - 4);
        //set html
        options.html = str;
        MathJax.Hub.Queue(['Typeset',MathJax.Hub, 'options']);
    });  
};

// Quiz Header info
const jsonHeader = { 
    showProgressBar: "bottom",
    showTimerPanel: "none",
    maxTimeToFinishPage: 10000,
    maxTimeToFinish: 25000,
    firstPageIsStarted: true,
    startSurveyText: "Start Quiz" //,
//    title: "Does This Make Sense?"
}


// One and Two question quizzes
function jsonSummary1EWF(json) {  
let jsonEnd1 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
};  
return jsonEnd1;
};


function jsonSummary2EWF(json) {  
let jsonEnd2 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
};  
return jsonEnd2;
};

// Three, four, and five question quizzes
function jsonSummary3EWF(json) {  
let jsonEnd3 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][3]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][3]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][3]["questions"][0]["correctAnswer"]
};  
return jsonEnd3;
};

function jsonSummary4EWF(json) {  
jsonEnd4 = jsonSummary3EWF(json);
jsonEnd4.completedHtml = jsonEnd4.completedHtml +  
"<br>"+
json["pages"][4]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][4]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][4]["questions"][0]["correctAnswer"]
;  
return jsonEnd4;
};

function jsonSummary5EWF(json) {  
jsonEnd5 = jsonSummary4EWF(json);
jsonEnd5.completedHtml = jsonEnd5.completedHtml +  
"<br>"+
json["pages"][5]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][5]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][5]["questions"][0]["correctAnswer"]
;  
return jsonEnd5;
};

function jsonSummary6EWF(json) {  
jsonEnd6 = jsonSummary5EWF(json);
jsonEnd6.completedHtml = jsonEnd6.completedHtml +  
"<br>"+
json["pages"][6]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][6]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][6]["questions"][0]["correctAnswer"]
;  
return jsonEnd6;
};

function jsonSummary7EWF(json) {  
jsonEnd7 = jsonSummary6EWF(json);
jsonEnd7.completedHtml = jsonEnd7.completedHtml +  
"<br>"+
json["pages"][7]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][7]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][7]["questions"][0]["correctAnswer"]
;  
return jsonEnd7;
};

function jsonSummary8EWF(json) {  
jsonEnd8 = jsonSummary7EWF(json);
jsonEnd8.completedHtml = jsonEnd8.completedHtml +  
"<br>"+
json["pages"][8]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][8]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][8]["questions"][0]["correctAnswer"]
;  
return jsonEnd8;
};

function jsonSummary9EWF(json) {  
jsonEnd9 = jsonSummary8EWF(json);
jsonEnd9.completedHtml = jsonEnd9.completedHtml +  
"<br>"+
json["pages"][9]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][9]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][9]["questions"][0]["correctAnswer"]
;  
return jsonEnd9;
};


function jsonSummary10EWF(json) {  
jsonEnd10 = jsonSummary9EWF(json);
jsonEnd10.completedHtml = jsonEnd10.completedHtml +  
"<br>"+
json["pages"][10]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][10]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][10]["questions"][0]["correctAnswer"]
;  
return jsonEnd10;
};


function jsonSummary11EWF(json) {  
jsonEnd11 = jsonSummary10EWF(json);
jsonEnd11.completedHtml = jsonEnd11.completedHtml +  
"<br>"+
json["pages"][11]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][11]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][11]["questions"][0]["correctAnswer"]
;  
return jsonEnd11;
};

Survey.StylesManager.applyTheme("modern");

</script>  
<!-- This completes the code for the quizzes -->

<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>

<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  if (t = document.getElementById("webex-total_correct")) {
    var correct = document.getElementsByClassName("webex-correct").length;
    var solvemes = document.getElementsByClassName("webex-solveme").length;
    var radiogroups = document.getElementsByClassName("webex-radiogroup").length;
    var selects = document.getElementsByClassName("webex-select").length;
    
    t.innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");
  
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");
  
  var cl = this.classList
  
  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;
  
  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }
  
  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

window.onload = function() {
  console.log("onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }
  
  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
  }

  update_total_correct();
}

</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="includeWebex/webex.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reviewers"><i class="fa fa-check"></i>Reviewers</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#other-collaborators"><i class="fa fa-check"></i>Other Collaborators</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version"><i class="fa fa-check"></i>Version</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#for-our-readers"><i class="fa fa-check"></i>For our Readers</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ChapIntro.html"><a href="ChapIntro.html"><i class="fa fa-check"></i><b>1</b> Loss Data and Insurance Activities</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ChapIntro.html"><a href="ChapIntro.html#S:Intro"><i class="fa fa-check"></i><b>1.1</b> Data Driven Insurance Activities</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="ChapIntro.html"><a href="ChapIntro.html#nature-and-relevance-of-insurance"><i class="fa fa-check"></i><b>1.1.1</b> Nature and Relevance of Insurance</a></li>
<li class="chapter" data-level="1.1.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:DataDriven"><i class="fa fa-check"></i><b>1.1.2</b> Why Data Driven?</a></li>
<li class="chapter" data-level="1.1.3" data-path="ChapIntro.html"><a href="ChapIntro.html#S:InsProcesses"><i class="fa fa-check"></i><b>1.1.3</b> Insurance Processes</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:PredModApps"><i class="fa fa-check"></i><b>1.2</b> Insurance Company Operations</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ChapIntro.html"><a href="ChapIntro.html#initiating-insurance"><i class="fa fa-check"></i><b>1.2.1</b> Initiating Insurance</a></li>
<li class="chapter" data-level="1.2.2" data-path="ChapIntro.html"><a href="ChapIntro.html#renewing-insurance"><i class="fa fa-check"></i><b>1.2.2</b> Renewing Insurance</a></li>
<li class="chapter" data-level="1.2.3" data-path="ChapIntro.html"><a href="ChapIntro.html#claims-and-product-management"><i class="fa fa-check"></i><b>1.2.3</b> Claims and Product Management</a></li>
<li class="chapter" data-level="1.2.4" data-path="ChapIntro.html"><a href="ChapIntro.html#S:Reserving"><i class="fa fa-check"></i><b>1.2.4</b> Loss Reserving</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ChapIntro.html"><a href="ChapIntro.html#S:LGPIF"><i class="fa fa-check"></i><b>1.3</b> Case Study: Wisconsin Property Fund</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="ChapIntro.html"><a href="ChapIntro.html#S:OutComes"><i class="fa fa-check"></i><b>1.3.1</b> Fund Claims Variables: Frequency and Severity</a></li>
<li class="chapter" data-level="1.3.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:FundVariables"><i class="fa fa-check"></i><b>1.3.2</b> Fund Rating Variables</a></li>
<li class="chapter" data-level="1.3.3" data-path="ChapIntro.html"><a href="ChapIntro.html#fund-operations"><i class="fa fa-check"></i><b>1.3.3</b> Fund Operations</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ChapIntro.html"><a href="ChapIntro.html#exercises"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
<li class="chapter" data-level="1.5" data-path="ChapIntro.html"><a href="ChapIntro.html#Intro-further-reading-and-resources"><i class="fa fa-check"></i><b>1.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html"><i class="fa fa-check"></i><b>2</b> Introduction to Data Analytics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:Elements"><i class="fa fa-check"></i><b>2.1</b> Elements of Data Analytics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#key-data-analytic-concepts"><i class="fa fa-check"></i><b>2.1.1</b> Key Data Analytic Concepts</a></li>
<li class="chapter" data-level="2.1.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:DataAlgorithm"><i class="fa fa-check"></i><b>2.1.2</b> Data versus Algorithmic Modeling</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:Process"><i class="fa fa-check"></i><b>2.2</b> Data Analysis Process</a></li>
<li class="chapter" data-level="2.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:SingleVarAnalytics"><i class="fa fa-check"></i><b>2.3</b> Single Variable Analytics</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:VarTypes"><i class="fa fa-check"></i><b>2.3.1</b> Variable Types</a></li>
<li class="chapter" data-level="2.3.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:EDACDA"><i class="fa fa-check"></i><b>2.3.2</b> Exploratory versus Confirmatory</a></li>
<li class="chapter" data-level="2.3.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#model-construction"><i class="fa fa-check"></i><b>2.3.3</b> Model Construction</a></li>
<li class="chapter" data-level="2.3.4" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#model-selection"><i class="fa fa-check"></i><b>2.3.4</b> Model Selection</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:ManyVarAnalytics"><i class="fa fa-check"></i><b>2.4</b> Analytics with Many Variables</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#supervised-and-unsupervised-learning"><i class="fa fa-check"></i><b>2.4.1</b> Supervised and Unsupervised Learning</a></li>
<li class="chapter" data-level="2.4.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#algorithmic-modeling"><i class="fa fa-check"></i><b>2.4.2</b> Algorithmic Modeling</a></li>
<li class="chapter" data-level="2.4.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-modeling"><i class="fa fa-check"></i><b>2.4.3</b> Data Modeling</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:DataLearn"><i class="fa fa-check"></i><b>2.5</b> Data</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-types"><i class="fa fa-check"></i><b>2.5.1</b> Data Types</a></li>
<li class="chapter" data-level="2.5.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-structures-and-storage"><i class="fa fa-check"></i><b>2.5.2</b> Data Structures and Storage</a></li>
<li class="chapter" data-level="2.5.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-cleaning"><i class="fa fa-check"></i><b>2.5.3</b> Data Cleaning</a></li>
<li class="chapter" data-level="2.5.4" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#Sec:BigDataAnalysis"><i class="fa fa-check"></i><b>2.5.4</b> Big Data Analysis</a></li>
<li class="chapter" data-level="2.5.5" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#ethical-issues"><i class="fa fa-check"></i><b>2.5.5</b> Ethical Issues</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#DS:further-reading-and-resources"><i class="fa fa-check"></i><b>2.6</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:MultiEDA"><i class="fa fa-check"></i><b>2.6.1</b> Technical Supplement: Multivariate Exploratory Analysis</a></li>
<li class="chapter" data-level="2.6.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#tree-based-models"><i class="fa fa-check"></i><b>2.6.2</b> Tree-based Models</a></li>
<li class="chapter" data-level="2.6.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#technical-supplement-some-r-functions"><i class="fa fa-check"></i><b>2.6.3</b> Technical Supplement: Some R Functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html"><i class="fa fa-check"></i><b>3</b> Frequency Modeling</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:frequency-distributions"><i class="fa fa-check"></i><b>3.1</b> Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:how-frequency-augments-severity-information"><i class="fa fa-check"></i><b>3.1.1</b> How Frequency Augments Severity Information</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:basic-frequency-distributions"><i class="fa fa-check"></i><b>3.2</b> Basic Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:foundations"><i class="fa fa-check"></i><b>3.2.1</b> Foundations</a></li>
<li class="chapter" data-level="3.2.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:generating-functions"><i class="fa fa-check"></i><b>3.2.2</b> Moment and Probability Generating Functions</a></li>
<li class="chapter" data-level="3.2.3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:important-frequency-distributions"><i class="fa fa-check"></i><b>3.2.3</b> Important Frequency Distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:the-a-b-0-class"><i class="fa fa-check"></i><b>3.3</b> The (<em>a</em>, <em>b</em>, 0) Class</a></li>
<li class="chapter" data-level="3.4" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:estimating-frequency-distributions"><i class="fa fa-check"></i><b>3.4</b> Estimating Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:parameter-estimation"><i class="fa fa-check"></i><b>3.4.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="3.4.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:frequency-distributions-mle"><i class="fa fa-check"></i><b>3.4.2</b> Frequency Distributions MLE</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:other-frequency-distributions"><i class="fa fa-check"></i><b>3.5</b> Other Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:zero-truncation-or-modification"><i class="fa fa-check"></i><b>3.5.1</b> Zero Truncation or Modification</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:mixture-distributions"><i class="fa fa-check"></i><b>3.6</b> Mixture Distributions</a></li>
<li class="chapter" data-level="3.7" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:goodness-of-fit"><i class="fa fa-check"></i><b>3.7</b> Goodness of Fit</a></li>
<li class="chapter" data-level="3.8" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
<li class="chapter" data-level="3.9" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#Freq-further-reading-and-resources"><i class="fa fa-check"></i><b>3.9</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:rcode"><i class="fa fa-check"></i><b>3.9.1</b> TS 3.A. R Code for Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ChapSeverity.html"><a href="ChapSeverity.html"><i class="fa fa-check"></i><b>4</b> Modeling Loss Severity</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:BasicQuantities"><i class="fa fa-check"></i><b>4.1</b> Basic Distributional Quantities</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Chap3Moments"><i class="fa fa-check"></i><b>4.1.1</b> Moments</a></li>
<li class="chapter" data-level="4.1.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LS:Quantiles"><i class="fa fa-check"></i><b>4.1.2</b> Quantiles</a></li>
<li class="chapter" data-level="4.1.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#moment-generating-function"><i class="fa fa-check"></i><b>4.1.3</b> Moment Generating Function</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:ContinuousDistn"><i class="fa fa-check"></i><b>4.2</b> Continuous Distributions for Modeling Loss Severity</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Loss:Gamma"><i class="fa fa-check"></i><b>4.2.1</b> Gamma Distribution</a></li>
<li class="chapter" data-level="4.2.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#pareto-distribution"><i class="fa fa-check"></i><b>4.2.2</b> Pareto Distribution</a></li>
<li class="chapter" data-level="4.2.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LS:Weibull"><i class="fa fa-check"></i><b>4.2.3</b> Weibull Distribution</a></li>
<li class="chapter" data-level="4.2.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#the-generalized-beta-distribution-of-the-second-kind"><i class="fa fa-check"></i><b>4.2.4</b> The Generalized Beta Distribution of the Second Kind</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#MethodsCreation"><i class="fa fa-check"></i><b>4.3</b> Methods of Creating New Distributions</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#functions-of-random-variables-and-their-distributions"><i class="fa fa-check"></i><b>4.3.1</b> Functions of Random Variables and their Distributions</a></li>
<li class="chapter" data-level="4.3.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#multiplication-by-a-constant"><i class="fa fa-check"></i><b>4.3.2</b> Multiplication by a Constant</a></li>
<li class="chapter" data-level="4.3.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LossSev:Raising"><i class="fa fa-check"></i><b>4.3.3</b> Raising to a Power</a></li>
<li class="chapter" data-level="4.3.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#exponentiation"><i class="fa fa-check"></i><b>4.3.4</b> Exponentiation</a></li>
<li class="chapter" data-level="4.3.5" data-path="ChapSeverity.html"><a href="ChapSeverity.html#finite-mixtures"><i class="fa fa-check"></i><b>4.3.5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="4.3.6" data-path="ChapSeverity.html"><a href="ChapSeverity.html#continuous-mixtures"><i class="fa fa-check"></i><b>4.3.6</b> Continuous Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:CoverageModifications"><i class="fa fa-check"></i><b>4.4</b> Coverage Modifications</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:PolicyDeduct"><i class="fa fa-check"></i><b>4.4.1</b> Policy Deductibles</a></li>
<li class="chapter" data-level="4.4.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:PolicyLimits"><i class="fa fa-check"></i><b>4.4.2</b> Policy Limits</a></li>
<li class="chapter" data-level="4.4.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#coinsurance-and-inflation"><i class="fa fa-check"></i><b>4.4.3</b> Coinsurance and Inflation</a></li>
<li class="chapter" data-level="4.4.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Chap3Reinsurance"><i class="fa fa-check"></i><b>4.4.4</b> Reinsurance</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:MaxLikeEstimation"><i class="fa fa-check"></i><b>4.5</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#maximum-likelihood-estimators-for-complete-data"><i class="fa fa-check"></i><b>4.5.1</b> Maximum Likelihood Estimators for Complete Data</a></li>
<li class="chapter" data-level="4.5.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Loss:MLEModified"><i class="fa fa-check"></i><b>4.5.2</b> Maximum Likelihood Estimators using Modified Data</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ChapSeverity.html"><a href="ChapSeverity.html#LM-further-reading-and-resources"><i class="fa fa-check"></i><b>4.6</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html"><i class="fa fa-check"></i><b>5</b> Model Selection and Estimation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:NonParInf"><i class="fa fa-check"></i><b>5.1</b> Nonparametric Estimation</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:NonParEst"><i class="fa fa-check"></i><b>5.1.1</b> Nonparametric Methods</a></li>
<li class="chapter" data-level="5.1.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#starting-values"><i class="fa fa-check"></i><b>5.1.2</b> Starting Values</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ModifiedData"><i class="fa fa-check"></i><b>5.2</b> Estimation using Modified Data</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ModifiedData1"><i class="fa fa-check"></i><b>5.2.1</b> Parametric Estimation using Modified Data</a></li>
<li class="chapter" data-level="5.2.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:NonParModified"><i class="fa fa-check"></i><b>5.2.2</b> Nonparametric Estimation using Modified Data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ModelSelection"><i class="fa fa-check"></i><b>5.3</b> Model Selection</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ToolsModelSelection"><i class="fa fa-check"></i><b>5.3.1</b> Tools for Model Selection and Diagnostics</a></li>
<li class="chapter" data-level="5.3.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Iterative:Selection"><i class="fa fa-check"></i><b>5.3.2</b> Iterative Model Selection</a></li>
<li class="chapter" data-level="5.3.3" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Tools:Stats:Likelihood"><i class="fa fa-check"></i><b>5.3.3</b> Model Selection Based on a Training Dataset</a></li>
<li class="chapter" data-level="5.3.4" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#model-selection-based-on-a-test-dataset"><i class="fa fa-check"></i><b>5.3.4</b> Model Selection Based on a Test Dataset</a></li>
<li class="chapter" data-level="5.3.5" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Cross-Validation"><i class="fa fa-check"></i><b>5.3.5</b> Model Selection Based on Cross-Validation</a></li>
<li class="chapter" data-level="5.3.6" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Modified-Data"><i class="fa fa-check"></i><b>5.3.6</b> Model Selection for Modified Data</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#MS:further-reading-and-resources"><i class="fa fa-check"></i><b>5.4</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html"><i class="fa fa-check"></i><b>6</b> Aggregate Loss Models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#introduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#individual-risk-model"><i class="fa fa-check"></i><b>6.2</b> Individual Risk Model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#moments-and-distribution"><i class="fa fa-check"></i><b>6.2.1</b> Moments and Distribution</a></li>
<li class="chapter" data-level="6.2.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#aggregate-loss-distribution"><i class="fa fa-check"></i><b>6.2.2</b> Aggregate Loss Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:AggLoss:CRM"><i class="fa fa-check"></i><b>6.3</b> Collective Risk Model</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#moments-and-distribution-1"><i class="fa fa-check"></i><b>6.3.1</b> Moments and Distribution</a></li>
<li class="chapter" data-level="6.3.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#stop-loss-insurance"><i class="fa fa-check"></i><b>6.3.2</b> Stop-loss Insurance</a></li>
<li class="chapter" data-level="6.3.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#closed-form-distributions"><i class="fa fa-check"></i><b>6.3.3</b> Closed-form Distributions</a></li>
<li class="chapter" data-level="6.3.4" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:AggLoss:Tweedie"><i class="fa fa-check"></i><b>6.3.4</b> Tweedie Distribution</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#computing-the-aggregate-claims-distribution"><i class="fa fa-check"></i><b>6.4</b> Computing the Aggregate Claims Distribution</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#recursive-method"><i class="fa fa-check"></i><b>6.4.1</b> Recursive Method</a></li>
<li class="chapter" data-level="6.4.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#simulation"><i class="fa fa-check"></i><b>6.4.2</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#effects-of-coverage-modifications"><i class="fa fa-check"></i><b>6.5</b> Effects of Coverage Modifications</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#impact-of-exposure-on-frequency"><i class="fa fa-check"></i><b>6.5.1</b> Impact of Exposure on Frequency</a></li>
<li class="chapter" data-level="6.5.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:MS:DedImpactClmFreq"><i class="fa fa-check"></i><b>6.5.2</b> Impact of Deductibles on Claim Frequency</a></li>
<li class="chapter" data-level="6.5.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#impact-of-policy-modifications-on-aggregate-claims"><i class="fa fa-check"></i><b>6.5.3</b> Impact of Policy Modifications on Aggregate Claims</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#AL-further-reading-and-resources"><i class="fa fa-check"></i><b>6.6</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#ts-6.a.1.-individual-risk-model-properties"><i class="fa fa-check"></i>TS 6.A.1. Individual Risk Model Properties</a></li>
<li class="chapter" data-level="" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#ts-6.a.2.-relationship-between-probability-generating-functions-of-x_i-and-x_it"><i class="fa fa-check"></i>TS 6.A.2. Relationship Between Probability Generating Functions of <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_i^T\)</span></a></li>
<li class="chapter" data-level="" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#ts-6.a.3.-moment-generating-function-of-aggregate-loss-s_n-in-example-6.3.8"><i class="fa fa-check"></i>TS 6.A.3. Moment Generating Function of Aggregate Loss <span class="math inline">\(S_N\)</span> in Example 6.3.8</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ChapSimulation.html"><a href="ChapSimulation.html"><i class="fa fa-check"></i><b>7</b> Simulation and Resampling</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:SimulationFundamentals"><i class="fa fa-check"></i><b>7.1</b> Simulation Fundamentals</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#generating-independent-uniform-observations"><i class="fa fa-check"></i><b>7.1.1</b> Generating Independent Uniform Observations</a></li>
<li class="chapter" data-level="7.1.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:InverseTransform"><i class="fa fa-check"></i><b>7.1.2</b> Inverse Transform Method</a></li>
<li class="chapter" data-level="7.1.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#simulation-precision"><i class="fa fa-check"></i><b>7.1.3</b> Simulation Precision</a></li>
<li class="chapter" data-level="7.1.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:SimulationStatInference"><i class="fa fa-check"></i><b>7.1.4</b> Simulation and Statistical Inference</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:Bootstrap"><i class="fa fa-check"></i><b>7.2</b> Bootstrapping and Resampling</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#bootstrap-foundations"><i class="fa fa-check"></i><b>7.2.1</b> Bootstrap Foundations</a></li>
<li class="chapter" data-level="7.2.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:Sim:Precision"><i class="fa fa-check"></i><b>7.2.2</b> Bootstrap Precision: Bias, Standard Deviation, and Mean Square Error</a></li>
<li class="chapter" data-level="7.2.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#confidence-intervals"><i class="fa fa-check"></i><b>7.2.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="7.2.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:ParametricBootStrap"><i class="fa fa-check"></i><b>7.2.4</b> Parametric Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:CrossValidation"><i class="fa fa-check"></i><b>7.3</b> Cross-Validation</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>7.3.1</b> k-Fold Cross-Validation</a></li>
<li class="chapter" data-level="7.3.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>7.3.2</b> Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="7.3.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#cross-validation-and-bootstrap"><i class="fa fa-check"></i><b>7.3.3</b> Cross-Validation and Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:ImportanceSampling"><i class="fa fa-check"></i><b>7.4</b> Importance Sampling</a></li>
<li class="chapter" data-level="7.5" data-path="ChapSimulation.html"><a href="ChapSimulation.html#Simulation:further-reading-and-resources"><i class="fa fa-check"></i><b>7.5</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#ts-7.a.-bootstrap-applications-in-predictive-modeling"><i class="fa fa-check"></i><b>7.5.1</b> TS 7.A. Bootstrap Applications in Predictive Modeling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ChBayes.html"><a href="ChBayes.html"><i class="fa fa-check"></i><b>8</b> Bayesian Inference and Modeling</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecIntro"><i class="fa fa-check"></i><b>8.1</b> A Gentle Introduction to Bayesian Statistics</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubSecBayesVsFreq"><i class="fa fa-check"></i><b>8.1.1</b> Bayesian versus Frequentist Statistics</a></li>
<li class="chapter" data-level="8.1.2" data-path="ChBayes.html"><a href="ChBayes.html#a-brief-history-lesson"><i class="fa fa-check"></i><b>8.1.2</b> A Brief History Lesson</a></li>
<li class="chapter" data-level="8.1.3" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecBayesRule"><i class="fa fa-check"></i><b>8.1.3</b> Bayes Rule</a></li>
<li class="chapter" data-level="8.1.4" data-path="ChBayes.html"><a href="ChBayes.html#an-introductory-example-of-bayes-rule"><i class="fa fa-check"></i><b>8.1.4</b> An Introductory Example of Bayes Rule</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecBuildingBlocks"><i class="fa fa-check"></i><b>8.2</b> Building Blocks of Bayesian Inference</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecPosterior"><i class="fa fa-check"></i><b>8.2.1</b> Posterior Distribution</a></li>
<li class="chapter" data-level="8.2.2" data-path="ChBayes.html"><a href="ChBayes.html#likelihood-function"><i class="fa fa-check"></i><b>8.2.2</b> Likelihood Function</a></li>
<li class="chapter" data-level="8.2.3" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecPrior"><i class="fa fa-check"></i><b>8.2.3</b> Prior Distribution</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecConjugate"><i class="fa fa-check"></i><b>8.3</b> Conjugate Families</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecBetaBin"><i class="fa fa-check"></i><b>8.3.1</b> The BetaBinomial Conjugate Family</a></li>
<li class="chapter" data-level="8.3.2" data-path="ChBayes.html"><a href="ChBayes.html#the-gammapoisson-conjugate-family"><i class="fa fa-check"></i><b>8.3.2</b> The GammaPoisson Conjugate Family</a></li>
<li class="chapter" data-level="8.3.3" data-path="ChBayes.html"><a href="ChBayes.html#the-normalnormal-conjugate-family"><i class="fa fa-check"></i><b>8.3.3</b> The NormalNormal Conjugate Family</a></li>
<li class="chapter" data-level="8.3.4" data-path="ChBayes.html"><a href="ChBayes.html#criticism-of-conjugate-family-models"><i class="fa fa-check"></i><b>8.3.4</b> Criticism of Conjugate Family Models</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecPosterior"><i class="fa fa-check"></i><b>8.4</b> Posterior Simulation</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ChBayes.html"><a href="ChBayes.html#introduction-to-markov-chain-monte-carlo-methods"><i class="fa fa-check"></i><b>8.4.1</b> Introduction to Markov Chain Monte Carlo Methods</a></li>
<li class="chapter" data-level="8.4.2" data-path="ChBayes.html"><a href="ChBayes.html#the-gibbs-sampler"><i class="fa fa-check"></i><b>8.4.2</b> The Gibbs Sampler</a></li>
<li class="chapter" data-level="8.4.3" data-path="ChBayes.html"><a href="ChBayes.html#the-metropolishastings-algorithm"><i class="fa fa-check"></i><b>8.4.3</b> The MetropolisHastings Algorithm</a></li>
<li class="chapter" data-level="8.4.4" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecDiag"><i class="fa fa-check"></i><b>8.4.4</b> Markov Chain Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecFurther"><i class="fa fa-check"></i><b>8.5</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChBayes.html"><a href="ChBayes.html#contributors-7"><i class="fa fa-check"></i>Contributors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html"><i class="fa fa-check"></i><b>9</b> Premium Foundations</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:IntroductionRatemaking"><i class="fa fa-check"></i><b>9.1</b> Introduction to Ratemaking</a></li>
<li class="chapter" data-level="9.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:AggRateMaking"><i class="fa fa-check"></i><b>9.2</b> Aggregate Ratemaking Methods</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:PurePremium"><i class="fa fa-check"></i><b>9.2.1</b> Pure Premium Method</a></li>
<li class="chapter" data-level="9.2.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:LossRatio"><i class="fa fa-check"></i><b>9.2.2</b> Loss Ratio Method</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:PricingPrinciples"><i class="fa fa-check"></i><b>9.3</b> Pricing Principles</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#premium-principles"><i class="fa fa-check"></i><b>9.3.1</b> Premium Principles</a></li>
<li class="chapter" data-level="9.3.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#properties-of-premium-principles"><i class="fa fa-check"></i><b>9.3.2</b> Properties of Premium Principles</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:HeterogeneousRisks"><i class="fa fa-check"></i><b>9.4</b> Heterogeneous Risks</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:ExposureToRisk"><i class="fa fa-check"></i><b>9.4.1</b> Exposure to Risk</a></li>
<li class="chapter" data-level="9.4.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:RatingFactors"><i class="fa fa-check"></i><b>9.4.2</b> Rating Factors</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:TrendDevelopment"><i class="fa fa-check"></i><b>9.5</b> Development and Trending</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#exposures-and-premiums"><i class="fa fa-check"></i><b>9.5.1</b> Exposures and Premiums</a></li>
<li class="chapter" data-level="9.5.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#losses-claims-and-payments"><i class="fa fa-check"></i><b>9.5.2</b> Losses, Claims, and Payments</a></li>
<li class="chapter" data-level="9.5.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:CompareMethods"><i class="fa fa-check"></i><b>9.5.3</b> Comparing Pure Premium and Loss Ratio Methods</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:GiniStatistic"><i class="fa fa-check"></i><b>9.6</b> Selecting a Premium</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#classic-lorenz-curve"><i class="fa fa-check"></i><b>9.6.1</b> Classic Lorenz Curve</a></li>
<li class="chapter" data-level="9.6.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#performance-curve-and-a-gini-statistic"><i class="fa fa-check"></i><b>9.6.2</b> Performance Curve and a Gini Statistic</a></li>
<li class="chapter" data-level="9.6.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#out-of-sample-validation"><i class="fa fa-check"></i><b>9.6.3</b> Out-of-Sample Validation</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#further-resources-and-contributors"><i class="fa fa-check"></i><b>9.7</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#ts-9.a.-rate-regulation"><i class="fa fa-check"></i>TS 9.A. Rate Regulation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html"><i class="fa fa-check"></i><b>10</b> Risk Classification</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:Introduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:PoissonRegression"><i class="fa fa-check"></i><b>10.2</b> Poisson Regression Model</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:Need.Poi.reg"><i class="fa fa-check"></i><b>10.2.1</b> Need for Poisson Regression</a></li>
<li class="chapter" data-level="10.2.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#poisson-regression"><i class="fa fa-check"></i><b>10.2.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="10.2.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#incorporating-exposure"><i class="fa fa-check"></i><b>10.2.3</b> Incorporating Exposure</a></li>
<li class="chapter" data-level="10.2.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#exercises-4"><i class="fa fa-check"></i><b>10.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:CatVarMultiTarriff"><i class="fa fa-check"></i><b>10.3</b> Categorical Variables and Multiplicative Tariff</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#rating-factors-and-tariff"><i class="fa fa-check"></i><b>10.3.1</b> Rating Factors and Tariff</a></li>
<li class="chapter" data-level="10.3.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#multiplicative-tariff-model"><i class="fa fa-check"></i><b>10.3.2</b> Multiplicative Tariff Model</a></li>
<li class="chapter" data-level="10.3.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#poisson-regression-for-multiplicative-tariff"><i class="fa fa-check"></i><b>10.3.3</b> Poisson Regression for Multiplicative Tariff</a></li>
<li class="chapter" data-level="10.3.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#numerical-examples"><i class="fa fa-check"></i><b>10.3.4</b> Numerical Examples</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#RC:further-reading-and-resources"><i class="fa fa-check"></i><b>10.4</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#ts-10.a.-estimating-poisson-regression-models"><i class="fa fa-check"></i>TS 10.A. Estimating Poisson Regression Models</a></li>
<li class="chapter" data-level="" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#ts-10.b.-selecting-rating-factors"><i class="fa fa-check"></i>TS 10.B. Selecting Rating Factors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ChapCredibility.html"><a href="ChapCredibility.html"><i class="fa fa-check"></i><b>11</b> Experience Rating Using Credibility Theory</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#introduction-to-applications-of-credibility-theory"><i class="fa fa-check"></i><b>11.1</b> Introduction to Applications of Credibility Theory</a></li>
<li class="chapter" data-level="11.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#limited-fluctuation-credibility"><i class="fa fa-check"></i><b>11.2</b> Limited Fluctuation Credibility</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:frequency"><i class="fa fa-check"></i><b>11.2.1</b> Full Credibility for Claim Frequency</a></li>
<li class="chapter" data-level="11.2.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-for-aggregate-losses-and-pure-premium"><i class="fa fa-check"></i><b>11.2.2</b> Full Credibility for Aggregate Losses and Pure Premium</a></li>
<li class="chapter" data-level="11.2.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-for-severity"><i class="fa fa-check"></i><b>11.2.3</b> Full Credibility for Severity</a></li>
<li class="chapter" data-level="11.2.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#partial-credibility"><i class="fa fa-check"></i><b>11.2.4</b> Partial Credibility</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:Cred:Buhlmann"><i class="fa fa-check"></i><b>11.3</b> Bhlmann Credibility</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:EPV-VHM-Z"><i class="fa fa-check"></i><b>11.3.1</b> Credibility <em>Z</em>, <em>EPV</em>, and <em>VHM</em></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#bhlmann-straub-credibility"><i class="fa fa-check"></i><b>11.4</b> Bhlmann-Straub Credibility</a></li>
<li class="chapter" data-level="11.5" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:Cred:BayesInf"><i class="fa fa-check"></i><b>11.5</b> Bayesian Inference and Bhlmann Credibility</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#Sec:Cred:gammaPoisson"><i class="fa fa-check"></i><b>11.5.1</b> Gamma-Poisson Model</a></li>
<li class="chapter" data-level="11.5.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#beta-binomial-model"><i class="fa fa-check"></i><b>11.5.2</b> Beta-Binomial Model</a></li>
<li class="chapter" data-level="11.5.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#exact-credibility"><i class="fa fa-check"></i><b>11.5.3</b> Exact Credibility</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="ChapCredibility.html"><a href="ChapCredibility.html#estimating-credibility-parameters"><i class="fa fa-check"></i><b>11.6</b> Estimating Credibility Parameters</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-standard-for-limited-fluctuation-credibility"><i class="fa fa-check"></i><b>11.6.1</b> Full Credibility Standard for Limited Fluctuation Credibility</a></li>
<li class="chapter" data-level="11.6.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#nonparametric-estimation-for-bhlmann-and-bhlmann-straub-models"><i class="fa fa-check"></i><b>11.6.2</b> Nonparametric Estimation for Bhlmann and Bhlmann-Straub Models</a></li>
<li class="chapter" data-level="11.6.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#semiparametric-estimation-for-bhlmann-and-bhlmann-straub-models"><i class="fa fa-check"></i><b>11.6.3</b> Semiparametric Estimation for Bhlmann and Bhlmann-Straub Models</a></li>
<li class="chapter" data-level="11.6.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#balancing-credibility-estimators"><i class="fa fa-check"></i><b>11.6.4</b> Balancing Credibility Estimators</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="ChapCredibility.html"><a href="ChapCredibility.html#Cred-further-reading-and-resources"><i class="fa fa-check"></i><b>11.7</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html"><i class="fa fa-check"></i><b>12</b> Insurance Portfolio Management including Reinsurance</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#introduction-to-insurance-portfolios"><i class="fa fa-check"></i><b>12.1</b> Introduction to Insurance Portfolios</a></li>
<li class="chapter" data-level="12.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:Tails"><i class="fa fa-check"></i><b>12.2</b> Tails of Distributions</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#classification-based-on-moments"><i class="fa fa-check"></i><b>12.2.1</b> Classification Based on Moments</a></li>
<li class="chapter" data-level="12.2.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#comparison-based-on-limiting-tail-behavior"><i class="fa fa-check"></i><b>12.2.2</b> Comparison Based on Limiting Tail Behavior</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:RiskMeasure"><i class="fa fa-check"></i><b>12.3</b> Risk Measures</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#coherent-risk-measures"><i class="fa fa-check"></i><b>12.3.1</b> Coherent Risk Measures</a></li>
<li class="chapter" data-level="12.3.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#value-at-risk"><i class="fa fa-check"></i><b>12.3.2</b> Value-at-Risk</a></li>
<li class="chapter" data-level="12.3.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#tail-value-at-risk"><i class="fa fa-check"></i><b>12.3.3</b> Tail Value-at-Risk</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:Reinsurance"><i class="fa fa-check"></i><b>12.4</b> Reinsurance</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:ProportionalRe"><i class="fa fa-check"></i><b>12.4.1</b> Proportional Reinsurance</a></li>
<li class="chapter" data-level="12.4.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:NonProportionalRe"><i class="fa fa-check"></i><b>12.4.2</b> Non-Proportional Reinsurance</a></li>
<li class="chapter" data-level="12.4.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:AdditionalRe"><i class="fa fa-check"></i><b>12.4.3</b> Additional Reinsurance Treaties</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#further-resources-and-contributors-1"><i class="fa fa-check"></i><b>12.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html"><i class="fa fa-check"></i><b>13</b> Loss Reserving</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:motivation"><i class="fa fa-check"></i><b>13.1</b> Motivation</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:claim-types"><i class="fa fa-check"></i><b>13.1.1</b> Closed, IBNR, and RBNS Claims</a></li>
<li class="chapter" data-level="13.1.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#why-reserving"><i class="fa fa-check"></i><b>13.1.2</b> Why Reserving?</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Data"><i class="fa fa-check"></i><b>13.2</b> Loss Reserve Data</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#from-micro-to-macro"><i class="fa fa-check"></i><b>13.2.1</b> From Micro to Macro</a></li>
<li class="chapter" data-level="13.2.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#run-off-triangles"><i class="fa fa-check"></i><b>13.2.2</b> Run-off Triangles</a></li>
<li class="chapter" data-level="13.2.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#loss-reserve-notation"><i class="fa fa-check"></i><b>13.2.3</b> Loss Reserve Notation</a></li>
<li class="chapter" data-level="13.2.4" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Rcode"><i class="fa fa-check"></i><b>13.2.4</b> R Code to Summarize Loss Reserve Data</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Chain-ladder"><i class="fa fa-check"></i><b>13.3</b> The Chain-Ladder Method</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:DeterministicCL"><i class="fa fa-check"></i><b>13.3.1</b> The Deterministic Chain-Ladder</a></li>
<li class="chapter" data-level="13.3.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#macks-distribution-free-chain-ladder-model"><i class="fa fa-check"></i><b>13.3.2</b> Macks Distribution-Free Chain-Ladder Model</a></li>
<li class="chapter" data-level="13.3.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#r-code-for-chain-ladder-predictions"><i class="fa fa-check"></i><b>13.3.3</b> R code for Chain-Ladder Predictions</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:GLMs"><i class="fa fa-check"></i><b>13.4</b> GLMs and Bootstrap for Loss Reserves</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#model-specification"><i class="fa fa-check"></i><b>13.4.1</b> Model Specification</a></li>
<li class="chapter" data-level="13.4.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#model-estimation-and-prediction"><i class="fa fa-check"></i><b>13.4.2</b> Model Estimation and Prediction</a></li>
<li class="chapter" data-level="13.4.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#bootstrap"><i class="fa fa-check"></i><b>13.4.3</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#LossRe:further-reading-and-resources"><i class="fa fa-check"></i><b>13.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html"><i class="fa fa-check"></i><b>14</b> Experience Rating using Bonus-Malus</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:Intro"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:NCD"><i class="fa fa-check"></i><b>14.2</b> <em>NCD</em> System in Several Countries</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#ncd-system-in-malaysia"><i class="fa fa-check"></i><b>14.2.1</b> <em>NCD</em> System in Malaysia</a></li>
<li class="chapter" data-level="14.2.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#ncd-systems-in-other-countries"><i class="fa fa-check"></i><b>14.2.2</b> NCD Systems in Other Countries</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:BMS"><i class="fa fa-check"></i><b>14.3</b> <em>BMS</em> and Markov Chain Model</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#transition-probability"><i class="fa fa-check"></i><b>14.3.1</b> Transition Probability</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:StatDist"><i class="fa fa-check"></i><b>14.4</b> <em>BMS</em> and Stationary Distribution</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#stationary-distribution"><i class="fa fa-check"></i><b>14.4.1</b> Stationary Distribution</a></li>
<li class="chapter" data-level="14.4.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-code-for-a-stationary-distribution"><i class="fa fa-check"></i><b>14.4.2</b> <code>R</code> Code for a Stationary Distribution</a></li>
<li class="chapter" data-level="14.4.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#premium-evolution"><i class="fa fa-check"></i><b>14.4.3</b> Premium Evolution</a></li>
<li class="chapter" data-level="14.4.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-program-for-premium-evolution"><i class="fa fa-check"></i><b>14.4.4</b> <code>R</code> Program for Premium Evolution</a></li>
<li class="chapter" data-level="14.4.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#convergence-rate"><i class="fa fa-check"></i><b>14.4.5</b> Convergence Rate</a></li>
<li class="chapter" data-level="14.4.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-program-for-convergence-rate"><i class="fa fa-check"></i><b>14.4.6</b> <code>R</code> Program for Convergence Rate</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:PremRtg"><i class="fa fa-check"></i><b>14.5</b> <em>BMS</em> and Premium Rating</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#premium-rating"><i class="fa fa-check"></i><b>14.5.1</b> Premium Rating</a></li>
<li class="chapter" data-level="14.5.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#a-priori-risk-classification"><i class="fa fa-check"></i><b>14.5.2</b> A Priori Risk Classification</a></li>
<li class="chapter" data-level="14.5.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#modelling-of-residual-heterogeneity"><i class="fa fa-check"></i><b>14.5.3</b> Modelling of Residual Heterogeneity</a></li>
<li class="chapter" data-level="14.5.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#stationary-distribution-allowing-for-residual-heterogeneity"><i class="fa fa-check"></i><b>14.5.4</b> Stationary Distribution Allowing for Residual Heterogeneity</a></li>
<li class="chapter" data-level="14.5.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#determination-of-optimal-relativities"><i class="fa fa-check"></i><b>14.5.5</b> Determination of Optimal Relativities</a></li>
<li class="chapter" data-level="14.5.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#numerical-illustrations"><i class="fa fa-check"></i><b>14.5.6</b> Numerical Illustrations</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:Further"><i class="fa fa-check"></i><b>14.6</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>14.6.1</b> Further Reading and References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html"><i class="fa fa-check"></i><b>15</b> Dependence Modeling</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#multivariate-variables"><i class="fa fa-check"></i><b>15.1</b> Multivariate Variables</a></li>
<li class="chapter" data-level="15.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:Measures"><i class="fa fa-check"></i><b>15.2</b> Classic Measures of Scalar Associations</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#association-measures-for-quantitative-variables"><i class="fa fa-check"></i><b>15.2.1</b> Association Measures for Quantitative Variables</a></li>
<li class="chapter" data-level="15.2.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#rank-based-measures"><i class="fa fa-check"></i><b>15.2.2</b> Rank Based Measures</a></li>
<li class="chapter" data-level="15.2.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#nominal-variables"><i class="fa fa-check"></i><b>15.2.3</b> Nominal Variables</a></li>
<li class="chapter" data-level="15.2.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#ordinal-variables"><i class="fa fa-check"></i><b>15.2.4</b> Ordinal Variables</a></li>
<li class="chapter" data-level="15.2.5" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#interval-variables"><i class="fa fa-check"></i><b>15.2.5</b> Interval Variables</a></li>
<li class="chapter" data-level="15.2.6" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#discrete-and-continuous-variables"><i class="fa fa-check"></i><b>15.2.6</b> Discrete and Continuous Variables</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:Copula"><i class="fa fa-check"></i><b>15.3</b> Introduction to Copulas</a></li>
<li class="chapter" data-level="15.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopAppl"><i class="fa fa-check"></i><b>15.4</b> Application Using Copulas</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#data-description"><i class="fa fa-check"></i><b>15.4.1</b> Data Description</a></li>
<li class="chapter" data-level="15.4.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#marginal-models"><i class="fa fa-check"></i><b>15.4.2</b> Marginal Models</a></li>
<li class="chapter" data-level="15.4.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#probability-integral-transformation"><i class="fa fa-check"></i><b>15.4.3</b> Probability Integral Transformation</a></li>
<li class="chapter" data-level="15.4.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#joint-modeling-with-copula-function"><i class="fa fa-check"></i><b>15.4.4</b> Joint Modeling with Copula Function</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopTyp"><i class="fa fa-check"></i><b>15.5</b> Types of Copulas</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#normal-gaussian-copulas"><i class="fa fa-check"></i><b>15.5.1</b> Normal (Gaussian) Copulas</a></li>
<li class="chapter" data-level="15.5.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#t--and-elliptical-copulas"><i class="fa fa-check"></i><b>15.5.2</b> <em>t</em>- and Elliptical Copulas</a></li>
<li class="chapter" data-level="15.5.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#archimedean-copulas"><i class="fa fa-check"></i><b>15.5.3</b> Archimedean Copulas</a></li>
<li class="chapter" data-level="15.5.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#properties-of-copulas"><i class="fa fa-check"></i><b>15.5.4</b> Properties of Copulas</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopImp"><i class="fa fa-check"></i><b>15.6</b> Why is Dependence Modeling Important?</a></li>
<li class="chapter" data-level="15.7" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#Dep:further-reading-and-resources"><i class="fa fa-check"></i><b>15.7</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#ts-15.a.-other-classic-measures-of-scalar-associations"><i class="fa fa-check"></i>TS 15.A. Other Classic Measures of Scalar Associations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="CAppA.html"><a href="CAppA.html"><i class="fa fa-check"></i><b>16</b> Appendix A: Review of Statistical Inference</a>
<ul>
<li class="chapter" data-level="16.1" data-path="CAppA.html"><a href="CAppA.html#S:AppA:BASIC"><i class="fa fa-check"></i><b>16.1</b> Basic Concepts</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="CAppA.html"><a href="CAppA.html#random-sampling"><i class="fa fa-check"></i><b>16.1.1</b> Random Sampling</a></li>
<li class="chapter" data-level="16.1.2" data-path="CAppA.html"><a href="CAppA.html#sampling-distribution"><i class="fa fa-check"></i><b>16.1.2</b> Sampling Distribution</a></li>
<li class="chapter" data-level="16.1.3" data-path="CAppA.html"><a href="CAppA.html#central-limit-theorem"><i class="fa fa-check"></i><b>16.1.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="CAppA.html"><a href="CAppA.html#S:AppA:PE"><i class="fa fa-check"></i><b>16.2</b> Point Estimation and Properties</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="CAppA.html"><a href="CAppA.html#method-of-moments-estimation"><i class="fa fa-check"></i><b>16.2.1</b> Method of Moments Estimation</a></li>
<li class="chapter" data-level="16.2.2" data-path="CAppA.html"><a href="CAppA.html#S:AppA:MLE"><i class="fa fa-check"></i><b>16.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="CAppA.html"><a href="CAppA.html#S:AppA:IE"><i class="fa fa-check"></i><b>16.3</b> Interval Estimation</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="CAppA.html"><a href="CAppA.html#S:AppA:IE:ED"><i class="fa fa-check"></i><b>16.3.1</b> Exact Distribution for Normal Sample Mean</a></li>
<li class="chapter" data-level="16.3.2" data-path="CAppA.html"><a href="CAppA.html#large-sample-properties-of-mle"><i class="fa fa-check"></i><b>16.3.2</b> Large-sample Properties of <em>MLE</em></a></li>
<li class="chapter" data-level="16.3.3" data-path="CAppA.html"><a href="CAppA.html#confidence-interval"><i class="fa fa-check"></i><b>16.3.3</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT"><i class="fa fa-check"></i><b>16.4</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="CAppA.html"><a href="CAppA.html#basic-concepts"><i class="fa fa-check"></i><b>16.4.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="16.4.2" data-path="CAppA.html"><a href="CAppA.html#student-t-test-based-on-mle"><i class="fa fa-check"></i><b>16.4.2</b> Student-<em>t</em> test based on <em>mle</em></a></li>
<li class="chapter" data-level="16.4.3" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT:LRT"><i class="fa fa-check"></i><b>16.4.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="16.4.4" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT:IC"><i class="fa fa-check"></i><b>16.4.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="CAppB.html"><a href="CAppB.html"><i class="fa fa-check"></i><b>17</b> Appendix B: Iterated Expectations</a>
<ul>
<li class="chapter" data-level="17.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:CD"><i class="fa fa-check"></i><b>17.1</b> Conditional Distribution and Conditional Expectation</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="CAppB.html"><a href="CAppB.html#conditional-distribution"><i class="fa fa-check"></i><b>17.1.1</b> Conditional Distribution</a></li>
<li class="chapter" data-level="17.1.2" data-path="CAppB.html"><a href="CAppB.html#conditional-expectation-and-conditional-variance"><i class="fa fa-check"></i><b>17.1.2</b> Conditional Expectation and Conditional Variance</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="CAppB.html"><a href="CAppB.html#S:AppB:IE"><i class="fa fa-check"></i><b>17.2</b> Iterated Expectations and Total Variance</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:LIE"><i class="fa fa-check"></i><b>17.2.1</b> Law of Iterated Expectations</a></li>
<li class="chapter" data-level="17.2.2" data-path="CAppB.html"><a href="CAppB.html#law-of-total-variance"><i class="fa fa-check"></i><b>17.2.2</b> Law of Total Variance</a></li>
<li class="chapter" data-level="17.2.3" data-path="CAppB.html"><a href="CAppB.html#application"><i class="fa fa-check"></i><b>17.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="CAppB.html"><a href="CAppB.html#S:AppConjugateDistributions"><i class="fa fa-check"></i><b>17.3</b> Conjugate Distributions</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="CAppB.html"><a href="CAppB.html#linear-exponential-family"><i class="fa fa-check"></i><b>17.3.1</b> Linear Exponential Family</a></li>
<li class="chapter" data-level="17.3.2" data-path="CAppB.html"><a href="CAppB.html#S:IterExp:Conjugate"><i class="fa fa-check"></i><b>17.3.2</b> Conjugate Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="CAppC.html"><a href="CAppC.html"><i class="fa fa-check"></i><b>18</b> Appendix C: Maximum Likelihood Theory</a>
<ul>
<li class="chapter" data-level="18.1" data-path="CAppC.html"><a href="CAppC.html#S:AppC:LF"><i class="fa fa-check"></i><b>18.1</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="CAppC.html"><a href="CAppC.html#likelihood-and-log-likelihood-functions"><i class="fa fa-check"></i><b>18.1.1</b> Likelihood and Log-likelihood Functions</a></li>
<li class="chapter" data-level="18.1.2" data-path="CAppC.html"><a href="CAppC.html#properties-of-likelihood-functions"><i class="fa fa-check"></i><b>18.1.2</b> Properties of Likelihood Functions</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="CAppC.html"><a href="CAppC.html#S:AppC:MLE"><i class="fa fa-check"></i><b>18.2</b> Maximum Likelihood Estimators</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="CAppC.html"><a href="CAppC.html#definition-and-derivation-of-mle"><i class="fa fa-check"></i><b>18.2.1</b> Definition and Derivation of <em>MLE</em></a></li>
<li class="chapter" data-level="18.2.2" data-path="CAppC.html"><a href="CAppC.html#asymptotic-properties-of-mle"><i class="fa fa-check"></i><b>18.2.2</b> Asymptotic Properties of <em>MLE</em></a></li>
<li class="chapter" data-level="18.2.3" data-path="CAppC.html"><a href="CAppC.html#use-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>18.2.3</b> Use of Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="CAppC.html"><a href="CAppC.html#S:AppC:SI"><i class="fa fa-check"></i><b>18.3</b> Statistical Inference Based on Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="CAppC.html"><a href="CAppC.html#hypothesis-testing"><i class="fa fa-check"></i><b>18.3.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="18.3.2" data-path="CAppC.html"><a href="CAppC.html#S:AppC:MLEModelVal"><i class="fa fa-check"></i><b>18.3.2</b> <em>MLE</em> and Model Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html"><i class="fa fa-check"></i><b>19</b> Appendix D: Summary of Distributions</a>
<ul>
<li class="chapter" data-level="19.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:DiscreteDistributions"><i class="fa fa-check"></i><b>19.1</b> Discrete Distributions</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab0-class"><i class="fa fa-check"></i><b>19.1.1</b> The <em>(a,b,0)</em> Class</a></li>
<li class="chapter" data-level="19.1.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab1-class"><i class="fa fa-check"></i><b>19.1.2</b> The <em>(a,b,1)</em> Class</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:ContinuousDistributions"><i class="fa fa-check"></i><b>19.2</b> Continuous Distributions</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#one-parameter-distributions"><i class="fa fa-check"></i><b>19.2.1</b> One Parameter Distributions</a></li>
<li class="chapter" data-level="19.2.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#two-parameter-distributions"><i class="fa fa-check"></i><b>19.2.2</b> Two Parameter Distributions</a></li>
<li class="chapter" data-level="19.2.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#three-parameter-distributions"><i class="fa fa-check"></i><b>19.2.3</b> Three Parameter Distributions</a></li>
<li class="chapter" data-level="19.2.4" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#four-parameter-distribution"><i class="fa fa-check"></i><b>19.2.4</b> Four Parameter Distribution</a></li>
<li class="chapter" data-level="19.2.5" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#other-distributions"><i class="fa fa-check"></i><b>19.2.5</b> Other Distributions</a></li>
<li class="chapter" data-level="19.2.6" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#distributions-with-finite-support"><i class="fa fa-check"></i><b>19.2.6</b> Distributions with Finite Support</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#limited-expected-values"><i class="fa fa-check"></i><b>19.3</b> Limited Expected Values</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html"><i class="fa fa-check"></i><b>20</b> Appendix E: Conventions for Notation</a>
<ul>
<li class="chapter" data-level="20.1" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:General"><i class="fa fa-check"></i><b>20.1</b> General Conventions</a></li>
<li class="chapter" data-level="20.2" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Abbreviations"><i class="fa fa-check"></i><b>20.2</b> Abbreviations</a></li>
<li class="chapter" data-level="20.3" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:StatSymbols"><i class="fa fa-check"></i><b>20.3</b> Common Statistical Symbols and Operators</a></li>
<li class="chapter" data-level="20.4" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Symbols"><i class="fa fa-check"></i><b>20.4</b> Common Mathematical Symbols and Functions</a></li>
<li class="chapter" data-level="20.5" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#further-readings"><i class="fa fa-check"></i><b>20.5</b> Further Readings</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="DataResources.html"><a href="DataResources.html"><i class="fa fa-check"></i><b>21</b> Appendix. Data Resources</a>
<ul>
<li class="chapter" data-level="21.1" data-path="DataResources.html"><a href="DataResources.html#S:WiscPropFundA"><i class="fa fa-check"></i><b>21.1</b> Wisconsin Property Fund</a></li>
<li class="chapter" data-level="21.2" data-path="DataResources.html"><a href="DataResources.html#Sec:DataTravel"><i class="fa fa-check"></i><b>21.2</b> ANU Corporate Travel Data</a></li>
<li class="chapter" data-level="21.3" data-path="DataResources.html"><a href="DataResources.html#Sec:DataGPA"><i class="fa fa-check"></i><b>21.3</b> ANU Group Personal Accident Data</a></li>
<li class="chapter" data-level="21.4" data-path="DataResources.html"><a href="DataResources.html#Sec:DataAuto"><i class="fa fa-check"></i><b>21.4</b> ANU Motor Vehicle Data</a></li>
<li class="chapter" data-level="21.5" data-path="DataResources.html"><a href="DataResources.html#spanish-personal-insurance-data"><i class="fa fa-check"></i><b>21.5</b> Spanish Personal Insurance Data</a></li>
<li class="chapter" data-level="21.6" data-path="DataResources.html"><a href="DataResources.html#r-package-casdatasets"><i class="fa fa-check"></i><b>21.6</b> R Package CASdatasets</a></li>
<li class="chapter" data-level="21.7" data-path="DataResources.html"><a href="DataResources.html#other-data-sources"><i class="fa fa-check"></i><b>21.7</b> Other Data Sources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTexts/Loss-Data-Analytics" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ChapModelSelection" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Model Selection and Estimation<a href="ChapModelSelection.html#ChapModelSelection" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Chapter Preview</em>. Model selection and estimation are fundamental
aspects of statistical modeling. Chapters <a href="ChapFrequency-Modeling.html#ChapFrequency-Modeling">3</a>
and <a href="ChapSeverity.html#ChapSeverity">4</a> have described how to fit parametric models to
frequency and severity data, respectively. This chapter begins with
nonparametric estimation. To compare alternative parametric models, it
is helpful to summarize data without reference to a specific parametric
distribution. Section <a href="ChapModelSelection.html#S:MS:NonParInf">5.1</a> describes nonparametric
estimation, and how it can be used to provide starting values for
parametric procedures.To provide a flavor as to how they can be adapted
to alternative sampling schemes, Section <a href="ChapModelSelection.html#S:MS:ModifiedData">5.2</a>
describes estimation for modified data including grouped, censored and
truncated data (following the Section <a href="ChapSeverity.html#S:MaxLikeEstimation">4.5</a>
introduction). The process of model selection is then summarized in
Section <a href="ChapModelSelection.html#S:MS:ModelSelection">5.3</a>, including tools for model
comparisons and diagnostics. Although our focus is on data from
continuous distributions, the same process can be used for discrete
versions or data that come from a hybrid combination of discrete and
continuous distributions.</p>
<div id="S:MS:NonParInf" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Nonparametric Estimation<a href="ChapModelSelection.html#S:MS:NonParInf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Estimate moments, quantiles, and distributions without reference to
a parametric distribution</li>
<li>Summarize the data graphically without reference to a parametric
distribution</li>
<li>Use nonparametric estimators to approximate parameters that can be
used to start a parametric estimation procedure</li>
</ul>
<hr />
<div id="S:MS:NonParEst" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Nonparametric Methods<a href="ChapModelSelection.html#S:MS:NonParEst" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Section <a href="ChapFrequency-Modeling.html#S:basic-frequency-distributions">3.2</a> for frequency and
Section <a href="ChapSeverity.html#S:BasicQuantities">4.1</a> for severity, we learned how to
summarize a distribution by computing means, variances,
quantiles/percentiles, and so on. To approximate these summary measures
using a dataset, one strategy is to:</p>
<ol style="list-style-type: lower-roman">
<li>assume a parametric form for a distribution, such as a negative
binomial for frequency or a gamma distribution for severity,</li>
<li>estimate the parameters of that distribution, and then</li>
<li>use the distribution with the estimated parameters to calculate the
desired summary measure.</li>
</ol>
<p>This is the <a href="#" class="tooltip" style="color:green"><em>parametric</em><span style="font-size:8pt">Distributional assumptions made on the population from which the data is drawn, with properties defined using parameters.</span></a> approach. Another strategy is to
estimate the desired summary measure directly from the observations
<em>without</em> reference to a parametric model. Not surprisingly, this is
known as the <a href="#" class="tooltip" style="color:green"><em>nonparametric</em><span style="font-size:8pt">No distributional assumptions are made on the population from which the data is drawn.</span></a> approach.</p>
<p>Let us start by considering the most basic type of
<a href="#" class="tooltip" style="color:green"><em>sampling scheme</em><span style="font-size:8pt">How the data is obtained from the population and what data is observed.</span></a> and assume that observations are
realizations from a set of random variables <span class="math inline">\(X_1, \ldots, X_n\)</span> that are
<a href="#" class="tooltip" style="color:green"><em>iid</em><span style="font-size:8pt">Independent and identically distributed</span></a> draws from an unknown population distribution
<span class="math inline">\(F(\cdot)\)</span>. An equivalent way of saying this is that <span class="math inline">\(X_1, \ldots, X_n\)</span>,
is a <em>random sample</em> (with replacement) from <span class="math inline">\(F(\cdot)\)</span>. To see how this
works, we now describe nonparametric estimators of many important
measures that summarize a distribution.</p>
<div id="S:MS:MomentEstimator" class="section level4 hasAnchor" number="5.1.1.1">
<h4><span class="header-section-number">5.1.1.1</span> Moment Estimators<a href="ChapModelSelection.html#S:MS:MomentEstimator" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We learned how to define moments in Section
<a href="ChapFrequency-Modeling.html#S:generating-functions">3.2.2</a> for frequency and Section
<a href="ChapSeverity.html#S:Chap3Moments">4.1.1</a> for severity. In particular, the <span class="math inline">\(k\)</span>-th moment,
<span class="math inline">\(\mathrm{E~}[X^k] = \mu^{\prime}_k\)</span>, summarizes many aspects of the
distribution for different choices of <span class="math inline">\(k\)</span>. Here, <span class="math inline">\(\mu^{\prime}_k\)</span> is
sometimes called the <span class="math inline">\(k\)</span>th <em>population</em> moment to distinguish it from
the <span class="math inline">\(k\)</span>th sample moment, <span class="math display">\[
\frac{1}{n} \sum_{i=1}^n X_i^k ,
\]</span> which is the corresponding nonparametric estimator. In typical
applications, <span class="math inline">\(k\)</span> is a positive integer, although it need not be in
theory.</p>
<p>An important special case is the first moment where <span class="math inline">\(k=1\)</span>. In this case,
the prime symbol (<span class="math inline">\(\prime\)</span>) and the <span class="math inline">\(1\)</span> subscript are usually dropped
and one uses <span class="math inline">\(\mu=\mu^{\prime}_1\)</span> to denote the population mean, or
simply the <em>mean</em>. The corresponding sample estimator for <span class="math inline">\(\mu\)</span> is
called the <em>sample mean</em>, denoted with a bar on top of the random
variable:</p>
<p><span class="math display">\[
\overline{X} =\frac{1}{n} \sum_{i=1}^n X_i .
\]</span></p>
<p>Another type of summary measure of interest is the <span class="math inline">\(k\)</span><em>-th central
moment</em>, <span class="math inline">\(\mathrm{E~} [(X-\mu)^k] = \mu_k\)</span>. (Sometimes, <span class="math inline">\(\mu^{\prime}_k\)</span>
is called the <span class="math inline">\(k\)</span>-th <em>raw</em> moment to distinguish it from the central
moment <span class="math inline">\(\mu_k\)</span>.). A nonparametric, or sample, estimator of <span class="math inline">\(\mu_k\)</span> is <span class="math display">\[
\frac{1}{n} \sum_{i=1}^n \left(X_i - \overline{X}\right)^k .
\]</span> The second central moment (<span class="math inline">\(k=2\)</span>) is an important case for which we
typically assign a new symbol, <span class="math inline">\(\sigma^2 = \mathrm{E~} [(X-\mu)^2]\)</span>,
known as the <em>variance</em>. Properties of the sample moment estimator of
the variance such as
<span class="math inline">\(n^{-1}\sum_{i=1}^n \left(X_i - \overline{X}\right)^2\)</span> have been studied
extensively but is not the only possible estimator. The most widely used
version is one where the effective sample size is reduced by one, and so
we define <span class="math display">\[
s^2 = \frac{1}{n-1} \sum_{i=1}^n \left(X_i - \overline{X}\right)^2.
\]</span></p>
<p>Dividing by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span> matters little when you have a large
sample size <span class="math inline">\(n\)</span> as is common in insurance applications. The <em>sample
variance</em> estimator <span class="math inline">\(s^2\)</span> is <a href="#" class="tooltip" style="color:green"><em>unbiased</em><span style="font-size:8pt">An estimator that has no bias, that is, the expected value of an estimator equals the parameter being estimated.</span></a> in the sense that
<span class="math inline">\(\mathrm{E~} [s^2] = \sigma^2\)</span>, a desirable property particularly when
interpreting results of an analysis.</p>
</div>
<div id="empirical-distribution-function" class="section level4 hasAnchor" number="5.1.1.2">
<h4><span class="header-section-number">5.1.1.2</span> Empirical Distribution Function<a href="ChapModelSelection.html#empirical-distribution-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We have seen how to compute nonparametric estimators of the <span class="math inline">\(k\)</span>th moment
<span class="math inline">\(\mathrm{E~} [X^k]\)</span>. In the same way, for any known function
<span class="math inline">\(\mathrm{g}(\cdot)\)</span>, we can estimate <span class="math inline">\(\mathrm{E~} [\mathrm{g}(X)]\)</span> using
<span class="math inline">\(n^{-1}\sum_{i=1}^n \mathrm{g}(X_i)\)</span>.</p>
<p>Now consider the function <span class="math inline">\(\mathrm{g}(X) = I(X \le x)\)</span> for a fixed <span class="math inline">\(x\)</span>.
Here, the notation <span class="math inline">\(I(\cdot)\)</span> is the <a href="#" class="tooltip" style="color:green"><em>indicator</em><span style="font-size:8pt">A categorical variable that has only two groups. the numerical values are usually taken to be one to indicate the presence of an attribute, and zero otherwise. another name for a binary variable.</span></a> function; it
returns 1 if the event <span class="math inline">\((\cdot)\)</span> is true and 0 otherwise. Note that now
the random variable <span class="math inline">\(\mathrm{g}(X)\)</span> has Bernoulli distribution (a
binomial distribution with <span class="math inline">\(n=1\)</span>). We can use this distribution to
readily calculate quantities such as the mean and the variance. For
example, for this choice of <span class="math inline">\(\mathrm{g}(\cdot)\)</span>, the expected value is
<span class="math inline">\(\mathrm{E~} [I(X \le x)] = \Pr(X \le x) = F(x)\)</span>, the distribution
function evaluated at <span class="math inline">\(x\)</span>. Using the <a href="#" class="tooltip" style="color:green"><em>analog principle</em><span style="font-size:8pt"></span></a>, we
define the nonparametric estimator of the distribution function</p>
<p><span class="math display">\[
\begin{aligned}
F_n(x)
&amp;=  \frac{1}{n} \sum_{i=1}^n I\left(X_i \le x\right) \\
&amp;=  \frac{\text{number of observations less than or equal to }x}{n} .
\end{aligned}
\]</span> As <span class="math inline">\(F_n(\cdot)\)</span> is based on only observations and does not assume a
parametric family for the distribution, it is nonparametric and also
known as the <a href="#" class="tooltip" style="color:green"><em>empirical distribution function</em><span style="font-size:8pt">The empirical distribution is a non-parametric estimate of the underlying distribution of a random variable. it directly uses the data observations to construct the distribution, with each observed data point in a size-n sample having probability 1/n.</span></a>. It is also
known as the <em>empirical cumulative distribution function</em> and, in <code>R</code>,
one can use the <code>ecdf(.)</code> function to compute it.</p>
<p><strong>Example 5.1.1. Toy Dataset</strong>. To illustrate, consider a fictitious, or
toy, dataset of <span class="math inline">\(n=10\)</span> observations. Determine the empirical
distribution function.</p>
<p><span class="math display">\[
{\small
\begin{array}{c|cccccccccc}
\hline
i &amp;1&amp;2&amp;3&amp;4&amp;5&amp;6&amp;7&amp;8&amp;9&amp;10 \\
X_i&amp; 10 &amp;15 &amp;15 &amp;15 &amp;20 &amp;23 &amp;23 &amp;23 &amp;23 &amp;30\\
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.1" href="javascript:toggleEX('toggleExample.5.1.1','displayExample.5.1.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.1" style="display: none">
<p>You should check that the sample mean is <span class="math inline">\(\overline{X} = 19.7\)</span> and that
the sample variance is <span class="math inline">\(s^2 =34.45556\)</span>. The corresponding empirical
distribution function is</p>
<p><span class="math display">\[
\begin{aligned}
F_n(x) &amp;=
\left\{
\begin{array}{ll}
0 &amp; \text{ for }\ x&lt;10 \\
0.1 &amp; \text{ for }\ 10 \leq x&lt;15 \\
0.4 &amp; \text{ for }\ 15 \leq x&lt;20 \\
0.5 &amp; \text{ for }\ 20 \leq x&lt;23 \\
0.9 &amp; \text{ for }\ 23 \leq x&lt;30 \\
1 &amp; \text{ for }\ x \geq 30,
\end{array}
\right.\end{aligned}
\]</span></p>
<p>as shown in Figure <a href="ChapModelSelection.html#fig:EDFToy">5.1</a>. The empirical distribution is
generally discrete and continuous from the right.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:EDFToy"></span>
<img src="LossDataAnalytics_files/figure-html/EDFToy-1.png" alt="Empirical Distribution Function of a Toy Example" width="60%" />
<p class="caption">
Figure 5.1: <strong>Empirical Distribution Function of a Toy Example</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Toy.4f" href="javascript:togglecode('toggleCode.Toy.4f','displayCode.Toy.4f');"><i><strong>Show R Code</strong></i></a>
</h5>
<div id="toggleCode.Toy.4f" style="display: none">
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="ChapModelSelection.html#cb40-1" aria-hidden="true" tabindex="-1"></a>(xExample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="fu">rep</span>(<span class="dv">15</span>, <span class="dv">3</span>), <span class="dv">20</span>, <span class="fu">rep</span>(<span class="dv">23</span>, <span class="dv">4</span>), <span class="dv">30</span>))</span>
<span id="cb40-2"><a href="ChapModelSelection.html#cb40-2" aria-hidden="true" tabindex="-1"></a>PercentilesxExample <span class="ot">&lt;-</span> <span class="fu">ecdf</span>(xExample)</span>
<span id="cb40-3"><a href="ChapModelSelection.html#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(PercentilesxExample, <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>)</span></code></pre></div>
</div>
</div>
<hr />
</div>
<div id="S:MS:QuantileEstimator" class="section level4 hasAnchor" number="5.1.1.3">
<h4><span class="header-section-number">5.1.1.3</span> Quartiles, Percentiles and Quantiles<a href="ChapModelSelection.html#S:MS:QuantileEstimator" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We have already seen in Section <a href="ChapSeverity.html#S:Chap3Moments">4.1.1</a> the
<a href="#" class="tooltip" style="color:green"><em>median</em><span style="font-size:8pt">50th percentile of a definition, or middle value where half of the distribution lies below</span></a>, which is the number such that approximately half of
a dataset is below (or above) it. The <a href="#" class="tooltip" style="color:green"><em>first quartile</em><span style="font-size:8pt">The 25th percentile; the number such that approximately 25% of the data is below it.</span></a> is the
number such that approximately 25% of the data is below it and the
<a href="#" class="tooltip" style="color:green"><em>third quartile</em><span style="font-size:8pt">The 75th percentile; the number such that approximately 75% of the data is below it.</span></a> is the number such that approximately 75% of
the data is below it. A <span class="math inline">\(100p\)</span> <a href="#" class="tooltip" style="color:green"><em>percentile</em><span style="font-size:8pt">A 100p-th percentile is the number such that 100 times p percent of the data is below it.</span></a> is the
number such that <span class="math inline">\(100 \times p\)</span> percent of the data is below it.</p>
<p>To generalize this concept, consider a distribution function <span class="math inline">\(F(\cdot)\)</span>,
which may or may not be continuous, and let <span class="math inline">\(q\)</span> be a fraction so that
<span class="math inline">\(0&lt;q&lt;1\)</span>. We want to define a <a href="#" class="tooltip" style="color:green"><em>quantile</em><span style="font-size:8pt">The q-th quantile is the point(s) at which the distribution function is equal to q, i.e.the inverse of the cumulative distribution function.</span></a>, say <span class="math inline">\(q_F\)</span>, to be a
number such that <span class="math inline">\(F(q_F) \approx q\)</span>. Notice that when <span class="math inline">\(q = 0.5\)</span>, <span class="math inline">\(q_F\)</span>
is the median; when <span class="math inline">\(q = 0.25\)</span>, <span class="math inline">\(q_F\)</span> is the first quartile, and so on.
In the same way, when <span class="math inline">\(q = 0, 0.01, 0.02, \ldots, 0.99, 1.00\)</span>, the
resulting <span class="math inline">\(q_F\)</span> is a percentile. So, a quantile generalizes the concepts
of median, quartiles, and percentiles.</p>
<p>To be precise, for a given <span class="math inline">\(0&lt;q&lt;1\)</span>, define the <span class="math inline">\(q\)</span><strong>th quantile</strong> <span class="math inline">\(q_F\)</span>
to be <em>any</em> number that satisfies</p>
<span class="math display" id="eq:Quantile">\[\begin{equation}
F(q_F-) \le q \le F(q_F)
\tag{5.1}
\end{equation}\]</span>
<p>Here, the notation <span class="math inline">\(F(x-)\)</span> means to evaluate the function <span class="math inline">\(F(\cdot)\)</span> as
a left-hand limit.</p>
<p>To get a better understanding of this definition, let us look at a few
special cases. First, consider the case where <span class="math inline">\(X\)</span> is a continuous random
variable so that the distribution function <span class="math inline">\(F(\cdot)\)</span> has no jump
points, as illustrated in Figure <a href="ChapModelSelection.html#fig:Quantile1">5.2</a>. In this figure, a
few fractions, <span class="math inline">\(q_1\)</span>, <span class="math inline">\(q_2\)</span>, and <span class="math inline">\(q_3\)</span> are shown with their
corresponding quantiles <span class="math inline">\(q_{F,1}\)</span>, <span class="math inline">\(q_{F,2}\)</span>, and <span class="math inline">\(q_{F,3}\)</span>. In each
case, it can be seen that <span class="math inline">\(F(q_F-)= F(q_F)\)</span> so that there is a unique
quantile. Because we can find a unique inverse of the distribution
function at any <span class="math inline">\(0&lt;q&lt;1\)</span>, we can write <span class="math inline">\(q_F= F^{-1}(q)\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Quantile1"></span>
<img src="LossDataAnalytics_files/figure-html/Quantile1-1.png" alt="Continuous Quantile Case" width="60%" />
<p class="caption">
Figure 5.2: <strong>Continuous Quantile Case</strong>
</p>
</div>
<p>Figure <a href="ChapModelSelection.html#fig:Quantile2">5.3</a> shows three cases for distribution
functions. The left panel corresponds to the continuous case just
discussed. The middle panel displays a jump point similar to those we
already saw in the empirical distribution function of Figure
<a href="ChapModelSelection.html#fig:EDFToy">5.1</a>. For the value of <span class="math inline">\(q\)</span> shown in this panel, we still
have a unique value of the quantile <span class="math inline">\(q_F\)</span>. Even though there are many
values of <span class="math inline">\(q\)</span> such that <span class="math inline">\(F(q_F-) \le q \le F(q_F)\)</span>, for a particular
value of <span class="math inline">\(q\)</span>, there is only one solution to equation <a href="ChapModelSelection.html#eq:Quantile">(5.1)</a>.
The right panel depicts a situation in which the quantile cannot be
uniquely determined for the <span class="math inline">\(q\)</span> shown as there is a range of <span class="math inline">\(q_F\)</span>s
satisfying equation <a href="ChapModelSelection.html#eq:Quantile">(5.1)</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Quantile2"></span>
<img src="LossDataAnalytics_files/figure-html/Quantile2-1.png" alt="Three Quantile Cases" width="90%" />
<p class="caption">
Figure 5.3: <strong>Three Quantile Cases</strong>
</p>
</div>
<hr />
<p><strong>Example 5.1.2. Toy Dataset: Continued.</strong> Determine quantiles
corresponding to the 20th, 50th, and 95th percentiles.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.2" href="javascript:toggleEX('toggleExample.5.1.2','displayExample.5.1.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.2" style="display: none">
<p><strong>Solution</strong>. Consider Figure <a href="ChapModelSelection.html#fig:EDFToy">5.1</a>. The case of <span class="math inline">\(q=0.20\)</span>
corresponds to the middle panel of Figure Figure <a href="ChapModelSelection.html#fig:Quantile2">5.3</a>,
so the 20th percentile is 15. The case of <span class="math inline">\(q=0.50\)</span> corresponds to the
right panel, so the median is any number between 20 and 23 inclusive.
Many software packages use the average 21.5 (e.g.<code>R</code>, as seen below).
For the 95th percentile, the solution is 30. We can see from Figure
<a href="ChapModelSelection.html#fig:EDFToy">5.1</a> that 30 also corresponds to the 99th and the 99.99th
percentiles.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="ChapModelSelection.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(xExample, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>), <span class="at">type =</span> <span class="dv">6</span>)</span></code></pre></div>
<pre><code> 20%  50%  95% 
15.0 21.5 30.0 </code></pre>
</div>
<hr />
<p>By taking a weighted average between data observations, smoothed
empirical quantiles can handle cases such as the right panel in Figure
<a href="ChapModelSelection.html#fig:Quantile2">5.3</a>. The <span class="math inline">\(q\)</span>th <a href="#" class="tooltip" style="color:green"><em>smoothed empirical quantile</em><span style="font-size:8pt">A quantile obtained by linear interpolation between two empirical quantiles, i.e.data points.</span></a>
is defined as <span class="math display">\[
\hat{\pi}_q = (1-h) X_{(j)} + h X_{(j+1)}
\]</span> where <span class="math inline">\(j=\lfloor(n+1)q\rfloor\)</span>, <span class="math inline">\(h=(n+1)q-j\)</span>, and
<span class="math inline">\(X_{(1)}, \ldots, X_{(n)}\)</span> are the ordered values (known as the <em>order
statistics</em>) corresponding to <span class="math inline">\(X_1, \ldots, X_n\)</span>. (Recall that the
brackets <span class="math inline">\(\lfloor \cdot\rfloor\)</span> are the floor function denoting the
greatest integer value.) Note that <span class="math inline">\(\hat{\pi}_q\)</span> is simply a linear
interpolation between <span class="math inline">\(X_{(j)}\)</span> and <span class="math inline">\(X_{(j+1)}\)</span>.</p>
<p><strong>Example 5.1.3. Toy Dataset: Continued.</strong> Determine the 50th and 20th
smoothed percentiles.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.3" href="javascript:toggleEX('toggleExample.5.1.3','displayExample.5.1.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.3" style="display: none">
<p><strong>Solution</strong> Take <span class="math inline">\(n=10\)</span> and <span class="math inline">\(q=0.5\)</span>. Then,
<span class="math inline">\(j=\lfloor(11)(0.5) \rfloor= \lfloor 5.5 \rfloor=5\)</span> and
<span class="math inline">\(h=(11)(0.5)-5=0.5\)</span>. Then the 0.5-th smoothed empirical quantile is
<span class="math display">\[\hat{\pi}_{0.5} = (1-0.5) X_{(5)} + (0.5) X_{(6)} = 0.5 (20) + (0.5)(23) = 21.5.\]</span>
Now take <span class="math inline">\(n=10\)</span> and <span class="math inline">\(q=0.2\)</span>. In this case,
<span class="math inline">\(j=\lfloor(11)(0.2)\rfloor=\lfloor 2.2 \rfloor=2\)</span> and
<span class="math inline">\(h=(11)(0.2)-2=0.2\)</span>. Then the 0.2-th smoothed empirical quantile is
<span class="math display">\[\hat{\pi}_{0.2} = (1-0.2) X_{(2)} + (0.2) X_{(3)} = 0.8 (15) + (0.2)(15) = 15.\]</span></p>
</div>
<hr />
</div>
<div id="S:MS:Density" class="section level4 hasAnchor" number="5.1.1.4">
<h4><span class="header-section-number">5.1.1.4</span> Density Estimators<a href="ChapModelSelection.html#S:MS:Density" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Discrete Variable.</strong> When the random variable is discrete, estimating
the probability mass function <span class="math inline">\(f(x) = \Pr(X=x)\)</span> is straightforward. We
simply use the sample average, defined to be</p>
<p><span class="math display">\[
f_n(x) = \frac{1}{n} \sum_{i=1}^n I(X_i = x),
\]</span></p>
<p>which is the proportion of the sample equal to <span class="math inline">\(x\)</span>.</p>
<p><strong>Continuous Variable within a Group.</strong> For a continuous random
variable, consider a discretized formulation in which the domain of
<span class="math inline">\(F(\cdot)\)</span> is partitioned by constants <span class="math inline">\(\{c_0 &lt; c_1 &lt; \cdots &lt; c_k\}\)</span>
into intervals of the form <span class="math inline">\([c_{j-1}, c_j)\)</span>, for <span class="math inline">\(j=1, \ldots, k\)</span>. The
data observations are thus grouped by the intervals into which they
fall. Then, we might use the basic definition of the empirical mass
function, or a variation such as
<span class="math display">\[f_n(x) = \frac{n_j}{n \times (c_j - c_{j-1})}  \ \ \ \ \ \ c_{j-1} \le x &lt; c_j,\]</span>
where <span class="math inline">\(n_j\)</span> is the number of observations (<span class="math inline">\(X_i\)</span>) that fall into the
interval <span class="math inline">\([c_{j-1}, c_j)\)</span>.</p>
<p><strong>Continuous Variable (not grouped).</strong> Extending this notion to
instances where we observe individual data, note that we can always
create arbitrary groupings and use this formula. More formally, let
<span class="math inline">\(b&gt;0\)</span> be a small positive constant, known as a <a href="#" class="tooltip" style="color:green"><em>bandwidth</em><span style="font-size:8pt">A small positive constant that defines the width of the steps and the degree of smoothing.</span></a>,
and define a density estimator to be</p>
<span class="math display" id="eq:KDF">\[\begin{equation}
f_n(x) = \frac{1}{2nb} \sum_{i=1}^n I(x-b &lt; X_i \le x + b)
\tag{5.2}
\end{equation}\]</span>
<h5 style="text-align: center;">
<a id="displayTheory.kernel.1" href="javascript:toggleTheory('toggleTheory.kernel.1','displayCode.kernel.1');"><i><strong>Show A Snippet of Theory</strong></i></a>
</h5>
<div id="toggleTheory.kernel.1" style="display: none">
<hr />
<p><strong>Snippet of Theory.</strong> The idea is that the estimator <span class="math inline">\(f_n(x)\)</span> in
equation <a href="ChapModelSelection.html#eq:KDF">(5.2)</a> is the average over <span class="math inline">\(n\)</span> <em>iid</em> realizations of a
random variable with mean</p>
<p><span class="math display">\[
\begin{aligned}
\mathrm{E~ } \left[\frac{1}{2b} I(x-b &lt; X \le x + b)\right] &amp;=  \frac{1}{2b}\left(F(x+b)-F(x-b)\right) \\
&amp; \rightarrow  F^{\prime}(x) = f(x),
\end{aligned}
\]</span></p>
<p>as <span class="math inline">\(b\rightarrow 0\)</span>. That is, <span class="math inline">\(f_n(x)\)</span> is an
<a href="#" class="tooltip" style="color:green"><em>asymptotically unbiased</em><span style="font-size:8pt"></span></a> estimator of <span class="math inline">\(f(x)\)</span> (its
expectation approaches the true value as sample size increases to
infinity). This development assumes some smoothness of <span class="math inline">\(F(\cdot)\)</span>, in
particular, twice differentiability at <span class="math inline">\(x\)</span>, but makes no assumptions on
the form of the distribution function <span class="math inline">\(F\)</span>. Because of this, the density
estimator <span class="math inline">\(f_n\)</span> is said to be <em>nonparametric</em>.</p>
<hr />
</div>
<p>More generally, define the <a href="#" class="tooltip" style="color:green"><em>kernel density estimator</em><span style="font-size:8pt">A nonparametric estimator of the density function of a random variable.</span></a> of the
<a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt">Probability density function</span></a> at <span class="math inline">\(x\)</span> as</p>
<span class="math display" id="eq:kernelDens">\[\begin{equation}
f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right) ,
\tag{5.3}
\end{equation}\]</span>
<p>where <span class="math inline">\(w\)</span> is a probability density function centered about 0. Note that
equation <a href="ChapModelSelection.html#eq:KDF">(5.2)</a> is a special case of the kernel density estimator
where <span class="math inline">\(w(x) = \frac{1}{2}I(-1 &lt; x \le 1)\)</span>, also known as the <em>uniform
kernel</em>. Other popular choices are shown in <a href="#tab:5.1">Table 5.1</a>.</p>
<p><a id=tab:5.1></a></p>
<p>Table 5.1. <strong>Popular Kernel Choices</strong></p>
<p><span class="math display">\[
{\small
\begin{matrix}
\begin{array}{l|cc}
\hline
\text{Kernel} &amp;  w(x) \\
\hline
\text{Uniform } &amp;  \frac{1}{2}I(-1 &lt; x \le 1) \\
\text{Triangle} &amp;  (1-|x|)\times I(|x| \le 1) \\
\text{Epanechnikov} &amp; \frac{3}{4}(1-x^2) \times I(|x| \le 1) \\
\text{Gaussian} &amp; \phi(x) \\
\hline
\end{array}\end{matrix}
}
\]</span></p>
<p>Here, <span class="math inline">\(\phi(\cdot)\)</span> is the standard normal density function. As we will
see in the following example, the choice of bandwidth <span class="math inline">\(b\)</span> comes with a
<a href="#" class="tooltip" style="color:green"><em>bias-variance tradeoff</em><span style="font-size:8pt">The tradeoff between model simplicity (underfitting; high bias) and flexibility (overfitting; high variance).</span></a> between matching local
distributional features and reducing the volatility.</p>
<hr />
<p><strong>Example 5.1.4. Property Fund.</strong> Figure <a href="ChapModelSelection.html#fig:Density2">5.4</a> shows a
histogram (with shaded gray rectangles) of logarithmic property claims
from 2010. The (blue) thick curve represents a Gaussian kernel density
where the bandwidth was selected automatically using an ad hoc rule
based on the sample size and volatility of these data. For this dataset,
the bandwidth turned out to be <span class="math inline">\(b=0.3255\)</span>. For comparison, the (red)
dashed curve represents the density estimator with a bandwidth equal to
0.1 and the green smooth curve uses a bandwidth of 1. As anticipated,
the smaller bandwidth (0.1) indicates taking local averages over less
data so that we get a better idea of the local average, but at the price
of higher volatility. In contrast, the larger bandwidth (1) smooths out
local fluctuations, yielding a smoother curve that may miss
perturbations in the local average. For actuarial applications, we
mainly use the kernel density estimator to get a quick visual impression
of the data. From this perspective, you can simply use the default ad
hoc rule for bandwidth selection, knowing that you have the ability to
change it depending on the situation at hand.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Density2"></span>
<img src="LossDataAnalytics_files/figure-html/Density2-1.png" alt="Histogram of Logarithmic Property Claims with Superimposed Kernel Density Estimators" width="70%" />
<p class="caption">
Figure 5.4: <strong>Histogram of Logarithmic Property Claims with Superimposed Kernel Density Estimators</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.kpdf" href="javascript:togglecode('toggleCode.kpdf','displayCode.kpdf');"><i><strong>Show R Code</strong></i></a>
</h5>
<div id="toggleCode.kpdf" style="display: none">
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="ChapModelSelection.html#cb43-1" aria-hidden="true" tabindex="-1"></a>ClaimLev <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Data/CLAIMLEVEL.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>); <span class="co">#nrow(ClaimLev); # 6258</span></span>
<span id="cb43-2"><a href="ChapModelSelection.html#cb43-2" aria-hidden="true" tabindex="-1"></a>ClaimData<span class="ot">&lt;-</span><span class="fu">subset</span>(ClaimLev,Year<span class="sc">==</span><span class="dv">2010</span>);     <span class="co">#2010 subset</span></span>
<span id="cb43-3"><a href="ChapModelSelection.html#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Density Comparison</span></span>
<span id="cb43-4"><a href="ChapModelSelection.html#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,.<span class="dv">35</span>),<span class="at">xlab=</span><span class="st">&quot;Log Expenditures&quot;</span>, <span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">col=</span><span class="st">&quot;lightgray&quot;</span>)</span>
<span id="cb43-5"><a href="ChapModelSelection.html#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim)), <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lwd=</span><span class="fl">2.5</span>)</span>
<span id="cb43-6"><a href="ChapModelSelection.html#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">bw=</span><span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb43-7"><a href="ChapModelSelection.html#cb43-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">bw=</span>.<span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;red&quot;</span>, <span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb43-8"><a href="ChapModelSelection.html#cb43-8" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;b=0.3255 (default)&quot;</span>, <span class="st">&quot;b=0.1&quot;</span>, <span class="st">&quot;b=1.0&quot;</span>), <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>), <span class="at">lwd=</span><span class="fu">c</span>(<span class="fl">2.5</span>,<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb43-9"><a href="ChapModelSelection.html#cb43-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>), <span class="at">cex=</span><span class="dv">1</span>)</span>
<span id="cb43-10"><a href="ChapModelSelection.html#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co">#density(log(ClaimData$Claim))$bw   ##default bandwidth</span></span></code></pre></div>
</div>
<hr />
<p>Nonparametric density estimators, such as the kernel estimator, are
regularly used in practice. The concept can also be extended to give
smooth versions of an empirical distribution function. Given the
definition of the kernel density estimator, the <em>kernel estimator of the
distribution function</em> can be found as</p>
<p><span class="math display">\[
\begin{aligned}
\tilde{F}_n(x) = \frac{1}{n} \sum_{i=1}^n W\left(\frac{x-X_i}{b}\right).\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(W\)</span> is the distribution function associated with the kernel
density <span class="math inline">\(w\)</span>. To illustrate, for the uniform kernel, we have
<span class="math inline">\(w(y) = \frac{1}{2}I(-1 &lt; y \le 1)\)</span>, so</p>
<p><span class="math display">\[
\begin{aligned}
W(y) =
\begin{cases}
0 &amp;            y&lt;-1\\
\frac{y+1}{2}&amp; -1 \le y &lt; 1 \\
1 &amp; y \ge 1 \\
\end{cases}\end{aligned} .
\]</span></p>
<hr />
<p><strong>Example 5.1.5. Actuarial Exam Question.</strong></p>
<p>You study five lives to estimate the time from the onset of a disease to
death. The times to death are:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
2 &amp; 3 &amp; 3 &amp; 3 &amp; 7  \\
\end{array}
\]</span></p>
<p>Using a triangular kernel with bandwidth <span class="math inline">\(2\)</span>, calculate the density
function estimate at 2.5.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.5" href="javascript:toggleEX('toggleExample.5.1.5','displayExample.5.1.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.5" style="display: none">
<p><strong>Solution.</strong> For the kernel density estimate, we have
<span class="math display">\[f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right),\]</span>
where <span class="math inline">\(n=5\)</span>, <span class="math inline">\(b=2\)</span>, and <span class="math inline">\(x=2.5\)</span>. For the triangular kernel,
<span class="math inline">\(w(x) = (1-|x|)\times I(|x| \le 1)\)</span>. Thus,</p>
<p><span class="math display">\[
\begin{array}{c|c|c}
\hline
X_i &amp; \frac{x-X_i}{b} &amp; w\left(\frac{x-X_i}{b} \right) \\
\hline
2 &amp; \frac{2.5-2}{2}=\frac{1}{4} &amp;  (1-\frac{1}{4})(1) = \frac{3}{4} \\
\hline
3 &amp; &amp; \\
3 &amp; \frac{2.5-3}{2}=\frac{-1}{4} &amp; \left(1-\left| \frac{-1}{4} \right| \right)(1) = \frac{3}{4} \\
3 &amp; &amp; \\
\hline
7 &amp; \frac{2.5-7}{2}=-2.25 &amp; (1-|-2.25|)(0) = 0\\
\hline
\end{array}
\]</span></p>
<p>Then the kernel density estimate at <span class="math inline">\(x=2.5\)</span> is
<span class="math display">\[f_n(2.5) = \frac{1}{5(2)}\left( \frac{3}{4} + (3) \frac{3}{4} + 0 \right) = \frac{3}{10}\]</span></p>
</div>
<hr />
</div>
<div id="S:MS:PlugIn" class="section level4 hasAnchor" number="5.1.1.5">
<h4><span class="header-section-number">5.1.1.5</span> Plug-in Principle<a href="ChapModelSelection.html#S:MS:PlugIn" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>One way to create a nonparametric estimator of some quantity is to use
the <em>analog</em> or <a href="#" class="tooltip" style="color:green"><em>plug-in principle</em><span style="font-size:8pt">The plug-in principle or analog principle of estimation proposes that population parameters be estimated by sample statistics which have the same property in the sample as the parameters do in the population.</span></a> where one replaces the
unknown <a href="#" class="tooltip" style="color:green"><em>cdf</em><span style="font-size:8pt">Cumulative distribution function</span></a> <span class="math inline">\(F\)</span> with a known estimate such as the empirical
<em>cdf</em> <span class="math inline">\(F_n\)</span>. So, if we are trying to estimate
<span class="math inline">\(\mathrm{E}~[\mathrm{g}(X)]=\mathrm{E}_F~[\mathrm{g}(X)]\)</span> for a generic
function <em>g</em>, then we define a nonparametric estimator to be
<span class="math inline">\(\mathrm{E}_{F_n}~[\mathrm{g}(X)]=n^{-1}\sum_{i=1}^n \mathrm{g}(X_i)\)</span>.</p>
<p>To see how this works, as a special case of <em>g</em> we consider the loss per
payment random variable is <span class="math inline">\(Y = (X-d)_+\)</span> and the <em>loss elimination ratio
(LER)</em> introduced in Section <a href="ChapSeverity.html#S:PolicyDeduct">4.4.1</a>. We can express this
as <span class="math display">\[
LER(d) = \frac{\mathrm{E~}[X - (X-d)_+]}{\mathrm{E~}[X]} =\frac{\mathrm{E~}[\min(X,d)]}{\mathrm{E~}[X]} ,
\]</span> for a fixed deductible <span class="math inline">\(d\)</span>.</p>
<p><strong>Example 5.1.6. Bodily Injury Claims and Loss Elimination Ratios</strong></p>
<p>We use a sample of 432 closed auto claims from Boston from
<span class="citation">Derrig, Ostaszewski, and Rempala (<a href="#ref-derrig2001applications" role="doc-biblioref">2001</a>)</span>. Losses are recorded for payments due to bodily
injuries in auto accidents. Losses are not subject to deductibles but
are limited by various maximum coverage amounts that are also available
in the data. It turns out that only 17 out of
432 (<span class="math inline">\(\approx\)</span>
4%) were
subject to these policy limits and so we ignore these data for this
illustration.</p>
<p>The average loss paid is 6906 in U.S. dollars.
Figure <a href="ChapModelSelection.html#fig:BIClaims">5.5</a> shows other aspects of the distribution.
Specifically, the left-hand panel shows the empirical distribution
function, the right-hand panel gives a nonparametric density plot.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:BIClaims"></span>
<img src="LossDataAnalytics_files/figure-html/BIClaims-1.png" alt="Bodily Injury Claims. The left-hand panel gives the empirical distribution function. The right-hand panel presents a nonparametric density plot." width="672" />
<p class="caption">
Figure 5.5: <strong>Bodily Injury Claims. The left-hand panel gives the empirical distribution function. The right-hand panel presents a nonparametric density plot.</strong>
</p>
</div>
<p>The impact of bodily injury losses can be mitigated by the imposition of
limits or purchasing reinsurance policies (see Section 10.3). To
quantify the impact of these risk mitigation tools, it is common to
compute the <em>loss elimination ratio (LER)</em> as introduced in Section
<a href="ChapSeverity.html#S:PolicyDeduct">4.4.1</a>. The distribution function is not available and so
must be estimated in some way. Using the plug-in principle, a
nonparametric estimator can be defined as</p>
<p><span class="math display">\[
LER_n(d) = \frac{n^{-1} \sum_{i=1}^n \min(X_i,d)}{n^{-1} \sum_{i=1}^n X_i} = \frac{\sum_{i=1}^n \min(X_i,d)}{\sum_{i=1}^n X_i} .
\]</span></p>
<p>Figure <a href="ChapModelSelection.html#fig:LER">5.6</a> shows the estimator <span class="math inline">\(LER_n(d)\)</span> for various choices
of <span class="math inline">\(d\)</span>. For example, at <span class="math inline">\(d=1,000\)</span>, we have <span class="math inline">\(LER_n(1000) \approx\)</span>
0.1442. Thus, imposing a limit of 1,000 means
that expected retained claims are 14.42
percent lower when compared to expected claims with a zero deductible.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:LER"></span>
<img src="LossDataAnalytics_files/figure-html/LER-1.png" alt="LER for Bodily Injury Claims. The figure presents the loss elimination ratio (LER) as a function of deductible \(d\)." width="672" />
<p class="caption">
Figure 5.6: <strong>LER for Bodily Injury Claims. The figure presents the loss elimination ratio (LER) as a function of deductible <span class="math inline">\(d\)</span>.</strong>
</p>
</div>
</div>
</div>
<div id="starting-values" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Starting Values<a href="ChapModelSelection.html#starting-values" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The method of moments and percentile matching are nonparametric
estimation methods that provide alternatives to maximum likelihood.
Generally, maximum likelihood is the preferred technique because it
employs data more efficiently. (See Appendix Chapter <a href="CAppC.html#CAppC">18</a> for
precise definitions of efficiency.) However, methods of moments and
percentile matching are useful because they are easier to interpret and
therefore allow the actuary or analyst to explain procedures to others.
Additionally, the numerical estimation procedure (e.g.if performed in
<code>R</code>) for the maximum likelihood is iterative and requires starting
values to begin the recursive process. Although many problems are robust
to the choice of the starting values, for some complex situations, it
can be important to have a starting value that is close to the (unknown)
optimal value. Method of moments and percentile matching are techniques
that can produce desirable estimates without a serious computational
investment and can thus be used as a <em>starting value</em> for computing
maximum likelihood.</p>
<div id="method-of-moments" class="section level4 hasAnchor" number="5.1.2.1">
<h4><span class="header-section-number">5.1.2.1</span> Method of Moments<a href="ChapModelSelection.html#method-of-moments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Under the <a href="#" class="tooltip" style="color:green"><em>method of moments</em><span style="font-size:8pt">The estimation of population parameters by approximating parametric moments using empirical sample moments.</span></a>, we approximate the moments of
the parametric distribution using the empirical (nonparametric) moments
described in Section <a href="ChapModelSelection.html#S:MS:MomentEstimator">5.1.1.1</a>. We can then
algebraically solve for the parameter estimates.</p>
<hr />
<p><strong>Example 5.1.7. Property Fund.</strong> For the 2010 property fund, there are
<span class="math inline">\(n=1,377\)</span> individual claims (in thousands of dollars) with</p>
<p><span class="math display">\[m_1 = \frac{1}{n} \sum_{i=1}^n X_i = 26.62259 \ \ \ \
\text{and} \ \ \ \
m_2 = \frac{1}{n} \sum_{i=1}^n X_i^2 = 136154.6 .\]</span> Fit the parameters
of the gamma and Pareto distributions using the method of moments.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.7" href="javascript:toggleEX('toggleExample.5.1.7','displayExample.5.1.7');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.7" style="display: none">
<p><strong>Solution.</strong> To fit a gamma distribution, we have
<span class="math inline">\(\mu_1 = \alpha \theta\)</span> and
<span class="math inline">\(\mu_2^{\prime} = \alpha(\alpha+1) \theta^2\)</span>. Equating the two yields
the method of moments estimators, easy algebra shows that</p>
<p><span class="math display">\[\alpha = \frac{\mu_1^2}{\mu_2^{\prime}-\mu_1^2}  \ \ \ \text{and} \ \ \  \theta = \frac{\mu_2^{\prime}-\mu_1^2}{\mu_1}.\]</span></p>
<p>Thus, the method of moment estimators are</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\alpha} &amp;=  \frac{26.62259^2}{136154.6-26.62259^2} = 0.005232809 \\
\hat{\theta} &amp;=  \frac{136154.6-26.62259^2}{26.62259} = 5,087.629.
\end{aligned}
\]</span></p>
<p>For comparison, the maximum likelihood values turn out to be
<span class="math inline">\(\hat{\alpha}_{MLE} = 0.2905959\)</span> and <span class="math inline">\(\hat{\theta}_{MLE} = 91.61378\)</span>, so
there are big discrepancies between the two estimation procedures. This
is one indication, as we have seen before, that the gamma model fits
poorly.</p>
<p>In contrast, now assume a Pareto distribution so that
<span class="math inline">\(\mu_1 = \theta/(\alpha -1)\)</span> and
<span class="math inline">\(\mu_2^{\prime} = 2\theta^2/((\alpha-1)(\alpha-2) )\)</span>. Note that this
expression for <span class="math inline">\(\mu_2^{\prime}\)</span> is only valid for <span class="math inline">\(\alpha&gt;2\)</span>. Easy
algebra shows</p>
<p><span class="math display">\[\alpha = 1+ \frac{\mu_2^{\prime}}{\mu_2^{\prime}-\mu_1^2} \ \ \ \
\text{and} \ \ \ \ \
\theta = (\alpha-1)\mu_1.\]</span></p>
<p>Thus, the method of moment estimators are</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\alpha} &amp;=  1+ \frac{136154.6}{136154.6-26,62259^2} = 2.005233 \\
\hat{\theta} &amp;=  (2.005233-1) \cdot 26.62259 = 26.7619
\end{aligned}
\]</span></p>
<p>The maximum likelihood values turn out to be
<span class="math inline">\(\hat{\alpha}_{MLE} = 0.9990936\)</span> and <span class="math inline">\(\hat{\theta}_{MLE} = 2.2821147\)</span>.
It is interesting that <span class="math inline">\(\hat{\alpha}_{MLE}&lt;1\)</span>; for the Pareto
distribution, recall that <span class="math inline">\(\alpha &lt;1\)</span> means that the mean is infinite.
This is another indication that the property claims dataset is a long
tail distribution.</p>
</div>
<hr />
<p>As the above example suggests, there is flexibility with the method of
moments. For example, we could have matched the second and third moments
instead of the first and second, yielding different estimators.
Furthermore, there is no guarantee that a solution will exist for each
problem. For data that are censored or truncated, matching moments is
possible for a few problems but, in general, this is a more difficult
scenario. Finally, for distributions where the moments do not exist or
are infinite, method of moments is not available. As an alternative, one
can use the percentile matching technique.</p>
</div>
<div id="percentile-matching" class="section level4 hasAnchor" number="5.1.2.2">
<h4><span class="header-section-number">5.1.2.2</span> Percentile Matching<a href="ChapModelSelection.html#percentile-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Under <a href="#" class="tooltip" style="color:green"><em>percentile matching</em><span style="font-size:8pt">The estimation of population parameters by approximating parametric percentiles using empirical quantiles.</span></a>, we approximate the quantiles or
percentiles of the parametric distribution using the empirical
(nonparametric) quantiles or percentiles described in Section
<a href="ChapModelSelection.html#S:MS:QuantileEstimator">5.1.1.3</a>.</p>
<hr />
<p><strong>Example 5.1.8. Property Fund.</strong> For the 2010 property fund, we
illustrate matching on quantiles. In particular, the Pareto distribution
is intuitively pleasing because of the closed-form solution for the
quantiles. Recall that the distribution function for the Pareto
distribution is
<span class="math display">\[F(x) = 1 - \left(\frac{\theta}{x+\theta}\right)^{\alpha}.\]</span> Easy
algebra shows that we can express the quantile as</p>
<p><span class="math display">\[F^{-1}(q) = \theta \left( (1-q)^{-1/\alpha} -1 \right).\]</span> for a
fraction <span class="math inline">\(q\)</span>, <span class="math inline">\(0&lt;q&lt;1\)</span>.</p>
<p>Determine estimates of the Pareto distribution parameters using the 25th
and 95th empirical quantiles.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.8" href="javascript:toggleEX('toggleExample.5.1.8','displayExample.5.1.8');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.8" style="display: none">
<p><strong>Solution.</strong></p>
<p>The 25th percentile (the first quartile) turns out to be <span class="math inline">\(0.78853\)</span> and
the 95th percentile is <span class="math inline">\(50.98293\)</span> (both in thousands of dollars). With
two equations
<span class="math display">\[0.78853 = \theta \left( 1- (1-.25)^{-1/\alpha} \right) \ \ \ \ \text{and} \ \ \ \ 50.98293 = \theta \left( 1- (1-.75)^{-1/\alpha} \right)\]</span>
and two unknowns, the solution is
<span class="math display">\[\hat{\alpha} = 0.9412076 \ \ \ \ \ \text{and} \ \ \ \
\hat{\theta} = 2.205617 .\]</span> We remark here that a numerical routine is
required for these solutions as no analytic solution is available.
Furthermore, recall that the <a href="#" class="tooltip" style="color:green"><em>maximum likelihood estimates</em><span style="font-size:8pt"></span></a>
are <span class="math inline">\(\hat{\alpha}_{MLE} = 0.9990936\)</span> and
<span class="math inline">\(\hat{\theta}_{MLE} = 2.2821147\)</span>, so the percentile matching provides a
better approximation for the Pareto distribution than the method of
moments.</p>
</div>
<hr />
<p><strong>Example 5.1.9. Actuarial Exam Question.</strong> You are given:</p>
<ol style="list-style-type: lower-roman">
<li>Losses follow a loglogistic distribution with cumulative
distribution function:
<span class="math display">\[F(x) = \frac{\left(x/\theta\right)^{\gamma}}{1+\left(x/\theta\right)^{\gamma}}\]</span></li>
<li>The sample of losses is:</li>
</ol>
<p><span class="math display">\[
\begin{array}{ccccccccccc}
10 &amp;35 &amp;80 &amp;86 &amp;90 &amp;120 &amp;158 &amp;180 &amp;200 &amp;210 &amp;1500 \\
\end{array}
\]</span></p>
<p>Calculate the estimate of <span class="math inline">\(\theta\)</span> by percentile matching, using the
40th and 80th empirically smoothed percentile estimates.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.9" href="javascript:toggleEX('toggleExample.5.1.9','displayExample.5.1.9');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.9" style="display: none">
<p><strong>Solution.</strong> With 11 observations, we have
<span class="math inline">\(j=\lfloor(n+1)q\rfloor = \lfloor 12(0.4) \rfloor = \lfloor 4.8\rfloor=4\)</span>
and <span class="math inline">\(h=(n+1)q-j = 12(0.4)-4=0.8\)</span>. By interpolation, the 40th empirically
smoothed percentile estimate is
<span class="math inline">\(\hat{\pi}_{0.4} = (1-h) X_{(j)} + h X_{(j+1)} = 0.2(86)+0.8(90)=89.2\)</span>.</p>
<p>Similarly, for the 80th empirically smoothed percentile estimate, we
have <span class="math inline">\(12(0.8)=9.6\)</span> so the estimate is
<span class="math inline">\(\hat{\pi}_{0.8} = 0.4(200)+0.6(210)=206\)</span>.</p>
<p>Using the loglogistic cumulative distribution, we need to solve the
following two equations for parameters <span class="math inline">\({\hat{\theta}}\)</span> and
<span class="math inline">\({\hat{\gamma}}\)</span>: <span class="math display">\[
0.4=\frac{(89.2/{\hat{\theta}})^{\hat{\gamma}}}{1+(89.2/{\hat{\theta}})^{\hat{\gamma}}} \ \ \ \text{and} \ \ \ \   0.8=\frac{(206/{\hat{\theta}})^{\hat{\gamma}}}{1+(206/{\hat{\theta}})^{\hat{\gamma}}} .
\]</span></p>
<p>Solving for each parenthetical expression gives
<span class="math inline">\(\frac{2}{3}=(89.2/\theta)^{\hat{\gamma}}\)</span> and
<span class="math inline">\(4=(206/{\hat{\theta}})^{\hat{\gamma}}\)</span>. Taking the ratio of the second
equation to the first gives
<span class="math inline">\(6=(206/89.2)^{\hat{\gamma}}\Rightarrow {\hat{\gamma}}=\frac{\log(6)}{\log(206/89.2)} = 2.1407\)</span>.
Then <span class="math inline">\(4^{1/2.1407}=206/{\hat{\theta}} \Rightarrow {\hat{\theta}}=107.8\)</span>.</p>
</div>
<hr />
<p>Like the method of moments, percentile matching is almost too flexible
in the sense that estimators can vary depending on different percentiles
chosen. For example, one actuary may use estimation on the 25th and 95th
percentiles whereas another uses the 20th and 80th percentiles. In
general estimated parameters will differ and there is no compelling
reason to prefer one over the other. Also as with the method of moments,
percentile matching is appealing because it provides a technique that
can be readily applied in selected situations and has an intuitive
basis. Although most actuarial applications use maximum likelihood
estimators, it can be convenient to have alternative approaches such as
method of moments and percentile matching available.</p>
<div id="surveyElement41">

</div>
<div id="surveyResult41">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz41.1" href="javascript:toggleQuiz
('display.Quiz41.2','display.Quiz41.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz41.2" style="display: none">
<p id="Quiz41Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz41.js">
</script>
</div>
</div>
</div>
<div id="S:MS:ModifiedData" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Estimation using Modified Data<a href="ChapModelSelection.html#S:MS:ModifiedData" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Describe grouped, censored, and truncated data</li>
<li>Estimate parametric distributions based on grouped, censored, and
truncated data</li>
<li>Estimate distributions nonparametrically based on grouped, censored,
and truncated data</li>
</ul>
<hr />
<div id="S:MS:ModifiedData1" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Parametric Estimation using Modified Data<a href="ChapModelSelection.html#S:MS:ModifiedData1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Basic theory and many applications are based on <em>individual</em>
observations that are <em>complete</em> and <em>unmodified</em>, as we have seen
in the previous section. Section <a href="ChapSeverity.html#S:MaxLikeEstimation">4.5</a> introduced
the concept of observations that are <em>modified</em> due to two common
types of limitations: <strong>censoring</strong> and <strong>truncation</strong>. For example, it
is common to think about an insurance deductible as producing data that
are truncated (from the left) or policy limits as yielding data that are
censored (from the right). This viewpoint is from the primary insurer
(the seller of the insurance). Another viewpoint is that of a reinsurer
(an insurer of an insurance company) that will be discussed more in
Chapter <a href="ChapPortMgt.html#ChapPortMgt">12</a>. A reinsurer may not observe a claim smaller
than an amount, only that a claim exists; this is an example of
censoring from the left. So, in this section, we cover the full gamut of
alternatives. Following the parametric methods introduced in Appendix
Chapters <a href="CAppA.html#CAppA">16</a> and <a href="CAppC.html#CAppC">18</a> for unmodified data, this section
will address parametric estimation methods for three alternatives to
individual, complete, and unmodified data: <strong>interval-censored</strong> data
available only in groups, data that are limited or <strong>censored</strong>, and
data that may not be observed due to <strong>truncation</strong>.</p>
<div id="S:MS:GroupedData" class="section level4 hasAnchor" number="5.2.1.1">
<h4><span class="header-section-number">5.2.1.1</span> Grouped Data<a href="ChapModelSelection.html#S:MS:GroupedData" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider a sample of size <span class="math inline">\(n\)</span> observed from the distribution <span class="math inline">\(F(\cdot)\)</span>,
but in groups so that we only know the group into which each observation
fell, not the exact value. This is referred to as <strong>grouped</strong> or
<strong>interval-censored</strong> data. For example, we may be looking at two
successive years of annual employee records. People employed in the
first year but not the second have left sometime during the year. With
an exact departure date (individual data), we could compute the amount
of time that they were with the firm, which constitutes the type of
unmodified data required for the maximum likelihood procedure given in
Appendix Chapter <a href="CAppC.html#CAppC">18</a>. Without the departure date (for grouped
data), we only know that they departed sometime during a year-long
interval, for which we may modify the maximum likelihood produre to
accommodate the change in data format.</p>
<p>Formalizing this idea, suppose there are <span class="math inline">\(k\)</span> groups or intervals
delimited by boundaries <span class="math inline">\(c_0 &lt; c_1&lt; \cdots &lt; c_k\)</span>. For each observation,
we only observe the interval into which it fell (e.g.<span class="math inline">\((c_{j-1}, c_j)\)</span>),
not the exact value. Thus, we only know the number of observations in
each interval. The constants <span class="math inline">\(\{c_0 &lt; c_1 &lt; \cdots &lt; c_k\}\)</span> form some
partition of the domain of <span class="math inline">\(F(\cdot)\)</span>. Then the probability of an
observation <span class="math inline">\(X_i\)</span> falling in the <span class="math inline">\(j\)</span>th interval is <span class="math display">\[\Pr\left(X
_i \in (c_{j-1}, c_j]\right) = F(c_j) - F(c_{j-1}).\]</span></p>
<p>The corresponding probability mass function for an observation is</p>
<p><span class="math display">\[
\begin{aligned}
f(x) &amp;=
\begin{cases}
F(c_1) - F(c_{0}) &amp;   \text{if }\ x \in (c_{0}, c_1]\\
\vdots &amp; \vdots \\
F(c_k) - F(c_{k-1}) &amp;   \text{if }\ x \in (c_{k-1}, c_k]\\
\end{cases} \\
&amp;= \prod_{j=1}^k \left\{F(c_j) - F(c_{j-1})\right\}^{I(x \in (c_{j-1}, c_j])}.
\end{aligned}
\]</span></p>
<p>Now, define <span class="math inline">\(n_j\)</span> to be the number of observations that fall in the
<span class="math inline">\(j\)</span>th interval, <span class="math inline">\((c_{j-1}, c_j]\)</span>. According to the defintion from
Appendix Section <a href="CAppC.html#S:AppC:LF">18.1</a>, the <a href="#" class="tooltip" style="color:green"><em>likelihood function</em><span style="font-size:8pt">A function of the likeliness of the parameters in a model, given the observed data.</span></a>
(with respect to the parameter(s) <span class="math inline">\(\theta\)</span>) is</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) = \prod_{j=1}^n f(x_i) = \prod_{j=1}^k \left\{F(c_j) - F(c_{j-1})\right\}^{n_j}.
\end{aligned}
\]</span></p>
<p>And the log-likelihood function is <span class="math display">\[
\begin{aligned}
l(\theta) = \log L(\theta) = \log \prod_{j=1}^n f(x_i) = \sum_{j=1}^k n_j \log \left\{F(c_j) - F(c_{j-1})\right\}.
\end{aligned}
\]</span></p>
<p>Maximizing the likelihood function (or equivalently, maximizing the
log-likelihood function following the procedure in from Appendix Section
<a href="CAppC.html#S:AppC:MLE">18.2</a>) would then produce the maximum likelihood estimators
(MLEs) of parameters for grouped data. Properties of MLEs and the
resulting statistical inference procedures are given in Appendix Chapter
<a href="CAppC.html#CAppC">18</a>.</p>
<p><strong>Example 5.2.1. Actuarial Exam Question.</strong> You are given:</p>
<ol style="list-style-type: lower-roman">
<li>Losses follow an exponential distribution with mean <span class="math inline">\(\theta\)</span>.</li>
<li>A random sample of 20 losses is distributed as follows:</li>
</ol>
<p><span class="math display">\[
{\small
\begin{array}{l|c}
\hline
\text{Loss Range} &amp; \text{Frequency} \\
\hline
[0,1000] &amp; 7 \\
(1000,2000] &amp; 6 \\
(2000,\infty) &amp; 7 \\
\hline
\end{array}
}
\]</span></p>
<p>Calculate the maximum likelihood estimate of <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.2.1" href="javascript:toggleEX('toggleExample.5.2.1','displayExample.5.2.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.2.1" style="display: none">
<p><strong>Solution.</strong> <span class="math display">\[
\begin{aligned}
L(\theta) &amp;= F(1000)^7[F(2000)-F(1000)]^6[1-F(2000)]^7 \\
&amp;= (1-e^{-1000/\theta})^7(e^{-1000/\theta} - e^{-2000/\theta})^6(e^{-2000/\theta})^7 \\
&amp;= (1-p)^7(p-p^2)^6(p^2)^7 \\
&amp;= p^{20}(1-p)^{13}
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(p=e^{-1000/\theta}\)</span>. Maximizing this expression with respect to
<span class="math inline">\(p\)</span> is equivalent to maximizing the likelihood with respect to <span class="math inline">\(\theta\)</span>.
The maximum occurs at <span class="math inline">\(p=\frac{20}{33}\)</span> and so
<span class="math inline">\(\hat{\theta}=\frac{-1000}{\log(20/33)}= 1996.90\)</span>.</p>
</div>
<hr />
</div>
<div id="censored-data" class="section level4 hasAnchor" number="5.2.1.2">
<h4><span class="header-section-number">5.2.1.2</span> Censored Data<a href="ChapModelSelection.html#censored-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Censoring</strong> occurs when we record only a limited value of an
observation. The most common form is <strong>right-censoring</strong>, in which we
record the <em>smaller</em> of the true dependent variable and a censoring
value. Using notation, let <span class="math inline">\(X\)</span> represent an outcome of interest, such as
the loss due to an insured event or time until an event. Let <span class="math inline">\(C_U\)</span>
denote the censoring value. With right-censored observations, we record
<span class="math inline">\(X_U^{\ast}= \min(X, C_U) = X \wedge C_U\)</span>. We also record whether or not
censoring has occurred. Let <span class="math inline">\(\delta_U= I(X \le C_U)\)</span> be a binary
variable that is 0 if censoring occurs and 1 if it does not, that is,
<span class="math inline">\(\delta_U\)</span> indicates whether or not <span class="math inline">\(X\)</span> is uncensored.</p>
<p>For an example that we saw in Section <a href="ChapSeverity.html#S:PolicyLimits">4.4.2</a>, <span class="math inline">\(C_U\)</span> may
represent the upper limit of coverage of an insurance policy (we used
<span class="math inline">\(u\)</span> for the upper limit in that section). The loss may exceed the amount
<span class="math inline">\(C_U\)</span>, but the insurer only has <span class="math inline">\(C_U\)</span> in its records as the amount paid
out and does not have the amount of the actual loss <span class="math inline">\(X\)</span> in its records.</p>
<p>Similarly, with <strong>left-censoring</strong>, we record the <em>larger</em> of a variable
of interest and a censoring variable. If <span class="math inline">\(C_L\)</span> is used to represent the
censoring value, we record <span class="math inline">\(X_L^{\ast}= \max(X, C_L)\)</span> along with the
censoring indicator <span class="math inline">\(\delta_L= I(X &gt; C_L)\)</span>.</p>
<p>As an example, you got a brief introduction to reinsurance (insurance
for insurers) in Section <a href="ChapSeverity.html#S:Chap3Reinsurance">4.4.4</a> and will see more in
Chapter <a href="ChapPortMgt.html#ChapPortMgt">12</a>. Suppose a reinsurer will cover insurer
losses greater than <span class="math inline">\(C_L\)</span>; this means that the reinsurer is responsible
for the excess of <span class="math inline">\(X_L^{\ast}\)</span> over <span class="math inline">\(C_L\)</span>. Using notation, the loss of
the reinsurer is <span class="math inline">\(Y = X_L^{\ast} - C_L\)</span>. To see this, first consider the
case where the policyholder loss <span class="math inline">\(X \le C_L\)</span>. Then, the insurer will pay
the entire claim and <span class="math inline">\(Y =C_L- C_L=0\)</span>, no loss for the reinsurer. For
contrast, if the loss <span class="math inline">\(X &gt; C_L\)</span>, then <span class="math inline">\(Y = X-C_L\)</span> represents the
reinsurers retained claims. Put another way, if a loss occurs, the
reinsurer records the actual amount if it exceeds the limit <span class="math inline">\(C_L\)</span> and
otherwise it only records that it had a loss of <span class="math inline">\(0\)</span>.</p>
</div>
<div id="truncated-data" class="section level4 hasAnchor" number="5.2.1.3">
<h4><span class="header-section-number">5.2.1.3</span> Truncated Data<a href="ChapModelSelection.html#truncated-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Censored observations are recorded for study, although in a limited
form. In contrast, <strong>truncated</strong> outcomes are a type of missing data. An
outcome is potentially truncated when the availability of an observation
depends on the outcome.</p>
<p>In insurance, it is common for observations to be <strong>left-truncated</strong> at
<span class="math inline">\(C_L\)</span> when the amount is <span class="math display">\[
\begin{aligned}
Y &amp;=
\left\{
\begin{array}{cl}
\text{we do not observe }X &amp; X \le C_L \\
X &amp; X &gt; C_L
\end{array}
\right.\end{aligned} .
\]</span></p>
<p>In other words, if <span class="math inline">\(X\)</span> is less than the threshold <span class="math inline">\(C_L\)</span>, then it is not
observed.</p>
<p>For an example we saw in Section <a href="ChapSeverity.html#S:PolicyDeduct">4.4.1</a>, <span class="math inline">\(C_L\)</span> may
represent the deductible of an insurance policy (we used <span class="math inline">\(d\)</span> for the
deductible in that section). If the insured loss is less than the
deductible, then the insurer may not observe or record the loss at all.
If the loss exceeds the deductible, then the excess <span class="math inline">\(X-C_L\)</span> is the claim
that the insurer covers. In Section <a href="ChapSeverity.html#S:PolicyDeduct">4.4.1</a>, we defined
the per payment loss to be <span class="math display">\[
Y^{P} = \left\{ \begin{matrix}
\text{Undefined} &amp; X \le d \\
X - d &amp; X &gt; d
\end{matrix} \right. ,
\]</span> so that if a loss exceeds a deductible, we record the excess amount
<span class="math inline">\(X-d\)</span>. This is very important when considering amounts that the insurer
will pay. However, for estimation purposes of this section, it matters
little if we subtract a known constant such as <span class="math inline">\(C_L=d\)</span>. So, for our
truncated variable <span class="math inline">\(Y\)</span>, we use the simpler convention and do not
subtract <span class="math inline">\(d\)</span>.</p>
<p>Similarly for <strong>right-truncated</strong> data, if <span class="math inline">\(X\)</span> exceeds a threshold
<span class="math inline">\(C_U\)</span>, then it is not observed. In this case, the amount is <span class="math display">\[
\begin{aligned}
Y &amp;=
\left\{
\begin{array}{cl}
X &amp; X \le C_U \\
\text{we do not observe }X &amp; X &gt; C_U.
\end{array}
\right.\end{aligned}
\]</span></p>
<p>Classic examples of truncation from the right include <span class="math inline">\(X\)</span> as a measure
of distance to a star. When the distance exceeds a certain level <span class="math inline">\(C_U\)</span>,
the star is no longer observable.</p>
<p>Figure <a href="ChapModelSelection.html#fig:CensorTrunc">5.7</a> compares truncated and censored
observations. Values of <span class="math inline">\(X\)</span> that are greater than the upper censoring
limit <span class="math inline">\(C_U\)</span> are not observed at all (right-censored), while values of
<span class="math inline">\(X\)</span> that are smaller than the lower truncation limit <span class="math inline">\(C_L\)</span> are
observed, but observed as <span class="math inline">\(C_L\)</span> rather than the actual value of <span class="math inline">\(X\)</span>
(left-truncated).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:CensorTrunc"></span>
<img src="LossDataAnalytics_files/figure-html/CensorTrunc-1.png" alt="Censoring and Truncation" width="60%" />
<p class="caption">
Figure 5.7: <strong>Censoring and Truncation</strong>
</p>
</div>
<hr />
<h5 style="text-align: center;">
<a id="displayExample.Mort.4f" href="javascript:toggleEX('toggleExample.Mort.4f','displayExample.Mort.4f');"><i><strong>Show Mortality Study Example</strong></i></a>
</h5>
<div id="toggleExample.Mort.4f" style="display: none">
<p><strong>Example  Mortality Study.</strong> Suppose that you are conducting a
two-year study of mortality of high-risk subjects, beginning January 1,
2010 and finishing January 1, 2012. Figure <a href="ChapModelSelection.html#fig:Mortality">5.8</a>
graphically portrays the six types of subjects recruited. For each
subject, the beginning of the arrow represents that the subject was
recruited and the arrow end represents the event time where in this
example the event represents death. The arrow represents exposure time.</p>
<p>(ref:Mortality) <strong>Timeline for Several Subjects on Test in a Mortality
Study</strong></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Mortality"></span>
<img src="LossDataAnalytics_files/figure-html/Mortality-1.png" alt="(ref:Mortality)" width="60%" />
<p class="caption">
Figure 5.8: (ref:Mortality)
</p>
</div>
<ul>
<li><strong>Type A - Right-censored.</strong> This subject is alive at the beginning
and the end of the study. Because the time of death is not known by
the end of the study, it is right-censored. Most subjects are Type
<ol style="list-style-type: upper-alpha">
<li></li>
</ol></li>
<li><strong>Type B - Complete</strong> information is available for a type B subject.
The subject is alive at the beginning of the study and the death
occurs within the observation period.</li>
<li><strong>Type C - Right-censored and left-truncated.</strong> A type C subject is
right-censored, in that death occurs after the observation period.
However, the subject entered after the start of the study and is
said to have a <em>delayed entry time</em>. Because the subject would not
have been observed had death occurred before entry, it is
left-truncated.</li>
<li><strong>Type D - Left-truncated.</strong> A type D subject also has delayed
entry. Because death occurs within the observation period, this
subject is not right censored.</li>
<li><strong>Type E - Left-truncated.</strong> A type E subject is not included in the
study because death occurs prior to the observation period.</li>
<li><strong>Type F - Right-truncated.</strong> Similarly, a type F subject is not
included because the entry time occurs after the observation period.</li>
</ul>
</div>
<hr />
<p>To summarize, for outcome <span class="math inline">\(X\)</span> and constants <span class="math inline">\(C_L\)</span> and <span class="math inline">\(C_U\)</span>,</p>
<table>
<colgroup>
<col width="26%" />
<col width="36%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Limitation Type</th>
<th align="center">Limited Variable</th>
<th align="center">Recording Information</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">right censoring</td>
<td align="center"><span class="math inline">\(X_U^{\ast}= \min(X, C_U)\)</span></td>
<td align="center"><span class="math inline">\(\delta_U= I(X \le C_U)\)</span></td>
</tr>
<tr class="even">
<td align="center">left censoring</td>
<td align="center"><span class="math inline">\(X_L^{\ast}= \max(X, C_L)\)</span></td>
<td align="center"><span class="math inline">\(\delta_L= I(X &gt; C_L)\)</span></td>
</tr>
<tr class="odd">
<td align="center">interval censoring</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">right truncation</td>
<td align="center"><span class="math inline">\(X\)</span></td>
<td align="center">observe <span class="math inline">\(X\)</span> if <span class="math inline">\(X \le C_U\)</span></td>
</tr>
<tr class="odd">
<td align="center">left truncation</td>
<td align="center"><span class="math inline">\(X\)</span></td>
<td align="center">observe <span class="math inline">\(X\)</span> if <span class="math inline">\(X &gt; C_L\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="parametric-estimation-using-censored-and-truncated-data" class="section level4 hasAnchor" number="5.2.1.4">
<h4><span class="header-section-number">5.2.1.4</span> Parametric Estimation using Censored and Truncated Data<a href="ChapModelSelection.html#parametric-estimation-using-censored-and-truncated-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Similar to grouped or interval-censored data, we may modify the maximum
likelihood procedure from Appendix Chapter <a href="CAppC.html#CAppC">18</a> for parametric
estimation using censored and/or truncated data.</p>
<p>For simplicity, we assume non-random censoring values and a continuous
outcome <span class="math inline">\(X\)</span>. To begin, consider the case of right-censored data where we
record <span class="math inline">\(X_U^{\ast}= \min(X, C_U)\)</span> and censoring indicator
<span class="math inline">\(\delta= I(X \le C_U)\)</span>. If censoring occurs so that <span class="math inline">\(\delta=0\)</span>, then
<span class="math inline">\(X &gt; C_U\)</span> and the likelihood associated with the observation is
<span class="math inline">\(\Pr(X &gt; C_U) = 1-F(C_U)\)</span>. If censoring does not occur so that
<span class="math inline">\(\delta=1\)</span>, then <span class="math inline">\(X \le C_U\)</span> and the likelihood is <span class="math inline">\(f(x)\)</span>. Summarizing,
we have the likelihood of a single observation as</p>
<p><span class="math display">\[
\begin{aligned}
\left\{
\begin{array}{ll}
1-F(C_U) &amp; \text{if }\delta=0 \\
f(x) &amp; \text{if } \delta = 1
\end{array}
\right. = \left\{ f(x)\right\}^{\delta} \left\{1-F(C_U)\right\}^{1-\delta} .
\end{aligned}
\]</span></p>
<p>The right-hand expression allows us to present the likelihood more
compactly. Now, for an <em>iid</em> sample of size <span class="math inline">\(n\)</span>, the likelihood is</p>
<p><span class="math display">\[
L(\theta) =
\prod_{i=1}^n \left\{ f(x_i)\right\}^{\delta_i} \left\{1-F(C_{Ui})\right\}^{1-\delta_i} = \prod_{\delta_i=1} f(x_i) \prod_{\delta_i=0} \{1-F(C_{Ui})\},
\]</span></p>
<p>with potential censoring times <span class="math inline">\(\{ C_{U1}, \ldots,C_{Un} \}\)</span>. Here, the
notation <span class="math inline">\(\prod_{\delta_i=1}\)</span> means to take the product over
uncensored observations, and similarly for <span class="math inline">\(\prod_{\delta_i=0}\)</span>.</p>
<p>On the other hand, truncated data are handled in maximum likelihood
inference via conditional probabilities. Specifically, we adjust the
likelihood contribution by dividing by the probability that the variable
was observed. To summarize, we have the following contributions to the
likelihood function for six types of outcomes:</p>
<p><span class="math display">\[
{\small
\begin{array}{lc}
\hline
\text{Outcome} &amp; \text{Likelihood Contribution} \\
\hline
\text{exact value} &amp; f(x) \\
\text{right-censoring} &amp; 1-F(C_U) \\
\text{left-censoring} &amp; F(C_L) \\
\text{right-truncation} &amp; f(x)/F(C_U) \\
\text{left-truncation} &amp; f(x)/(1-F(C_L)) \\
\text{interval-censoring} &amp; F(C_U)-F(C_L) \\
\hline
\end{array}
}
\]</span></p>
<p>For known outcomes and censored data, the likelihood is
<span class="math display">\[L(\theta) = \prod_{E} f(x_i) \prod_{R} \{1-F(C_{Ui})\} \prod_{L}
F(C_{Li}) \prod_{I} (F(C_{Ui})-F(C_{Li})),\]</span> where <span class="math inline">\(\prod_{E}\)</span> is the
product over observations with <em>E</em>xact values, and similarly for
<span class="math inline">\(R\)</span>ight-, <span class="math inline">\(L\)</span>eft- <br> and <span class="math inline">\(I\)</span>nterval-censoring.</p>
<p>For right-censored and left-truncated data, the likelihood is
<span class="math display">\[L(\theta) = \prod_{E} \frac{f(x_i)}{1-F(C_{Li})} \prod_{R} \frac{1-F(C_{Ui})}{1-F(C_{Li})},\]</span>
and similarly for other combinations.</p>
<p>With the forms of likelihood functions derived above, we may perform
maximum likelihood estimation and inference based on the distribution
functions and maximum likelihood procedures given respectively in
Appendix Chapters <a href="#CAppD"><strong>??</strong></a> and <a href="CAppC.html#CAppC">18</a>. To get further
insights, consider the following examples.</p>
<hr />
<h5 style="text-align: center;">
<a id="displayExample.Exp.4f" href="javascript:toggleEX('toggleExample.Exp.4f','displayExample.Exp.4f');"><i><strong>Show Special Case - Exponential Distribution</strong></i></a>
</h5>
<div id="toggleExample.Exp.4f" style="display: none">
<p><strong>Special Case: Exponential Distribution.</strong> Consider data that are
right-censored and left-truncated, with random variables <span class="math inline">\(X_i\)</span> that are
exponentially distributed with mean <span class="math inline">\(\theta\)</span>. With these specifications,
recall that <span class="math inline">\(f(x) = \theta^{-1} \exp(-x/\theta)\)</span> and
<span class="math inline">\(F(x) = 1-\exp(-x/\theta)\)</span>.</p>
<p>For this special case, the log-likelihood is</p>
<p><span class="math display">\[
\begin{aligned}
l(\theta) &amp;= \sum_{E} \left\{ \log f(x_i) - \log (1-F(C_{Li})) \right\} + \sum_{R}\left\{ \log (1-F(C_{Ui}))- \log (1-\mathrm{F}(C_{Li})) \right\}\\
&amp;= \sum_{E} (-\log \theta -(x_i-C_{Li})/\theta ) -\sum_{R} (C_{Ui}-C_{Li})/\theta .
\end{aligned}
\]</span></p>
<p>To simplify the notation, define <span class="math inline">\(\delta_i = I(X_i &lt; C_{Ui})\)</span> to be a
binary variable that indicates right-censoring. Let
<span class="math inline">\(X_i^{\ast \ast} = \min(X_i, C_{Ui}) - C_{Li}\)</span> be the amount that the
observed variable exceeds the lower truncation limit. With this, the
log-likelihood is</p>
<span class="math display" id="eq:EXPloglik">\[\begin{equation}
l(\theta) =  - \sum_{i=1}^n \left((1-\delta_i) \log \theta + \frac{x_i^{\ast \ast}}{\theta}\right)
\tag{5.4}
\end{equation}\]</span>
<p>Taking derivatives with respect to the parameter <span class="math inline">\(\theta\)</span> and setting it
equal to zero yields the maximum likelihood estimator</p>
<p><span class="math display">\[
\widehat{\theta}  = \frac{1}{n_u} \sum_{i=1}^n  x_i^{\ast \ast},
\]</span></p>
<p>where <span class="math inline">\(n_u = \sum_i (1-\delta_i)\)</span> is the number of uncensored
observations.</p>
</div>
<hr />
<p><strong>Example 5.2.2. Actuarial Exam Question.</strong> You are given:</p>
<ol style="list-style-type: lower-roman">
<li>A sample of losses is: 600 700 900</li>
<li>No information is available about losses of 500 or less.</li>
<li>Losses are assumed to follow an exponential distribution with mean
<span class="math inline">\(\theta\)</span>.</li>
</ol>
<p>Calculate the maximum likelihood estimate of <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.2.2" href="javascript:toggleEX('toggleExample.5.2.2','displayExample.5.2.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.2.2" style="display: none">
<p><strong>Solution.</strong> These observations are truncated at 500. The contribution
of each observation to the likelihood function is
<span class="math display">\[\frac{f(x)}{1-F(500)} = \frac{\theta^{-1}e^{-x/\theta}}{e^{-500/\theta}}.\]</span></p>
<p>Then the likelihood function is</p>
<p><span class="math display">\[L(\theta)= \frac{\theta^{-1} e^{-600/\theta} \theta^{-1} e^{-700/\theta} \theta^{-1} e^{-900/\theta}}{(e^{-500/\theta})^3} = \theta^{-3}e^{-700/\theta}.\]</span></p>
<p>The log-likelihood is</p>
<p><span class="math display">\[
l(\theta) = \log L(\theta) = -3 \log \theta - 700 \theta^{-1}.
\]</span></p>
<p>Maximizing this expression by setting the derivative with respect to
<span class="math inline">\(\theta\)</span> equal to 0, we have</p>
<p><span class="math display">\[
L&#39;(\theta) = -3 \theta^{-1} + 700 \theta^{-2} = 0 \ \Rightarrow \ \hat{\theta} = \frac{700}{3} = 233.33 .
\]</span></p>
</div>
<hr />
<p><strong>Example 5.2.3. Actuarial Exam Question.</strong> You are given the following
information about a random sample:</p>
<ol style="list-style-type: lower-roman">
<li>The sample size equals five.</li>
<li>The sample is from a Weibull distribution with <span class="math inline">\(\tau=2\)</span>.</li>
<li>Two of the sample observations are known to exceed 50, and the
remaining three observations are 20, 30, and 45.</li>
</ol>
<p>Calculate the maximum likelihood estimate of <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.2.3" href="javascript:toggleEX('toggleExample.5.2.3','displayExample.5.2.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.2.3" style="display: none">
<p><strong>Solution.</strong> The likelihood function is</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) &amp;= f(20) f(30) f(45) [1-F(50)]^2 \\
&amp;= \frac{2(20/\theta)^2 e^{-(20/\theta)^2}}{20} \frac{2(30/\theta)^2 e^{-(30/\theta)^2}}{30} \frac{2(45/\theta)^2 e^{-(45/\theta)^2}}{45}(e^{-(50/\theta)^2})^2 \\
&amp;\propto \frac{1}{\theta^6} e^{-8325/\theta^2}.
\end{aligned}
\]</span></p>
<p>The natural logarithm of the above expression is
<span class="math inline">\(-6\log\theta - \frac{8325}{\theta^2}\)</span>. Maximizing this expression by
setting its derivative to 0, we get</p>
<p><span class="math display">\[\frac{-6}{\theta} + \frac{16650}{\theta^3} = 0 \ \Rightarrow \ \hat{\theta} = \left(\frac{16650}{6}\right)^{\frac{1}{2}} = 52.6783.\]</span></p>
</div>
<hr />
</div>
</div>
<div id="S:MS:NonParModified" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Nonparametric Estimation using Modified Data<a href="ChapModelSelection.html#S:MS:NonParModified" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It can be useful to calibrate parametric estimators with nonparametric
methods that do not rely on a parametric form of the distribution. In
particular, empirical distribution functions provide useful benchmarks,
so it is helpful to understand the estimation procedures for grouped,
censored, and truncated data.</p>
<div id="grouped-data" class="section level4 hasAnchor" number="5.2.2.1">
<h4><span class="header-section-number">5.2.2.1</span> Grouped Data<a href="ChapModelSelection.html#grouped-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>As we have seen in Section <a href="ChapModelSelection.html#S:MS:GroupedData">5.2.1.1</a>, observations may be
grouped (also referred to as interval censored) in the sense that we
only observe them as belonging in one of <span class="math inline">\(k\)</span> intervals of the form
<span class="math inline">\((c_{j-1}, c_j]\)</span>, for <span class="math inline">\(j=1, \ldots, k\)</span>. At the boundaries, the empirical
distribution function is defined in the same way as Section
<a href="ChapModelSelection.html#S:MS:NonParInf">5.1</a>: <span class="math display">\[
F_n(c_j) = \frac{\text{number of observations } \le c_j}{n}.
\]</span></p>
<p><strong>Ogive Estimator.</strong> For other values of <span class="math inline">\(x \in (c_{j-1}, c_j)\)</span>, we can
estimate the distribution function with the
<a href="#" class="tooltip" style="color:green"><em>ogive estimator</em><span style="font-size:8pt">A nonparametric estimator for the distribution function in the presence of grouped data.</span></a>, which linearly interpolates between
<span class="math inline">\(F_n(c_{j-1})\)</span> and <span class="math inline">\(F_n(c_j)\)</span>, i.e.the values of the boundaries
<span class="math inline">\(F_n(c_{j-1})\)</span> and <span class="math inline">\(F_n(c_j)\)</span> are connected with a straight line. This
can formally be expressed as
<span class="math display">\[F_n(x) = \frac{c_j-x}{c_j-c_{j-1}} F_n(c_{j-1}) + \frac{x-c_{j-1}}{c_j-c_{j-1}} F_n(c_j) \ \ \ \text{for } c_{j-1} \le x &lt; c_j\,.\]</span></p>
<p>The corresponding density is</p>
<p><span class="math display">\[
f_n(x) = F^{\prime}_n(x) = \frac{F_n(c_j)-F_n(c_{j-1})}{c_j - c_{j-1}} \ \ \  \text{for } c_{j-1} &lt; x &lt; c_j .
\]</span></p>
<hr />
<p><strong>Example 5.2.4. Actuarial Exam Question.</strong> You are given the following
information regarding claim sizes for 100 claims:</p>
<p><span class="math display">\[
{\small
\begin{array}{r|c}
\hline
\text{Claim Size} &amp;  \text{Number of Claims} \\
\hline
0 - 1,000 &amp; 16 \\
1,000 - 3,000 &amp; 22 \\
3,000 - 5,000 &amp; 25 \\
5,000 - 10,000 &amp; 18 \\
10,000 - 25,000 &amp; 10 \\
25,000 - 50,000 &amp; 5 \\
50,000 - 100,000 &amp; 3 \\
\text{over  } 100,000 &amp; 1 \\
\hline
\end{array}
}
\]</span></p>
<p>Use the ogive estimator to approximate the probability that a randomly
chosen claim is between 2000 and 6000.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.2.4" href="javascript:toggleEX('toggleExample.5.2.4','displayExample.5.2.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.2.4" style="display: none">
<p><strong>Solution.</strong> At the boundaries, the empirical distribution function is
defined in the usual way, so we have
<span class="math display">\[F_{100}(1000) = 0.16, \ F_{100}(3000)=0.38, \ F_{100}(5000)=0.63, \ F_{100}(10000)=0.81.\]</span>
For other claim sizes, the ogive estimator linearly interpolates between
these values:</p>
<p><span class="math display">\[
\begin{array}{ll}
F_{100}(2000) &amp;= 0.5F_{100}(1000) + 0.5F_{100}(3000) = 0.5(0.16)+0.5(0.38)=0.27 \\
F_{100}(6000) &amp;=0.8F_{100}(5000)+0.2F_{100}(10000) = 0.8(0.63)+0.2(0.81)=0.666.
\end{array}
\]</span></p>
<p>Thus, the probability that a claim is between 2000 and 6000 is
<span class="math inline">\(F_{100}(6000) - F_{100}(2000) = 0.666-0.27 = 0.396\)</span>.</p>
</div>
<hr />
</div>
<div id="S:MS:RightCensored" class="section level4 hasAnchor" number="5.2.2.2">
<h4><span class="header-section-number">5.2.2.2</span> Right-Censored Empirical Distribution Function<a href="ChapModelSelection.html#S:MS:RightCensored" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For right-censored data, the <a href="#" class="tooltip" style="color:green"><em>product-limit estimator</em><span style="font-size:8pt">A nonparametric estimator of the survival function in the presence of incomplete data. also known as the kaplan-meier estimator.</span></a> due to
<span class="citation">(<a href="#ref-kaplan1958" role="doc-biblioref">Kaplan and Meier 1958</a>)</span> is a well-known estimator of the empirical distribution
function.</p>
<p><strong>Motivation for the Kaplan-Meier Product Limit Estimator.</strong> To explain
why the product-limit works so well with censored observations, let us
first return to the usual case without censoring. From Section
<a href="ChapModelSelection.html#S:MS:NonParInf">5.1</a>, the empirical distribution function <span class="math inline">\(F_n(x)\)</span> is
an <em>unbiased</em> estimator of the distribution function <span class="math inline">\(F(x)\)</span>. This is
because <span class="math inline">\(F_n(x)\)</span> is the average of indicator variables each of which are
unbiased. That is, <span class="math inline">\(\mathrm{E~} [I(X_i \le x)] = \Pr(X_i \le x) = F(x)\)</span>.</p>
<p>Now suppose the random outcome is censored on the right by a limiting
amount, say, <span class="math inline">\(C_U\)</span>, so that we record the smaller of the two,
<span class="math inline">\(X^* = \min(X, C_U)\)</span>. For values of <span class="math inline">\(x\)</span> that are smaller than <span class="math inline">\(C_U\)</span>, the
indicator variable still provides an unbiased estimator of the
distribution function before we reach the censoring limit. That is,
<span class="math inline">\(\mathrm{E~} [I(X^* \le x)] = F(x)\)</span> because <span class="math inline">\(I(X^* \le x) = I(X \le x)\)</span>
for <span class="math inline">\(x &lt; C_U\)</span>. In the same way,
<span class="math inline">\(\mathrm{E~} [I(X^* &gt; x)] = 1 -F(x) = S(x)\)</span>, making <span class="math inline">\(1-F_n(x)\)</span> an
unbiased estimator of the <em>survival function</em> <span class="math inline">\(S(x)=1-F(x)\)</span>. But, for
<span class="math inline">\(x&gt;C_U\)</span>, <span class="math inline">\(I(X^* \le x)\)</span> is in general not an unbiased estimator of
<span class="math inline">\(F(x)\)</span>.</p>
<p>As an alternative, consider <em>two</em> random variables that have different
censoring limits. For illustration, suppose that we observe
<span class="math inline">\(X_1^* = \min(X_1, 5)\)</span> and <span class="math inline">\(X_2^* = \min(X_2, 10)\)</span> where <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>
are independent draws from the same distribution. For <span class="math inline">\(x \le 5\)</span>, the
empirical distribution function <span class="math inline">\(F_2(x)\)</span> is an unbiased estimator of
<span class="math inline">\(F(x)\)</span>. However, for <span class="math inline">\(5 &lt; x \le 10\)</span>, the first observation cannot be
used for the distribution function because of the censoring limitation.
Instead, the strategy developed by <span class="citation">(<a href="#ref-kaplan1958" role="doc-biblioref">Kaplan and Meier 1958</a>)</span> uses <span class="math inline">\(S_2(5)\)</span> as an
estimator of <span class="math inline">\(S(5)\)</span> and then use the second observation to estimate the
survival function conditional on survival to time 5,
<span class="math inline">\(\Pr(X &gt; x | X &gt;5) = \frac{S(x)}{S(5)}\)</span>. Specifically, for
<span class="math inline">\(5 &lt; x \le 10\)</span>, the estimator of the survival function is</p>
<p><span class="math display">\[
\hat{S}(x) = S_2(5) \times I(X_2^* &gt; x ) .
\]</span></p>
<p><strong>Kaplan-Meier Product Limit Estimator.</strong> Extending this idea, for each
observation <span class="math inline">\(i\)</span>, let <span class="math inline">\(u_i\)</span> be the upper censoring limit (<span class="math inline">\(=\infty\)</span> if no
censoring). Thus, the recorded value is <span class="math inline">\(x_i\)</span> in the case of no
censoring and <span class="math inline">\(u_i\)</span> if there is censoring. Let <span class="math inline">\(t_{1} &lt;\cdots&lt; t_{k}\)</span> be
<span class="math inline">\(k\)</span> distinct points at which an uncensored loss occurs, and let <span class="math inline">\(s_j\)</span> be
the number of uncensored losses <span class="math inline">\(x_i\)</span>s at <span class="math inline">\(t_{j}\)</span>. The corresponding
<a href="#" class="tooltip" style="color:green"><em>risk set</em><span style="font-size:8pt">The number of observations that are active (not censored) at a specific point.</span></a> is the number of observations that are active (not
censored) at a value <em>less than</em> <span class="math inline">\(t_{j}\)</span>, denoted as
<span class="math inline">\(R_j = \sum_{i=1}^n I(x_i \geq t_{j}) + \sum_{i=1}^n I(u_i \geq t_{j})\)</span>.</p>
<p>With this notation, the <strong>product-limit estimator</strong> of the distribution
function is</p>
<span class="math display" id="eq:KaplanMeier">\[\begin{equation}
\hat{F}(x) =
\left\{
\begin{array}{ll}
0 &amp; x&lt;t_{1} \\
1-\prod_{j:t_{j} \leq x}\left( 1-\frac{s_j}{R_{j}}\right) &amp; x \geq t_{1}
\end{array}
\right. .
\tag{5.5}
\end{equation}\]</span>
<p>For example, if <span class="math inline">\(x\)</span> is smaller than the smallest uncensored loss, then
<span class="math inline">\(x&lt;t_1\)</span> and <span class="math inline">\(\hat{F}(x) =0\)</span>. As another example, if <span class="math inline">\(x\)</span> falls between
the second and third smallest uncensored losses, then <span class="math inline">\(x \in (t_2,t_3]\)</span>
and
<span class="math inline">\(\hat{F}(x) = 1 - \left(1- \frac{s_1}{R_{1}}\right)\left(1- \frac{s_2}{R_{2}}\right)\)</span>.</p>
<p>As usual, the corresponding estimator of the survival function is
<span class="math inline">\(\hat{S}(x) = 1 - \hat{F}(x)\)</span>.</p>
<hr />
<p><strong>Example 5.2.5. Actuarial Exam Question.</strong> The following is a sample of
10 payments:</p>
<p><span class="math display">\[
\begin{array}{cccccccccc}
4 &amp;4 &amp;5+ &amp;5+ &amp;5+ &amp;8 &amp;10+ &amp;10+ &amp;12 &amp;15 \\
\end{array}
\]</span></p>
<p>where <span class="math inline">\(+\)</span> indicates that a loss has exceeded the policy limit.</p>
<p>Using the Kaplan-Meier product-limit estimator, calculate the
probability that the loss on a policy exceeds 11, <span class="math inline">\(\hat{S}(11)\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.2.5" href="javascript:toggleEX('toggleExample.5.2.5','displayExample.5.2.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.2.5" style="display: none">
<p><strong>Solution.</strong> There are four event times (non-censored observations).
For each time <span class="math inline">\(t_j\)</span>, we can calculate the number of events <span class="math inline">\(s_j\)</span> and the
risk set <span class="math inline">\(R_j\)</span> as the following:</p>
<p><span class="math display">\[
\begin{array}{cccc}
\hline
j &amp; t_j &amp; s_j &amp; R_j \\
\hline
1 &amp; 4 &amp; 2 &amp; 10 \\
2 &amp; 8 &amp; 1 &amp; 5 \\
3 &amp; 12 &amp; 1 &amp; 2 \\
4 &amp; 15 &amp; 1 &amp; 1 \\
\hline
\end{array}
\]</span></p>
<p>Thus, the Kaplan-Meier estimate of <span class="math inline">\(S(11)\)</span> is <span class="math display">\[
\begin{aligned}
\hat{S}(11) &amp;= \prod_{j:t_j\leq 11} \left( 1- \frac{s_j}{R_j} \right) =  \prod_{j=1}^{2} \left( 1- \frac{s_j}{R_j} \right)\\
&amp;= \left(1-\frac{2}{10} \right) \left(1-\frac{1}{5} \right) = (0.8)(0.8)= 0.64. \\
\end{aligned}
\]</span></p>
</div>
<hr />
<p><strong>Example 5.2.6. Bodily Injury Claims.</strong> We consider again the Boston
auto bodily injury claims data from <span class="citation">Derrig, Ostaszewski, and Rempala (<a href="#ref-derrig2001applications" role="doc-biblioref">2001</a>)</span> that was
introduced in Example 5.1.6. In that example, we omitted the
17 claims that were censored by policy limits.
Now, we include the full dataset and use the Kaplan-Meier product limit
to estimate the survival function. This is given in Figure
<a href="ChapModelSelection.html#fig:KMSurvival">5.9</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:KMSurvival"></span>
<img src="LossDataAnalytics_files/figure-html/KMSurvival-1.png" alt="Kaplan-Meier Estimate of the Survival Function for Bodily Injury Claims" width="672" />
<p class="caption">
Figure 5.9: <strong>Kaplan-Meier Estimate of the Survival Function for Bodily Injury Claims</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.KaplanMeier.4f" href="javascript:togglecode('toggleCode.KaplanMeier.4f','displayCode.KaplanMeier.4f');"><i><strong>Show R Code</strong></i></a>
</h5>
<div id="toggleCode.KaplanMeier.4f" style="display: none">
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="ChapModelSelection.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(survival)  <span class="co"># for Surv(), survfit()</span></span>
<span id="cb44-2"><a href="ChapModelSelection.html#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># BIData &lt;- read.csv(&#39;Data/DerrigResampling.csv&#39;, header =T)</span></span>
<span id="cb44-3"><a href="ChapModelSelection.html#cb44-3" aria-hidden="true" tabindex="-1"></a>BIData<span class="sc">$</span>UnCensored <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">*</span> (BIData<span class="sc">$</span>AmountPaid <span class="sc">&lt;</span> BIData<span class="sc">$</span>PolicyLimit)</span>
<span id="cb44-4"><a href="ChapModelSelection.html#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="do">## KM estimate</span></span>
<span id="cb44-5"><a href="ChapModelSelection.html#cb44-5" aria-hidden="true" tabindex="-1"></a>KM0 <span class="ot">&lt;-</span> <span class="fu">survfit</span>(<span class="fu">Surv</span>(AmountPaid, UnCensored) <span class="sc">~</span> <span class="dv">1</span>, <span class="at">type =</span> <span class="st">&quot;kaplan-meier&quot;</span>, <span class="at">data =</span> BIData)</span>
<span id="cb44-6"><a href="ChapModelSelection.html#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(KM0, <span class="at">conf.int =</span> <span class="cn">FALSE</span>, <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Kaplan Meier Survival&quot;</span>)</span></code></pre></div>
</div>
<hr />
<p><strong>Right-Censored, Left-Truncated Empirical Distribution Function.</strong> In
addition to right-censoring, we now extend the framework to allow for
left-truncated data. As before, for each observation <span class="math inline">\(i\)</span>, let <span class="math inline">\(u_i\)</span> be
the upper censoring limit (<span class="math inline">\(=\infty\)</span> if no censoring). Further, let
<span class="math inline">\(d_i\)</span> be the lower truncation limit (0 if no truncation). Thus, the
recorded value (if it is greater than <span class="math inline">\(d_i\)</span>) is <span class="math inline">\(x_i\)</span> in the case of no
censoring and <span class="math inline">\(u_i\)</span> if there is censoring. Let <span class="math inline">\(t_{1} &lt;\cdots&lt; t_{k}\)</span> be
<span class="math inline">\(k\)</span> distinct points at which an event of interest occurs, and let <span class="math inline">\(s_j\)</span>
be the number of recorded events <span class="math inline">\(x_i\)</span>s at time point <span class="math inline">\(t_{j}\)</span>. The
corresponding risk set is
<span class="math display">\[R_j = \sum_{i=1}^n I(x_i \geq t_{j}) + \sum_{i=1}^n I(u_i \geq t_{j}) - \sum_{i=1}^n I(d_i \geq t_{j}).\]</span></p>
<p>With this new definition of the risk set, the product-limit estimator of
the distribution function can be obtained using equation
<a href="ChapModelSelection.html#eq:KaplanMeier">(5.5)</a>.</p>
<p><strong>Greenwoods Formula</strong>. For statistical inference, <span class="citation">(<a href="#ref-greenwood1926" role="doc-biblioref">Greenwood 1926</a>)</span>
derived the formula for the estimated variance of the product-limit
estimator as</p>
<p><span class="math display">\[
\widehat{Var}(\hat{F}(x)) = (1-\hat{F}(x))^{2} \sum _{j:t_{j} \leq x} \dfrac{s_j}{R_{j}(R_{j}-s_j)}.
\]</span></p>
<p>As usual, we refer to the square root of the estimated variance as the
<em>standard error</em>, a quantity that is routinely used in confidence
intervals and for hypothesis testing (see, e.g., Appendix Section
<a href="CAppA.html#S:AppA:IE">16.3</a>). To compute this, the <code>survfit</code> function in <code>R</code> takes
a survival data object and creates a new object containing the
Kaplan-Meier estimate of the survival function along with confidence
intervals. The Kaplan-Meier method (<code>type='kaplan-meier'</code>) is used by
default to construct an estimate of the survival curve. The resulting
discrete survival function has point masses at the observed event times
(discharge dates) <span class="math inline">\(t_j\)</span>, where the probability of an event given
survival to that duration is estimated as the number of observed events
at the duration <span class="math inline">\(s_j\)</span> divided by the number of subjects exposed or
at-risk just prior to the event duration <span class="math inline">\(R_j\)</span>.</p>
<p><strong>Alternative Estimators</strong>. Two alternate types of estimators are
available for the <code>survfit</code> function. The alternative (<code>type='fh2'</code>)
handles ties, in essence, by assuming that multiple events at the same
duration occur in some arbitrary order. Another alternative
(<code>type='fleming-harrington'</code>) uses the <a href="#" class="tooltip" style="color:green"><em>Nelson-Aalen</em><span style="font-size:8pt">A nonparametric estimator of the cumulative hazard function in the presence of incomplete data.</span></a>
<span class="citation">(<a href="#ref-aalen1978" role="doc-biblioref">Aalen 1978</a>)</span> estimator of the <strong>cumulative hazard function</strong> to obtain
an estimate of the survival function. The estimated cumulative hazard
<span class="math inline">\(\hat{H}(x)\)</span> starts at zero and is incremented at each observed event
duration <span class="math inline">\(t_j\)</span> by the number of events <span class="math inline">\(s_j\)</span> divided by the number at
risk <span class="math inline">\(R_j\)</span>. With the same notation as above, the <strong>Nelson-alen</strong>
estimator of the distribution function is</p>
<p><span class="math display">\[
\begin{aligned}
\hat{F}_{NA}(x) &amp;=
\left\{
\begin{array}{ll}
0 &amp; x&lt;t_{1} \\
1- \exp \left(-\sum_{j:t_{j} \leq x}\frac{s_j}{R_j} \right) &amp; x \geq t_{1}
\end{array}
\right. .\end{aligned}
\]</span></p>
<p>Note that the above expression is a result of the Nelson-alen estimator
of the cumulative hazard function
<span class="math display">\[\hat{H}(x)=\sum_{j:t_j\leq x}  \frac{s_j}{R_j},\]</span>and the relationship
between the survival function and cumulative hazard function is
<span class="math inline">\(\hat{S}_{NA}(x)=e^{-\hat{H}(x)}\)</span>.</p>
<hr />
<p><strong>Example 5.2.7. Actuarial Exam Question.</strong></p>
<p>For observation <span class="math inline">\(i\)</span> of a survival study:</p>
<ul>
<li><span class="math inline">\(d_i\)</span> is the left truncation point</li>
<li><span class="math inline">\(x_i\)</span> is the observed value if not right censored</li>
<li><span class="math inline">\(u_i\)</span> is the observed value if right censored</li>
</ul>
<p>You are given:</p>
<p><span class="math display">\[
{\small
\begin{array}{c|cccccccccc}
\hline
\text{Observation } (i) &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10\\ \hline
d_i &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1.3 &amp; 1.5 &amp; 1.6\\
x_i &amp; 0.9 &amp; - &amp; 1.5 &amp; - &amp; - &amp; 1.7 &amp; - &amp; 2.1 &amp; 2.1 &amp; - \\
u_i &amp; - &amp; 1.2 &amp; - &amp; 1.5 &amp; 1.6 &amp; - &amp; 1.7 &amp; - &amp; - &amp; 2.3 \\
\hline
\end{array}
}
\]</span></p>
<p>Calculate the Kaplan-Meier product-limit estimate, <span class="math inline">\(\hat{S}(1.6)\)</span></p>
<h5 style="text-align: center;">
<a id="displayExample.5.2.7" href="javascript:toggleEX('toggleExample.5.2.7','displayExample.5.2.7');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.2.7" style="display: none">
<p><strong>Solution.</strong> Recall the risk set
<span class="math inline">\(R_j = \sum_{i=1}^n \left\{ I(x_i \geq t_{j}) + I(u_i \geq t_{j}) - I(d_i \geq t_{j}) \right\}\)</span>.
Then</p>
<p><span class="math display">\[
\begin{array}{ccccc}
\hline
j &amp; t_j &amp; s_j &amp; R_j &amp; \hat{S}(t_j) \\
\hline
1  &amp; 0.9   &amp; 1   &amp; 10-3 = 7 &amp; 1-\frac{1}{7} = \frac{6}{7} \\
2  &amp; 1.5   &amp; 1   &amp; 8-2 = 6  &amp; \frac{6}{7}\left( 1 - \frac{1}{6} \right) = \frac{5}{7}\\
3  &amp; 1.7   &amp; 1   &amp; 5-0 = 5  &amp; \frac{5}{7}\left( 1 - \frac{1}{5} \right) = \frac{4}{7}\\
4  &amp; 2.1   &amp; 2   &amp; 3        &amp; \frac{4}{7}\left( 1 - \frac{2}{3}\right) = \frac{4}{21}\\
\hline
\end{array}
\]</span></p>
<p>The Kaplan-Meier estimate is therefore <span class="math inline">\(\hat{S}(1.6) = \frac{5}{7}\)</span>.</p>
</div>
<hr />
<p><strong>Example 5.2.8. Actuarial Exam Question. - Continued.</strong></p>
<ol style="list-style-type: lower-alpha">
<li>Using the Nelson-alen estimator, calculate the probability that the
loss on a policy exceeds 11, <span class="math inline">\(\hat{S}_{NA}(11)\)</span>.</li>
<li>Calculate Greenwoods approximation to the variance of the
product-limit estimate <span class="math inline">\(\hat{S}(11)\)</span>.</li>
</ol>
<h5 style="text-align: center;">
<a id="displayExample.5.2.8" href="javascript:toggleEX('toggleExample.5.2.8','displayExample.5.2.8');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.2.8" style="display: none">
<p><strong>Solution.</strong> As before, there are four event times (non-censored
observations). For each time <span class="math inline">\(t_j\)</span>, we can calculate the number of
events <span class="math inline">\(s_j\)</span> and the risk set <span class="math inline">\(R_j\)</span> as the following:</p>
<p><span class="math display">\[
\begin{array}{cccc}
\hline
j &amp; t_j &amp; s_j &amp; R_j \\
\hline
1 &amp; 4 &amp; 2 &amp; 10 \\
2 &amp; 8 &amp; 1 &amp; 5 \\
3 &amp; 12 &amp; 1 &amp; 2 \\
4 &amp; 15 &amp; 1 &amp; 1 \\
\hline
\end{array}
\]</span></p>
<p>The Nelson-alen estimate of <span class="math inline">\(S(11)\)</span> is
<span class="math inline">\(\hat{S}_{NA}(11)=e^{-\hat{H}(11)} = e^{-0.4} = 0.67\)</span>, since <span class="math display">\[
\begin{aligned}
\hat{H}(11) &amp;= \sum_{j:t_j\leq 11} \frac{s_j}{R_j}  = \sum_{j=1}^{2} \frac{s_j}{R_j}  \\
&amp;= \frac{2}{10} + \frac{1}{5}  = 0.2 + 0.2 = 0.4 .\\
\end{aligned}
\]</span></p>
<p>From earlier work, the Kaplan-Meier estimate of <span class="math inline">\(S(11)\)</span> is
<span class="math inline">\(\hat{S}(11) = 0.64\)</span>. Then Greenwoods estimate of the variance of the
product-limit estimate of <span class="math inline">\(S(11)\)</span> is <span class="math display">\[
\begin{aligned}
\widehat{Var}(\hat{S}(11)) &amp;= (\hat{S}(11))^2 \sum_{j:t_j\leq 11} \frac{s_j}{R_j(R_j-s_j)}
&amp;= (0.64)^2 \left(\frac{2}{10(8)} + \frac{1}{5(4)} \right)  = 0.0307. \\
\end{aligned}
\]</span></p>
</div>
<hr />
</div>
</div>
</div>
<div id="S:MS:ModelSelection" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Model Selection<a href="ChapModelSelection.html#S:MS:ModelSelection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Determine measures that summarize deviations of a parametric from a nonparametric fit</li>
<li>Describe the iterative model selection specification process</li>
<li>Outline steps needed to select a parametric model</li>
<li>Describe pitfalls of model selection based purely on in-sample data when compared to the advantages of out-of-sample model validation</li>
</ul>
<hr />
<p>In addition to nonparametric tools for model selection based on marginal
distributions of outcomes ignoring explanatory variables, this section
underscores the idea that model selection is an iterative process in
which models are cyclically (re)formulated and tested for
appropriateness before using them for inference. After an overview, we
describe the <a href="#" class="tooltip" style="color:green"><em>model selection</em><span style="font-size:8pt">The process of selecting a statistical model from a set of candidate models using data.</span></a> process from Section
<a href="ChapDataAnalytics.html#S:Process">2.2</a> based on:</p>
<ul>
<li>an <a href="#" class="tooltip" style="color:green"><em>in-sample</em><span style="font-size:8pt">A dataset used for analysis and model development. also known as a training dataset.</span></a> or training dataset,</li>
<li>an <a href="#" class="tooltip" style="color:green"><em>out-of-sample</em><span style="font-size:8pt">A dataset used for model validation. also known as a test dataset.</span></a> or test dataset, and</li>
<li>a method that combines these approaches known as
<a href="#" class="tooltip" style="color:green"><em>cross-validation</em><span style="font-size:8pt">A model validation procedure in which the data sample is partitioned into subsamples, where splits are formed by separately taking each subsample as the out-of-sample dataset.</span></a>.</li>
</ul>
<div id="S:MS:ToolsModelSelection" class="section level3 hasAnchor" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Tools for Model Selection and Diagnostics<a href="ChapModelSelection.html#S:MS:ToolsModelSelection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Section <a href="ChapModelSelection.html#S:MS:NonParInf">5.1</a> introduced nonparametric estimators in
which there was no parametric form assumed about the underlying
distributions. However, in many actuarial applications, analysts seek to
employ a parametric fit of a distribution for ease of explanation and
the ability to readily extend it to more complex situations such as
including explanatory variables in a regression setting. When fitting a
parametric distribution, one analyst might try to use a gamma
distribution to represent a set of loss data. However, another analyst
may prefer to use a Pareto distribution. How does one determine which
model to select?</p>
<p>Nonparametric tools can be used to corroborate the selection of
parametric models. Essentially, the approach is to compute selected
summary measures under a fitted parametric model and to compare it to
the corresponding quantity under the nonparametric model. As the
nonparametric model does not assume a specific distribution and is
merely a function of the data, it is used as a benchmark to assess how
well the parametric distribution/model represents the data. Also, as the
sample size increases, the empirical distribution converges almost
surely to the underlying population distribution (by the strong law of
large numbers). Thus the empirical distribution is a good proxy for the
population. The comparison of parametric to nonparametric estimators may
alert the analyst to deficiencies in the parametric model and sometimes
point ways to improving the parametric specification. Procedures geared
towards assessing the validity of a model are known as
<a href="#" class="tooltip" style="color:green"><em>model diagnostics</em><span style="font-size:8pt">Procedures to assess the validity of a model</span></a>.</p>
<div id="S:MS:GraphComparison" class="section level4 hasAnchor" number="5.3.1.1">
<h4><span class="header-section-number">5.3.1.1</span> Graphical Comparison of Distributions<a href="ChapModelSelection.html#S:MS:GraphComparison" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We have already seen the technique of overlaying graphs for comparison
purposes. To reinforce the application of this technique, Figure
<a href="ChapModelSelection.html#fig:ComparisonCDFPDF">5.10</a> compares the empirical distribution to two
parametric fitted distributions. The left panel shows the distribution
functions of claims distributions. The dots forming an S-shaped curve
represent the empirical distribution function at each observation. The
thick blue curve gives corresponding values for the fitted gamma
distribution and the light purple is for the fitted Pareto distribution.
Because the Pareto is much closer to the empirical distribution function
than the gamma, this provides evidence that the Pareto is the better
model for this dataset. The right panel gives similar information for
the density function and provides a consistent message. Based (only) on
these figures, the Pareto distribution is the clear choice for the
analyst.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ComparisonCDFPDF"></span>
<img src="LossDataAnalytics_files/figure-html/ComparisonCDFPDF-1.png" alt="Nonparametric Versus Fitted Parametric Distribution and Density Functions. The left-hand panel compares distribution functions, with the dots corresponding to the empiricaldistribution, the thick blue curve corresponding to the fitted gamma and the light purple curve corresponding to the fitted Pareto. The right hand panel compares these three distributions summarized using probability density functions. " width="80%" />
<p class="caption">
Figure 5.10: <strong>Nonparametric Versus Fitted Parametric Distribution and Density Functions. The left-hand panel compares distribution functions, with the dots corresponding to the empiricaldistribution, the thick blue curve corresponding to the fitted gamma and the light purple curve corresponding to the fitted Pareto. The right hand panel compares these three distributions summarized using probability density functions. </strong>
</p>
</div>
<p>For another way to compare the appropriateness of two fitted models,
consider the <a href="#" class="tooltip" style="color:green"><em>probability-probability (pp) plot</em><span style="font-size:8pt">A plot that compares two models through their cumulative probabilities.</span></a>. A <span class="math inline">\(pp\)</span> plot
compares cumulative probabilities under two models. For our purposes,
these two models are the nonparametric empirical distribution function
and the parametric fitted model. Figure <a href="ChapModelSelection.html#fig:PPPlot">5.11</a> shows <span class="math inline">\(pp\)</span>
plots for the Property Fund data introduced in Section <a href="ChapIntro.html#S:LGPIF">1.3</a>.
The fitted gamma is on the left and the fitted Pareto is on the right,
compared to the same empirical distribution function of the data. The
straight line represents equality between the two distributions being
compared, so points close to the line are desirable. As seen in earlier
demonstrations, the Pareto is much closer to the empirical distribution
than the gamma, providing additional evidence that the Pareto is the
better model.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:PPPlot"></span>
<img src="LossDataAnalytics_files/figure-html/PPPlot-1.png" alt="Probability-Probability (\(pp\)) Plots. The horizontal axis gives the empirical distribution function at each observation. In the left-hand panel, the corresponding distribution function for the gamma is shown in the vertical axis. The right-hand panel shows the fitted Pareto distribution. Lines of \(y=x\) are superimposed." width="80%" />
<p class="caption">
Figure 5.11: <strong>Probability-Probability (<span class="math inline">\(pp\)</span>) Plots. The horizontal axis gives the empirical distribution function at each observation. In the left-hand panel, the corresponding distribution function for the gamma is shown in the vertical axis. The right-hand panel shows the fitted Pareto distribution. Lines of <span class="math inline">\(y=x\)</span> are superimposed.</strong>
</p>
</div>
<p>A <span class="math inline">\(pp\)</span> plot is useful in part because no artificial scaling is required,
such as with the overlaying of densities in Figure
<a href="ChapModelSelection.html#fig:ComparisonCDFPDF">5.10</a>, in which we switched to the log scale to
better visualize the data. The Chapter 5 <em>Technical Supplement A.1</em>
introduces a variation of the <span class="math inline">\(pp\)</span> plot known as a
<a href="#" class="tooltip" style="color:green"><em>Lorenz curve</em><span style="font-size:8pt">A graph of the proportion of a population on the horizontal axis and a distribution function of interest on the vertical axis.</span></a>; this is an important tool for assessing
income inequality. Furthermore, <span class="math inline">\(pp\)</span> plots are available in multivariate
settings where more than one outcome variable is available. However, a
limitation of the <span class="math inline">\(pp\)</span> plot is that, because it plots <em>cumulative</em>
distribution functions, it can sometimes be difficult to detect <em>where</em>
a fitted parametric distribution is deficient. As an alternative, it is
common to use a <a href="#" class="tooltip" style="color:green"><em>quantile-quantile (qq) plot</em><span style="font-size:8pt">A plot that compares two models through their quantiles.</span></a>, as
demonstrated in Figure <a href="ChapModelSelection.html#fig:QQPlot">5.12</a>.</p>
<p>The <span class="math inline">\(qq\)</span> plot compares two fitted models through their quantiles. As
with <span class="math inline">\(pp\)</span> plots, we compare the nonparametric to a parametric fitted
model. Quantiles may be evaluated at each point of the dataset, or on a
grid (e.g., at <span class="math inline">\(0, 0.001, 0.002, \ldots, 0.999, 1.000\)</span>), depending on
the application. In Figure <a href="ChapModelSelection.html#fig:QQPlot">5.12</a>, for each point on the
aforementioned grid, the horizontal axis displays the empirical quantile
and the vertical axis displays the corresponding fitted parametric
quantile (gamma for the upper two panels, Pareto for the lower two).
Quantiles are plotted on the original scale in the left panels and on
the log scale in the right panels to allow us to see where a fitted
distribution is deficient. The straight line represents equality between
the empirical distribution and fitted distribution. From these plots, we
again see that the Pareto is an overall better fit than the gamma.
Furthermore, the lower-right panel suggests that the Pareto distribution
does a good job with large claims, but provides a poorer fit for small
claims.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:QQPlot"></span>
<img src="LossDataAnalytics_files/figure-html/QQPlot-1.png" alt="Quantile-Quantile (\(qq\)) Plots. The horizontal axis gives the empirical quantiles at each observation. The right-hand panels they are graphed on a logarithmic basis. The vertical axis gives the quantiles from the fitted distributions; gamma quantiles are in the upper panels, Pareto quantiles are in the lower panels." width="80%" />
<p class="caption">
Figure 5.12: <strong>Quantile-Quantile (<span class="math inline">\(qq\)</span>) Plots. The horizontal axis gives the empirical quantiles at each observation. The right-hand panels they are graphed on a logarithmic basis. The vertical axis gives the quantiles from the fitted distributions; gamma quantiles are in the upper panels, Pareto quantiles are in the lower panels.</strong>
</p>
</div>
<hr />
<p><strong>Example 5.3.1. Actuarial Exam Question.</strong> The graph below shows a <span class="math inline">\(pp\)</span>
plot of a fitted distribution compared to a sample.</p>
<p><img src="LossDataAnalytics_files/figure-html/unnamed-chunk-55-1.png" width="40%" style="display: block; margin: auto;" /></p>
<p>Comment on the two distributions with respect to left tail, right tail,
and median probabilities.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.3.1" href="javascript:toggleEX('toggleExample.5.3.1','displayExample.5.3.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.3.1" style="display: none">
<p><strong>Solution.</strong> The tail of the fitted distribution is too thick on the
left, too thin on the right, and the fitted distribution has less
probability around the median than the sample. To see this, recall that
the <span class="math inline">\(pp\)</span> plot graphs the cumulative distribution of two distributions on
its axes (empirical on the x-axis and fitted on the y-axis in this
case). For small values of <span class="math inline">\(x\)</span>, the fitted model assigns greater
probability to being below that value than occurred in the sample (i.e.
<span class="math inline">\(F(x) &gt; F_n(x)\)</span>). This indicates that the model has a heavier left tail
than the data. For large values of <span class="math inline">\(x\)</span>, the model again assigns greater
probability to being below that value and thus less probability to being
above that value (i.e.<span class="math inline">\(S(x) &lt; S_n(x)\)</span>). This indicates that the model
has a lighter right tail than the data. In addition, as we go from 0.4
to 0.6 on the horizontal axis (thus looking at the middle 20% of the
data), the <span class="math inline">\(pp\)</span> plot increases from about 0.3 to 0.4. This indicates
that the model puts only about 10% of the probability in this range.</p>
</div>
<hr />
</div>
<div id="S:MS:Tools:Stats" class="section level4 hasAnchor" number="5.3.1.2">
<h4><span class="header-section-number">5.3.1.2</span> Statistical Comparison of Distributions<a href="ChapModelSelection.html#S:MS:Tools:Stats" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When selecting a model, it is helpful to make the graphical displays
presented. However, for reporting results, it can be effective to
supplement the graphical displays with selected statistics that
summarize model goodness of fit. <a href="#tab:5.2">Table 5.2</a> provides three
commonly used <a href="#" class="tooltip" style="color:green"><em>goodness of fit statistics</em><span style="font-size:8pt"></span></a>. In this table,
<span class="math inline">\(F_n\)</span> is the empirical distribution, <span class="math inline">\(F\)</span> is the fitted or hypothesized
distribution, and <span class="math inline">\(F_i^* = F(x_i)\)</span>.</p>
<p><a id=tab:5.2></a></p>
<p>Table 5.2. <strong>Three Goodness of Fit Statistics</strong></p>
<p><span class="math display">\[
{\small
\begin{matrix}
\begin{array}{l|cc}
\hline
\text{Statistic} &amp; \text{Definition} &amp; \text{Computational Expression} \\
\hline
\text{Kolmogorov-} &amp; \max_x |F_n(x) - F(x)| &amp; \max(D^+, D^-) \text{ where } \\
~~~\text{Smirnov} &amp;&amp; D^+ = \max_{i=1, \ldots, n} \left|\frac{i}{n} - F_i^*\right| \\
&amp;&amp; D^- = \max_{i=1, \ldots, n} \left| F_i^* - \frac{i-1}{n} \right| \\
\text{Cramer-von Mises} &amp; n \int (F_n(x) - F(x))^2 f(x) dx &amp; \frac{1}{12n} + \sum_{i=1}^n \left(F_i^* - (2i-1)/n\right)^2 \\
\text{Anderson-Darling} &amp; n \int \frac{(F_n(x) - F(x))^2}{F(x)(1-F(x))} f(x) dx &amp; -n-\frac{1}{n} \sum_{i=1}^n (2i-1) \log\left(F_i^*(1-F_{n+1-i})\right)^2 \\
\hline
\end{array} \\
\end{matrix}
}
\]</span></p>
<p>The <em>Kolmogorov-Smirnov statistic</em> is the maximum absolute difference
between the fitted distribution function and the empirical distribution
function. Instead of comparing differences between single points, the
<em>Cramer-von Mises statistic</em> integrates the difference between the
empirical and fitted distribution functions over the entire range of
values. The <em>Anderson-Darling statistic</em> also integrates this difference
over the range of values, although weighted by the inverse of the
variance. It therefore places greater emphasis on the tails of the
distribution (i.e when <span class="math inline">\(F(x)\)</span> or <span class="math inline">\(1-F(x)=S(x)\)</span> is small).</p>
<hr />
<p><strong>Example 5.3.2. Actuarial Exam Question (modified).</strong> A sample of claim
payments is:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
29 &amp; 64 &amp; 90 &amp; 135 &amp; 182  \\
\end{array}
\]</span></p>
<p>Compare the empirical claims distribution to an exponential distribution
with mean <span class="math inline">\(100\)</span> by calculating the value of the Kolmogorov-Smirnov test
statistic.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.3.2" href="javascript:toggleEX('toggleExample.5.3.2','displayExample.5.3.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.3.2" style="display: none">
<p><strong>Solution.</strong> For an exponential distribution with mean <span class="math inline">\(100\)</span>, the
cumulative distribution function is <span class="math inline">\(F(x)=1-e^{-x/100}\)</span>. Thus,</p>
<p><span class="math display">\[
\begin{array}{ccccc}
\hline
x &amp; F(x) &amp; F_n(x) &amp; F_n(x-) &amp; \max(|F(x)-F_n(x)|,|F(x)-F_n(x-)|) \\
\hline
29  &amp; 0.2517 &amp; 0.2 &amp; 0   &amp; \max(0.0517, 0.2517) = 0.2517 \\
64  &amp; 0.4727 &amp; 0.4 &amp; 0.2 &amp; \max(0.0727, 0.2727) = 0.2727 \\
90  &amp; 0.5934 &amp; 0.6 &amp; 0.4 &amp; \max(0.0066, 0.1934) = 0.1934 \\
135 &amp; 0.7408 &amp; 0.8 &amp; 0.6 &amp; \max(0.0592, 0.1408) = 0.1408 \\
182 &amp; 0.8380 &amp; 1   &amp; 0.8 &amp; \max(0.1620, 0.0380) = 0.1620 \\
\hline
\end{array}
\]</span></p>
<p>The Kolmogorov-Smirnov test statistic is therefore</p>
<p><span class="math display">\[
KS = \max(0.2517, 0.2727, 0.1934, 0.1408, 0.1620) = 0.2727 .
\]</span></p>
</div>
<hr />
<div id="surveyElement43">

</div>
<div id="surveyResult43">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz43.1" href="javascript:toggleQuiz
('display.Quiz43.2','display.Quiz43.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz43.2" style="display: none">
<p id="Quiz43Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz43.js">
</script>
</div>
</div>
<div id="S:MS:Iterative:Selection" class="section level3 hasAnchor" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Iterative Model Selection<a href="ChapModelSelection.html#S:MS:Iterative:Selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In our model development, we examine the data graphically, hypothesize a
model structure, and compare the data to a candidate model in order to
formulate an improved model. <span class="citation">Box (<a href="#ref-box1980sampling" role="doc-biblioref">1980</a>)</span> describes this as an
<em>iterative process</em> which is shown in Figure <a href="ChapModelSelection.html#fig:Iterative">5.13</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Iterative"></span>
<img src="Figures/F5Iterative.png" alt="Iterative Model Specification Process" width="80%" />
<p class="caption">
Figure 5.13: <strong>Iterative Model Specification Process</strong>
</p>
</div>
<p>This iterative process provides a useful recipe for structuring the task
of specifying a model to represent a set of data.</p>
<ol style="list-style-type: decimal">
<li>The first step, the model formulation stage, is accomplished by
examining the data graphically and using prior knowledge of
relationships, such as from economic theory or industry practice.</li>
<li>The second step in the iteration is fitting based on the assumptions
of the specified model. These assumptions must be consistent with
the data to make valid use of the model.</li>
<li>The third step is <em>diagnostic checking</em>; the data and model must be
consistent with one another before additional inferences can be
made. Diagnostic checking is an important part of the model
formulation; it can reveal mistakes made in previous steps and
provide ways to correct these mistakes.</li>
</ol>
<p>The iterative process also emphasizes the skills you need to make data
analytics work. First, you need a willingness to summarize information
numerically and portray this information graphically. Second, it is
important to develop an understanding of model properties. You should
understand how a probabilistic model behaves in order to match a set of
data to it. Third, theoretical properties of the model are also
important for inferring general relationships based on the behavior of
the data.</p>
</div>
<div id="S:MS:Tools:Stats:Likelihood" class="section level3 hasAnchor" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Model Selection Based on a Training Dataset<a href="ChapModelSelection.html#S:MS:Tools:Stats:Likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As introduced in Section <a href="ChapDataAnalytics.html#S:Process">2.2</a>, it is common to refer to a
dataset used for fitting the model as a <em>training</em> or an <em>in-sample</em>
dataset. Techniques available for selecting a model depend upon whether
the outcomes <span class="math inline">\(X\)</span> are discrete, continuous, or a hybrid of the two,
although the principles are the same.</p>
<p><strong>Graphical and other Basic Summary Measures.</strong> Begin by summarizing the
data graphically and with statistics that do not rely on a specific
parametric form, as summarized in Section <a href="ChapModelSelection.html#S:MS:NonParInf">5.1</a> above.
Specifically, you will want to graph both the empirical distribution and
density functions. Particularly for loss data that contain many zeros
and that can be skewed, deciding on the appropriate scale (e.g.,
logarithmic) may present some difficulties. For discrete data, tables
are often preferred. Determine sample moments, such as the mean and
variance, as well as selected quantiles, including the minimum, maximum,
and the median. For discrete data, the mode (or most frequently
occurring value) is usually helpful.</p>
<p>These summaries, as well as your familiarity of industry practice, will
suggest one or more candidate parametric models. Generally, start with
the simpler parametric models (for example, one parameter exponential
before a two parameter gamma), gradually introducing more complexity
into the modeling process.</p>
<p>Critique the candidate parametric model numerically and graphically. For
the graphs, utilize the tools introduced in Section
<a href="ChapModelSelection.html#S:MS:ToolsModelSelection">5.3.1</a> such as <span class="math inline">\(pp\)</span> and <span class="math inline">\(qq\)</span> plots. For the
numerical assessments, examine the statistical significance of
parameters and try to eliminate parameters that do not provide
additional information. In addition to statistical significance of
parameters, you may use the following model comparison tools.</p>
<p><strong>Likelihood Ratio Tests.</strong> For comparing model fits, if one model is a
subset of another, then a likelihood ratio test may be employed; the
general approach to likelihood ratio testing is described in Appendix
Sections <a href="CAppA.html#S:AppA:HT:LRT">16.4.3</a> and <a href="CAppC.html#S:AppC:MLEModelVal">18.3.2</a>.</p>
<p><strong>Goodness of Fit Statistics.</strong> Generally, models are not proper subsets
of one another in which case overall goodness of fit statistics are
helpful for comparing models. <em>Information criteria</em> are one type of
goodness of statistic. The most widely used examples are Akaikes
Information Criterion (<em>AIC</em>) and the (Schwarz) Bayesian Information
Criterion (<em>BIC</em>); they are widely cited because they can be readily
generalized to multivariate settings. Appendix Section
<a href="CAppA.html#S:AppA:HT:IC">16.4.4</a> provides a summary of these statistics.</p>
<p>For selecting the appropriate distribution, statistics that compare a
parametric fit to a nonparametric alternative, summarized in Section
<a href="ChapModelSelection.html#S:MS:Tools:Stats">5.3.1.2</a>, are useful for model comparison. For discrete
data, a <em>goodness of fit</em> statistic (as described in Section
<a href="ChapFrequency-Modeling.html#S:goodness-of-fit">3.7</a>) is generally preferred as it is more intuitive
and simpler to explain.</p>
</div>
<div id="model-selection-based-on-a-test-dataset" class="section level3 hasAnchor" number="5.3.4">
<h3><span class="header-section-number">5.3.4</span> Model Selection Based on a Test Dataset<a href="ChapModelSelection.html#model-selection-based-on-a-test-dataset" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><a href="#" class="tooltip" style="color:green"><em>Model validation</em><span style="font-size:8pt">The process of confirming that the proposed model is appropriate.</span></a> introduced in Section <a href="ChapDataAnalytics.html#S:Process">2.2</a> is
the process of confirming that the proposed model is appropriate based
on a <em>test</em> or an <em>out-of-sample</em> dataset, especially in light of the
purposes of the investigation. Model validation is important since the
model selection process based only on training or in-sample data can be
susceptible to <a href="#" class="tooltip" style="color:green"><em>data-snooping</em><span style="font-size:8pt">Repeatedly fitting models to a data set without a prior hypothesis of interest.</span></a>, that is, fitting a great
number of models to a single set of data. By looking at a large number
of models, we may overfit the data and understate the natural variation
in our representation.</p>
<p>Selecting a model based only on in-sample data also does not support the
goal of <a href="#" class="tooltip" style="color:green"><em>predictive inference</em><span style="font-size:8pt">Preditive inference is the process of using past data observations to predict future observations.</span></a>. Particularly in actuarial
applications, our goal is to make statements about <em>new</em> experience
rather than a dataset at hand. For example, we use claims experience
from one year to develop a model that can be used to price insurance
contracts for the following year. As an analogy, we can think about the
training dataset as experience from one year that is used to predict the
behavior of the next years test dataset.</p>
<p>We can respond to these criticisms by using a technique known as
<strong>out-of-sample validation</strong>. The ideal situation is to have available
two sets of data, one for training, or model development, and the other
for testing, or model validation. We initially develop one or several
models on the first dataset that we call <em>candidate</em> models. Then, the
relative performance of the candidate models can be measured on the
second set of data. In this way, the data used to validate the model are
unaffected by the procedures used to formulate the model.</p>
<p><strong>Random Split of the Data.</strong> Unfortunately, rarely will two sets of
data be available to the investigator. As mentioned in Section
<a href="ChapDataAnalytics.html#S:Process">2.2</a>, we can implement the validation process by splitting
the dataset into <strong>training</strong> and <strong>test</strong> subsamples, respectively.
Figure <a href="ChapModelSelection.html#fig:ModelValidation">5.14</a> illustrates this splitting of the
data.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ModelValidation"></span>
<img src="LossDataAnalytics_files/figure-html/ModelValidation-1.png" alt="Model Validation. A dataset is randomly split into two subsamples." width="60%" />
<p class="caption">
Figure 5.14: <strong>Model Validation. A dataset is randomly split into two subsamples.</strong>
</p>
</div>
<p>Various researchers recommend different proportions for the allocation.
<span class="citation">Snee (<a href="#ref-snee1977validation" role="doc-biblioref">1977</a>)</span> suggests that data-splitting not be done unless the
sample size is moderately large. The guidelines of <span class="citation">Picard and Berk (<a href="#ref-picard1990data" role="doc-biblioref">1990</a>)</span> show
that the greater the number of parameters to be estimated, the greater
the proportion of observations is needed for the training subsample for
model development.</p>
<p><strong>Selecting a Distribution.</strong> Still, our focus so far has been to select
a distribution for a dataset that can be used for actuarial modeling
without additional explanatory or input variables <span class="math inline">\(x_1, \ldots, x_k\)</span>.
Even in this more fundamental problem, the model validation approach is
valuable. If we base all inference on only in-sample data, then there is
a tendency to select more complicated models than needed. For example,
we might select a four parameter GB2, generalized beta of the second
kind, distribution when only a two parameter Pareto is needed.
Information criteria such as <a href="#" class="tooltip" style="color:green"><em>AIC</em><span style="font-size:8pt">A goodness of fit measure of a statistical model that describes how well it fits a set of observations.</span></a> and <a href="#" class="tooltip" style="color:green"><em>BIC</em><span style="font-size:8pt">Bayesian information criterion</span></a>
introduced in Appendix Section <a href="CAppA.html#S:AppA:HT:IC">16.4.4</a> include penalties for
model complexity and thus provide protection against over-fitting, but
using a test sample may also help achieve parsimonious models. From a
quote often attributed to Albert Einstein, we want to use the simplest
model as possible but no simpler.</p>
<hr />
<p><strong>Example 5.3.3. Wisconsin Property Fund.</strong> For the 2010 property fund
data from Section <a href="ChapIntro.html#S:LGPIF">1.3</a>, we may try to select a severity
distribution based on out-of-sample prediction. In particular, we may
randomly select 1,000 observations as our training data, and use the
remaining 377 claims to validate the two models based respectively on
gamma and Pareto distributions. For illustration purposes, We compare
the Kolmogorov-Smirnov statistics respectively for the training and test
datasets using the models fitted from training data.</p>
<h5 style="text-align: center;">
<a id="displayCode.ValidationKS.1" href="javascript:togglecode('toggleCode.ValidationKS.1','displayCode.ValidationKS.1');"><i><strong>Show R Code for Kolmogorov-Smirnov model validation</strong></i></a>
</h5>
<div id="toggleCode.ValidationKS.1" style="display: none">
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="ChapModelSelection.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb45-2"><a href="ChapModelSelection.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(VGAM)</span>
<span id="cb45-3"><a href="ChapModelSelection.html#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(goftest)</span>
<span id="cb45-4"><a href="ChapModelSelection.html#cb45-4" aria-hidden="true" tabindex="-1"></a>claim_lev <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Data/CLAIMLEVEL.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb45-5"><a href="ChapModelSelection.html#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2010 subset</span></span>
<span id="cb45-6"><a href="ChapModelSelection.html#cb45-6" aria-hidden="true" tabindex="-1"></a>claim_data <span class="ot">&lt;-</span> <span class="fu">subset</span>(claim_lev, Year <span class="sc">==</span> <span class="dv">2010</span>)</span>
<span id="cb45-7"><a href="ChapModelSelection.html#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="ChapModelSelection.html#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomly re-order the data - &#39;shuffle it&#39;</span></span>
<span id="cb45-9"><a href="ChapModelSelection.html#cb45-9" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(claim_data)</span>
<span id="cb45-10"><a href="ChapModelSelection.html#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb45-11"><a href="ChapModelSelection.html#cb45-11" aria-hidden="true" tabindex="-1"></a>rdata <span class="ot">&lt;-</span> claim_data[<span class="fu">sample</span>(n), ]</span>
<span id="cb45-12"><a href="ChapModelSelection.html#cb45-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-13"><a href="ChapModelSelection.html#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Use training data to fit the models, and training and test data to calculate</span></span>
<span id="cb45-14"><a href="ChapModelSelection.html#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="co"># KS statistics</span></span>
<span id="cb45-15"><a href="ChapModelSelection.html#cb45-15" aria-hidden="true" tabindex="-1"></a>train.id <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>  <span class="co"># indices for training data</span></span>
<span id="cb45-16"><a href="ChapModelSelection.html#cb45-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-17"><a href="ChapModelSelection.html#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Pareto</span></span>
<span id="cb45-18"><a href="ChapModelSelection.html#cb45-18" aria-hidden="true" tabindex="-1"></a>fit.pareto <span class="ot">&lt;-</span> <span class="fu">vglm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, paretoII, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">data =</span> rdata[train.id, ])</span>
<span id="cb45-19"><a href="ChapModelSelection.html#cb45-19" aria-hidden="true" tabindex="-1"></a>InSamplePareto <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(rdata[train.id, ]<span class="sc">$</span>Claim, <span class="st">&quot;pparetoII&quot;</span>, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">shape =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">2</span>]),</span>
<span id="cb45-20"><a href="ChapModelSelection.html#cb45-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">scale =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">1</span>]))</span>
<span id="cb45-21"><a href="ChapModelSelection.html#cb45-21" aria-hidden="true" tabindex="-1"></a>OutSamplePareto <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(rdata[<span class="sc">-</span>train.id, ]<span class="sc">$</span>Claim, <span class="st">&quot;pparetoII&quot;</span>, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">shape =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">2</span>]),</span>
<span id="cb45-22"><a href="ChapModelSelection.html#cb45-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">scale =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">1</span>]))</span>
<span id="cb45-23"><a href="ChapModelSelection.html#cb45-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Gamma</span></span>
<span id="cb45-24"><a href="ChapModelSelection.html#cb45-24" aria-hidden="true" tabindex="-1"></a>fit.gamma <span class="ot">&lt;-</span> <span class="fu">glm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> rdata[train.id, ], <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb45-25"><a href="ChapModelSelection.html#cb45-25" aria-hidden="true" tabindex="-1"></a>gamma_theta <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.gamma)) <span class="sc">*</span> <span class="fu">gamma.dispersion</span>(fit.gamma)</span>
<span id="cb45-26"><a href="ChapModelSelection.html#cb45-26" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">gamma.dispersion</span>(fit.gamma)</span>
<span id="cb45-27"><a href="ChapModelSelection.html#cb45-27" aria-hidden="true" tabindex="-1"></a>InSampleGamma <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(rdata[train.id, ]<span class="sc">$</span>Claim, <span class="st">&quot;pgamma&quot;</span>, <span class="at">shape =</span> alpha, <span class="at">scale =</span> gamma_theta)</span>
<span id="cb45-28"><a href="ChapModelSelection.html#cb45-28" aria-hidden="true" tabindex="-1"></a>OutSampleGamma <span class="ot">&lt;-</span> <span class="fu">ks.test</span>(rdata[<span class="sc">-</span>train.id, ]<span class="sc">$</span>Claim, <span class="st">&quot;pgamma&quot;</span>, <span class="at">shape =</span> alpha, <span class="at">scale =</span> gamma_theta)</span></code></pre></div>
<p>Based on in-sample prediction, the Kolmogorov-Smirnov goodness of fit
statistic for the gamma distribution turns out to be
0.2771 and for the Pareto
distribution is 0.046. Based on
out-of-sample prediction, the Kolmogorov-Smirnov goodness of fit
statistic for the gamma distribution turns out to be
0.2693 and for the Pareto
distribution is 0.0746. Based on
both in-sample and out-of-sample prediction, the Pareto model seems to
give considerably better goodness of fit under the random seed used in
the code for splitting the training and test data.</p>
</div>
<p><strong>Model Validation Statistics.</strong> In addition to the nonparametric tools
introduced earlier for comparing marginal distributions of the outcome
or output variables ignoring potential explanatory or input variables,
much of the literature supporting the establishment of a model
validation process is based on regression and classification models that
you can think of as an <em>input-output</em> problem (<span class="citation">James et al. (<a href="#ref-james2013introduction" role="doc-biblioref">2013</a>)</span>).
That is, we have several inputs or predictor variables
<span class="math inline">\(x_1, \ldots, x_k\)</span> that are related to an output or outcome <span class="math inline">\(y\)</span> through
a function such as <span class="math display">\[y = \mathrm{g}\left(x_1, \ldots, x_k\right).\]</span>For
model selection, one uses the training sample to develop an estimate of
<span class="math inline">\(\mathrm{g}\)</span>, say, <span class="math inline">\(\hat{\mathrm{g}}\)</span>, and then calibrate the average
distance from the observed outcomes to the predictions using a criterion
of the form</p>
<span class="math display" id="eq:OutSampleCriter">\[\begin{equation}
\frac{1}{n}\sum_i \mathrm{d}(y_i,\hat{\mathrm{g}}\left(x_{i1}, \ldots, x_{ik}\right) ) .
\tag{5.6}
\end{equation}\]</span>
<p>Here, d is some measure of distance and the sum <span class="math inline">\(i\)</span> is over the test
data. The function <span class="math inline">\(\mathrm{g}\)</span> may not have an analytical form and can
be estimated for each observation using the different different types of
algorithms and models introduced earlier in Section
<a href="ChapDataAnalytics.html#S:ManyVarAnalytics">2.4</a>. In many regression applications, it is common
to use the squared Euclidean distance of the form
<span class="math inline">\(\mathrm{d}(y_i,\mathrm{g}) = (y_i-\mathrm{g})^2\)</span> under which the
criterion in equation <a href="ChapModelSelection.html#eq:OutSampleCriter">(5.6)</a> is called the <strong>mean
squared error (MSE)</strong>. Using data simulated from linear models, Example
2.3.1 uses the <strong>root mean squared error (Rmse)</strong> which is the squared
root of the MSE. From equation <a href="ChapModelSelection.html#eq:OutSampleCriter">(5.6)</a>, the MSE
criteria works the best for linear models under normal distributions
with constant variance, as minimizing MSE is equivalent to the maximum
likelihood and least squares criterion in training data. In data
analytics and linear regression, one may consider transformations of the
outcome variable in order for the MSE criteria to work more effectively.
In actuarial applications, the <strong>mean absolute error (MAE)</strong> under the
Euclidean distance <span class="math inline">\(\mathrm{d}(y_i,\mathrm{g}) = |y_i-\mathrm{g}|\)</span> may
be preferred because of the skewed nature of loss data. For right-skewed
outcomes, it may require a larger sample size for the validation
statistics to pickup the correct model when large outlying values of <span class="math inline">\(y\)</span>
can have a large effect on the measures. Following Example 2.3.1, we use
simulated data in Examples 5.3.4 through 5.3.7 to compare the AIC
information criteria from Appendix Chapter <a href="CAppA.html#S:AppA:HT:IC">16.4.4</a> with
out-of-sample MSE and MAE criterion for selecting the distribution and
input variables for outcomes that are respectively from normal and
right-skewed distributions including lognormal and gamma distributions.
For right skewed distributions, we find that the AIC information
criteria seems to work consistently for selecting the correct
distributional form and mean structure (input variables), whereas
out-of-sample MSE and MAE may not work for right-skewed outcomes like
those from gamma distributions, even with relatively large sample sizes.
Therefore, model validation statistics commonly used in data analytics
may only work for minimizing specific cost functions, such as the MAE
that represents the average absolute error for out-of-sample prediction,
and do not necessarily guarantee correct selection of the underlying
data generating mechanism.</p>
<hr />
<p><strong>Example 5.3.4. In-sample AIC and out-of-sample MSE for normal
outcomes</strong>. Example 2.3.1 assumes that there is a set of claims that
potentially varies by a single categorical variable with six levels. To
illustrating in-sample over-fitting, it also assumes that two of the six
levels share a common mean that differs from rest of levels. For Example
2.3.1, the claim amounts were generated from a linear model with
constant variance, for which in-sample AIC and out-of-sample Rmse
provide consistent results from the cross-validation procedure to be
introduced in the next section. Here, we may use the same data
generation mechanism to compare the performance of in-sample AIC with
the in-sample and out-of-sample Rmse criteria. In particular, we
generate a total of 200 samples and split them equally into the training
and test datasets. From the output table, we observe the two-level model
was correctly selected by both in-sample AIC and out-of-sample MSE
criteria, whereas in-sample MSE prefers an over-fitted model with six
levels. Thus, due to concerns of model over-fitting, we do not use
in-sample distance measures such as the MSE and MAE criterion that
favors more complicated models.</p>
<h5 style="text-align: center;">
<a id="displayCode.ValidationStat.1" href="javascript:togglecode('toggleCode.ValidationStat.1','displayCode.ValidationStat.1');"><i><strong>Show R Code for model validation statistics</strong></i></a>
</h5>
<div id="toggleCode.ValidationStat.1" style="display: none">
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="ChapModelSelection.html#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb46-2"><a href="ChapModelSelection.html#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="ChapModelSelection.html#cb46-3" aria-hidden="true" tabindex="-1"></a>rmse <span class="ot">&lt;-</span> Metrics<span class="sc">::</span>rmse</span>
<span id="cb46-4"><a href="ChapModelSelection.html#cb46-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb46-5"><a href="ChapModelSelection.html#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb46-6"><a href="ChapModelSelection.html#cb46-6" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb46-7"><a href="ChapModelSelection.html#cb46-7" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>((u <span class="sc">==</span> <span class="dv">4</span>) <span class="sc">+</span> (u <span class="sc">==</span> <span class="dv">5</span>))</span>
<span id="cb46-8"><a href="ChapModelSelection.html#cb46-8" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(u)</span>
<span id="cb46-9"><a href="ChapModelSelection.html#cb46-9" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">*</span> (x1 <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb46-10"><a href="ChapModelSelection.html#cb46-10" aria-hidden="true" tabindex="-1"></a>xyData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x1, x2, y)</span>
<span id="cb46-11"><a href="ChapModelSelection.html#cb46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-12"><a href="ChapModelSelection.html#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Use training data to fit the models, and training and test data to obtain MSE</span></span>
<span id="cb46-13"><a href="ChapModelSelection.html#cb46-13" aria-hidden="true" tabindex="-1"></a>train.id <span class="ot">&lt;-</span> <span class="fu">sample</span>(n, n<span class="sc">/</span><span class="dv">2</span>)  <span class="co"># indices for training data</span></span>
<span id="cb46-14"><a href="ChapModelSelection.html#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="ChapModelSelection.html#cb46-15" aria-hidden="true" tabindex="-1"></a>Rmse.train <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">3</span>) <span class="ot">-&gt;</span> Rmse.test <span class="ot">-&gt;</span> AIC.train</span>
<span id="cb46-16"><a href="ChapModelSelection.html#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="ChapModelSelection.html#cb46-17" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> xyData[<span class="sc">-</span>train.id, ]</span>
<span id="cb46-18"><a href="ChapModelSelection.html#cb46-18" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> xyData[train.id, ]</span>
<span id="cb46-19"><a href="ChapModelSelection.html#cb46-19" aria-hidden="true" tabindex="-1"></a>model0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train)</span>
<span id="cb46-20"><a href="ChapModelSelection.html#cb46-20" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> train)</span>
<span id="cb46-21"><a href="ChapModelSelection.html#cb46-21" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x2, <span class="at">data =</span> train)</span>
<span id="cb46-22"><a href="ChapModelSelection.html#cb46-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-23"><a href="ChapModelSelection.html#cb46-23" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model0))</span>
<span id="cb46-24"><a href="ChapModelSelection.html#cb46-24" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model1))</span>
<span id="cb46-25"><a href="ChapModelSelection.html#cb46-25" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model2))</span>
<span id="cb46-26"><a href="ChapModelSelection.html#cb46-26" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model0, test))</span>
<span id="cb46-27"><a href="ChapModelSelection.html#cb46-27" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model1, test))</span>
<span id="cb46-28"><a href="ChapModelSelection.html#cb46-28" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model2, test))</span>
<span id="cb46-29"><a href="ChapModelSelection.html#cb46-29" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model0)</span>
<span id="cb46-30"><a href="ChapModelSelection.html#cb46-30" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model1)</span>
<span id="cb46-31"><a href="ChapModelSelection.html#cb46-31" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model2)</span>
<span id="cb46-32"><a href="ChapModelSelection.html#cb46-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-33"><a href="ChapModelSelection.html#cb46-33" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.train, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(Rmse.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(AIC.train,</span>
<span id="cb46-34"><a href="ChapModelSelection.html#cb46-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb46-35"><a href="ChapModelSelection.html#cb46-35" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb46-36"><a href="ChapModelSelection.html#cb46-36" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Train&quot;</span>, <span class="st">&quot;Rmse - Test&quot;</span>, <span class="st">&quot;AIC - Train&quot;</span>)</span>
<span id="cb46-37"><a href="ChapModelSelection.html#cb46-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-38"><a href="ChapModelSelection.html#cb46-38" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Model Selection based on MSE and AIC for normal outputs**&quot;</span>,</span>
<span id="cb46-39"><a href="ChapModelSelection.html#cb46-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-58">Table 5.1: </span><strong>Model Selection based on MSE and AIC for normal outputs</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Train</td>
<td align="right">1.186</td>
<td align="right">1.016</td>
<td align="right">0.990</td>
</tr>
<tr class="even">
<td align="left">Rmse - Test</td>
<td align="right">1.081</td>
<td align="right">0.958</td>
<td align="right">1.012</td>
</tr>
<tr class="odd">
<td align="left">AIC - Train</td>
<td align="right">321.935</td>
<td align="right">293.028</td>
<td align="right">295.694</td>
</tr>
</tbody>
</table>
</div>
<hr />
<p><strong>Example 5.3.5. MSE and MAE for right-skewed outcomes - lognormal
claims</strong>. For claims modeling, one may wonder how the MSE and MAE types
of criterion may perform for right-skewed data. Using the same data
generating procedure, we may generate lognormal claim amounts by
exponentiating the normal outcomes from the previous example. We fit the
lognormal claim amounts with gamma and lognormal regression commonly
used for ratemaking and claims analytics. For the specific data
generating mechanism, we observe that it requires a larger sample size
for out-of-sample Rmse and MAE to select the correct distributional form
and mean structure, when compared with in-sample AIC criteria. The AIC
criteria is able to pick out the correct model with a sample size of
200, while out-of-sample MSE and MAE fail to. Thus, for right skewed
output, precautions need to be taken when using model validation
statistics that may be sensitive to large claim values, particularly
when the sample size is relatively small.</p>
<h5 style="text-align: center;">
<a id="displayCode.ValidationStat.2" href="javascript:togglecode('toggleCode.ValidationStat.2','displayCode.ValidationStat.2');"><i><strong>Show R Code for model validation statistics for lognormal outputs</strong></i></a>
</h5>
<div id="toggleCode.ValidationStat.2" style="display: none">
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="ChapModelSelection.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb47-2"><a href="ChapModelSelection.html#cb47-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb47-3"><a href="ChapModelSelection.html#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb47-4"><a href="ChapModelSelection.html#cb47-4" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb47-5"><a href="ChapModelSelection.html#cb47-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>((u <span class="sc">==</span> <span class="dv">4</span>) <span class="sc">+</span> (u <span class="sc">==</span> <span class="dv">5</span>))</span>
<span id="cb47-6"><a href="ChapModelSelection.html#cb47-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(u)</span>
<span id="cb47-7"><a href="ChapModelSelection.html#cb47-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">*</span> (x1 <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb47-8"><a href="ChapModelSelection.html#cb47-8" aria-hidden="true" tabindex="-1"></a>exp.y <span class="ot">&lt;-</span> <span class="fu">exp</span>(y)</span>
<span id="cb47-9"><a href="ChapModelSelection.html#cb47-9" aria-hidden="true" tabindex="-1"></a>xyData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x1, x2, y, exp.y)</span>
<span id="cb47-10"><a href="ChapModelSelection.html#cb47-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-11"><a href="ChapModelSelection.html#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Use training data to fit the models, and training and test data to obtain</span></span>
<span id="cb47-12"><a href="ChapModelSelection.html#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE/MAE</span></span>
<span id="cb47-13"><a href="ChapModelSelection.html#cb47-13" aria-hidden="true" tabindex="-1"></a>train.id <span class="ot">&lt;-</span> <span class="fu">sample</span>(n, n<span class="sc">/</span><span class="dv">2</span>)  <span class="co"># indices for training data</span></span>
<span id="cb47-14"><a href="ChapModelSelection.html#cb47-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-15"><a href="ChapModelSelection.html#cb47-15" aria-hidden="true" tabindex="-1"></a>Rmse.train <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">3</span>) <span class="ot">-&gt;</span> Rmse.test <span class="ot">-&gt;</span> mae.train <span class="ot">-&gt;</span> mae.test <span class="ot">-&gt;</span> AIC.train</span>
<span id="cb47-16"><a href="ChapModelSelection.html#cb47-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-17"><a href="ChapModelSelection.html#cb47-17" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> xyData[<span class="sc">-</span>train.id, ]</span>
<span id="cb47-18"><a href="ChapModelSelection.html#cb47-18" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> xyData[train.id, ]</span>
<span id="cb47-19"><a href="ChapModelSelection.html#cb47-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-20"><a href="ChapModelSelection.html#cb47-20" aria-hidden="true" tabindex="-1"></a><span class="co"># fit normal models</span></span>
<span id="cb47-21"><a href="ChapModelSelection.html#cb47-21" aria-hidden="true" tabindex="-1"></a>model0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train)</span>
<span id="cb47-22"><a href="ChapModelSelection.html#cb47-22" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> train)</span>
<span id="cb47-23"><a href="ChapModelSelection.html#cb47-23" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x2, <span class="at">data =</span> train)</span>
<span id="cb47-24"><a href="ChapModelSelection.html#cb47-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-25"><a href="ChapModelSelection.html#cb47-25" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Rmse and MAE based on the predicted mean from lognormal</span></span>
<span id="cb47-26"><a href="ChapModelSelection.html#cb47-26" aria-hidden="true" tabindex="-1"></a><span class="co"># distributions</span></span>
<span id="cb47-27"><a href="ChapModelSelection.html#cb47-27" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-28"><a href="ChapModelSelection.html#cb47-28" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-29"><a href="ChapModelSelection.html#cb47-29" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-30"><a href="ChapModelSelection.html#cb47-30" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-31"><a href="ChapModelSelection.html#cb47-31" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-32"><a href="ChapModelSelection.html#cb47-32" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-33"><a href="ChapModelSelection.html#cb47-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-34"><a href="ChapModelSelection.html#cb47-34" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-35"><a href="ChapModelSelection.html#cb47-35" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-36"><a href="ChapModelSelection.html#cb47-36" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-37"><a href="ChapModelSelection.html#cb47-37" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-38"><a href="ChapModelSelection.html#cb47-38" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-39"><a href="ChapModelSelection.html#cb47-39" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb47-40"><a href="ChapModelSelection.html#cb47-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-41"><a href="ChapModelSelection.html#cb47-41" aria-hidden="true" tabindex="-1"></a><span class="co"># AIC(model0) 2*2-2*sum(dnorm(train$y,predict(model0),sigma(model0),log = T))</span></span>
<span id="cb47-42"><a href="ChapModelSelection.html#cb47-42" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model0<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0),</span>
<span id="cb47-43"><a href="ChapModelSelection.html#cb47-43" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sigma</span>(model0), <span class="at">log =</span> T))</span>
<span id="cb47-44"><a href="ChapModelSelection.html#cb47-44" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model1<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1),</span>
<span id="cb47-45"><a href="ChapModelSelection.html#cb47-45" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sigma</span>(model1), <span class="at">log =</span> T))</span>
<span id="cb47-46"><a href="ChapModelSelection.html#cb47-46" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model2<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2),</span>
<span id="cb47-47"><a href="ChapModelSelection.html#cb47-47" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sigma</span>(model2), <span class="at">log =</span> T))</span>
<span id="cb47-48"><a href="ChapModelSelection.html#cb47-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-49"><a href="ChapModelSelection.html#cb47-49" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.train, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(Rmse.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.train,</span>
<span id="cb47-50"><a href="ChapModelSelection.html#cb47-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(AIC.train, <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb47-51"><a href="ChapModelSelection.html#cb47-51" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb47-52"><a href="ChapModelSelection.html#cb47-52" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Train&quot;</span>, <span class="st">&quot;Rmse - Test&quot;</span>, <span class="st">&quot;MAE - Train&quot;</span>, <span class="st">&quot;MAE - Test&quot;</span>,</span>
<span id="cb47-53"><a href="ChapModelSelection.html#cb47-53" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;AIC - Train&quot;</span>)</span>
<span id="cb47-54"><a href="ChapModelSelection.html#cb47-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-55"><a href="ChapModelSelection.html#cb47-55" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Model Selection based on in-sample AIC and out-of-sample MSE and MAE from lognormal model**&quot;</span>,</span>
<span id="cb47-56"><a href="ChapModelSelection.html#cb47-56" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-59">Table 5.2: </span><strong>Model Selection based on in-sample AIC and out-of-sample MSE and MAE from lognormal model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Train</td>
<td align="right">4.365</td>
<td align="right">4.185</td>
<td align="right">4.192</td>
</tr>
<tr class="even">
<td align="left">Rmse - Test</td>
<td align="right">3.881</td>
<td align="right">3.686</td>
<td align="right">3.679</td>
</tr>
<tr class="odd">
<td align="left">MAE - Train</td>
<td align="right">2.077</td>
<td align="right">1.821</td>
<td align="right">1.807</td>
</tr>
<tr class="even">
<td align="left">MAE - Test</td>
<td align="right">2.166</td>
<td align="right">2.056</td>
<td align="right">2.073</td>
</tr>
<tr class="odd">
<td align="left">AIC - Train</td>
<td align="right">1800.716</td>
<td align="right">1681.550</td>
<td align="right">1686.142</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="ChapModelSelection.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fit gamma models</span></span>
<span id="cb48-2"><a href="ChapModelSelection.html#cb48-2" aria-hidden="true" tabindex="-1"></a>model0 <span class="ot">&lt;-</span> <span class="fu">glm</span>(exp.y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb48-3"><a href="ChapModelSelection.html#cb48-3" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(exp.y <span class="sc">~</span> x1, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb48-4"><a href="ChapModelSelection.html#cb48-4" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(exp.y <span class="sc">~</span> x2, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb48-5"><a href="ChapModelSelection.html#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="ChapModelSelection.html#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Rmse and MAE based on the predicted mean from gamma distributions</span></span>
<span id="cb48-7"><a href="ChapModelSelection.html#cb48-7" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0))</span>
<span id="cb48-8"><a href="ChapModelSelection.html#cb48-8" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1))</span>
<span id="cb48-9"><a href="ChapModelSelection.html#cb48-9" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2))</span>
<span id="cb48-10"><a href="ChapModelSelection.html#cb48-10" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0, test))</span>
<span id="cb48-11"><a href="ChapModelSelection.html#cb48-11" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1, test))</span>
<span id="cb48-12"><a href="ChapModelSelection.html#cb48-12" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2, test))</span>
<span id="cb48-13"><a href="ChapModelSelection.html#cb48-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-14"><a href="ChapModelSelection.html#cb48-14" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0))</span>
<span id="cb48-15"><a href="ChapModelSelection.html#cb48-15" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1))</span>
<span id="cb48-16"><a href="ChapModelSelection.html#cb48-16" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2))</span>
<span id="cb48-17"><a href="ChapModelSelection.html#cb48-17" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0, test))</span>
<span id="cb48-18"><a href="ChapModelSelection.html#cb48-18" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1, test))</span>
<span id="cb48-19"><a href="ChapModelSelection.html#cb48-19" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2, test))</span>
<span id="cb48-20"><a href="ChapModelSelection.html#cb48-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-21"><a href="ChapModelSelection.html#cb48-21" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model0)</span>
<span id="cb48-22"><a href="ChapModelSelection.html#cb48-22" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model1)</span>
<span id="cb48-23"><a href="ChapModelSelection.html#cb48-23" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model2)</span>
<span id="cb48-24"><a href="ChapModelSelection.html#cb48-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-25"><a href="ChapModelSelection.html#cb48-25" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.train, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(Rmse.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.train,</span>
<span id="cb48-26"><a href="ChapModelSelection.html#cb48-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(AIC.train, <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb48-27"><a href="ChapModelSelection.html#cb48-27" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb48-28"><a href="ChapModelSelection.html#cb48-28" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Train&quot;</span>, <span class="st">&quot;Rmse - Test&quot;</span>, <span class="st">&quot;MAE - Train&quot;</span>, <span class="st">&quot;MAE - Test&quot;</span>,</span>
<span id="cb48-29"><a href="ChapModelSelection.html#cb48-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;AIC - Train&quot;</span>)</span>
<span id="cb48-30"><a href="ChapModelSelection.html#cb48-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-31"><a href="ChapModelSelection.html#cb48-31" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Model Selection based on in-sample AIC and out-of-sample MSE and MAE from gamma model**&quot;</span>,</span>
<span id="cb48-32"><a href="ChapModelSelection.html#cb48-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-59">Table 5.2: </span><strong>Model Selection based on in-sample AIC and out-of-sample MSE and MAE from gamma model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Train</td>
<td align="right">4.634</td>
<td align="right">4.572</td>
<td align="right">4.572</td>
</tr>
<tr class="even">
<td align="left">Rmse - Test</td>
<td align="right">4.298</td>
<td align="right">4.232</td>
<td align="right">4.235</td>
</tr>
<tr class="odd">
<td align="left">MAE - Train</td>
<td align="right">1.862</td>
<td align="right">1.815</td>
<td align="right">1.817</td>
</tr>
<tr class="even">
<td align="left">MAE - Test</td>
<td align="right">2.127</td>
<td align="right">2.123</td>
<td align="right">2.128</td>
</tr>
<tr class="odd">
<td align="left">AIC - Train</td>
<td align="right">1906.398</td>
<td align="right">1789.312</td>
<td align="right">1795.662</td>
</tr>
</tbody>
</table>
</div>
<hr />
<p><strong>Example 5.3.6. MSE and MAE for right-skewed outcomes - gamma claims</strong>.
For right-skewed outcomes, we may be interested in studying how the MSE
and MAE types of measures work for another loss severity distribution,
the gamma distribution, that is widely used in ratemaking and claims
analytics. Here, we use a similar mean structure for generating claims
amounts based on a gamma regression with the log link function. We fit
the data using gamma regression and lognormal regression. For gamma
outcomes, the table shows that out-of-sample MSE and MAE criterion fail
to select the correct distributional form or the mean structure even
with a total of 1000 samples. By changing the gamma shape parameter, you
may see that the out-of-sample MSE and MAE criterion work in certain
settings for correctly selecting the distributional form or the mean
structure, but the performance of such model validation statistics does
not seem to be consistent across different parameter values and sample
sizes for right-skewed gamma outcomes. Again, the AIC criteria seems to
be working consistently in selecting the correct distribution and mean
structure for the data generated from gamma distributions, even with a
smaller sample size of 200.</p>
<h5 style="text-align: center;">
<a id="displayCode.ValidationStat.3" href="javascript:togglecode('toggleCode.ValidationStat.3','displayCode.ValidationStat.3');"><i><strong>Show R Code for model validation statistics for gamma outputs</strong></i></a>
</h5>
<div id="toggleCode.ValidationStat.3" style="display: none">
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="ChapModelSelection.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb49-2"><a href="ChapModelSelection.html#cb49-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb49-3"><a href="ChapModelSelection.html#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)</span>
<span id="cb49-4"><a href="ChapModelSelection.html#cb49-4" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-5"><a href="ChapModelSelection.html#cb49-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>((u <span class="sc">==</span> <span class="dv">4</span>) <span class="sc">+</span> (u <span class="sc">==</span> <span class="dv">5</span>))</span>
<span id="cb49-6"><a href="ChapModelSelection.html#cb49-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(u)</span>
<span id="cb49-7"><a href="ChapModelSelection.html#cb49-7" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">as.numeric</span>(x1 <span class="sc">==</span> <span class="dv">1</span>))  <span class="co"># gamma mean</span></span>
<span id="cb49-8"><a href="ChapModelSelection.html#cb49-8" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb49-9"><a href="ChapModelSelection.html#cb49-9" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> alpha<span class="sc">/</span>mu</span>
<span id="cb49-10"><a href="ChapModelSelection.html#cb49-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(n, alpha, beta)</span>
<span id="cb49-11"><a href="ChapModelSelection.html#cb49-11" aria-hidden="true" tabindex="-1"></a>log.y <span class="ot">&lt;-</span> <span class="fu">log</span>(y)</span>
<span id="cb49-12"><a href="ChapModelSelection.html#cb49-12" aria-hidden="true" tabindex="-1"></a>xyData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x1, x2, y, log.y)</span>
<span id="cb49-13"><a href="ChapModelSelection.html#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="ChapModelSelection.html#cb49-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Use training data to fit the models, and training and test data to obtain</span></span>
<span id="cb49-15"><a href="ChapModelSelection.html#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="co"># MSE/MAE</span></span>
<span id="cb49-16"><a href="ChapModelSelection.html#cb49-16" aria-hidden="true" tabindex="-1"></a>train.id <span class="ot">&lt;-</span> <span class="fu">sample</span>(n, n<span class="sc">/</span><span class="dv">2</span>)  <span class="co"># indices for training data</span></span>
<span id="cb49-17"><a href="ChapModelSelection.html#cb49-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-18"><a href="ChapModelSelection.html#cb49-18" aria-hidden="true" tabindex="-1"></a>Rmse.train <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">3</span>) <span class="ot">-&gt;</span> Rmse.test <span class="ot">-&gt;</span> mae.train <span class="ot">-&gt;</span> mae.test <span class="ot">-&gt;</span> AIC.train</span>
<span id="cb49-19"><a href="ChapModelSelection.html#cb49-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-20"><a href="ChapModelSelection.html#cb49-20" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> xyData[<span class="sc">-</span>train.id, ]</span>
<span id="cb49-21"><a href="ChapModelSelection.html#cb49-21" aria-hidden="true" tabindex="-1"></a>train <span class="ot">&lt;-</span> xyData[train.id, ]</span>
<span id="cb49-22"><a href="ChapModelSelection.html#cb49-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-23"><a href="ChapModelSelection.html#cb49-23" aria-hidden="true" tabindex="-1"></a><span class="co"># fit normal models</span></span>
<span id="cb49-24"><a href="ChapModelSelection.html#cb49-24" aria-hidden="true" tabindex="-1"></a>model0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train)</span>
<span id="cb49-25"><a href="ChapModelSelection.html#cb49-25" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.y <span class="sc">~</span> x1, <span class="at">data =</span> train)</span>
<span id="cb49-26"><a href="ChapModelSelection.html#cb49-26" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.y <span class="sc">~</span> x2, <span class="at">data =</span> train)</span>
<span id="cb49-27"><a href="ChapModelSelection.html#cb49-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-28"><a href="ChapModelSelection.html#cb49-28" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Rmse and MAE based on the predicted mean from lognormal</span></span>
<span id="cb49-29"><a href="ChapModelSelection.html#cb49-29" aria-hidden="true" tabindex="-1"></a><span class="co"># distributions</span></span>
<span id="cb49-30"><a href="ChapModelSelection.html#cb49-30" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-31"><a href="ChapModelSelection.html#cb49-31" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-32"><a href="ChapModelSelection.html#cb49-32" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-33"><a href="ChapModelSelection.html#cb49-33" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-34"><a href="ChapModelSelection.html#cb49-34" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-35"><a href="ChapModelSelection.html#cb49-35" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-36"><a href="ChapModelSelection.html#cb49-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-37"><a href="ChapModelSelection.html#cb49-37" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-38"><a href="ChapModelSelection.html#cb49-38" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-39"><a href="ChapModelSelection.html#cb49-39" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-40"><a href="ChapModelSelection.html#cb49-40" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-41"><a href="ChapModelSelection.html#cb49-41" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-42"><a href="ChapModelSelection.html#cb49-42" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb49-43"><a href="ChapModelSelection.html#cb49-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-44"><a href="ChapModelSelection.html#cb49-44" aria-hidden="true" tabindex="-1"></a><span class="co"># AIC(model0) 2*2-2*sum(dnorm(train$y,predict(model0),sigma(model0),log = T))</span></span>
<span id="cb49-45"><a href="ChapModelSelection.html#cb49-45" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model0<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model0),</span>
<span id="cb49-46"><a href="ChapModelSelection.html#cb49-46" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sigma</span>(model0), <span class="at">log =</span> T))</span>
<span id="cb49-47"><a href="ChapModelSelection.html#cb49-47" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model1<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model1),</span>
<span id="cb49-48"><a href="ChapModelSelection.html#cb49-48" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sigma</span>(model1), <span class="at">log =</span> T))</span>
<span id="cb49-49"><a href="ChapModelSelection.html#cb49-49" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model2<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model2),</span>
<span id="cb49-50"><a href="ChapModelSelection.html#cb49-50" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sigma</span>(model2), <span class="at">log =</span> T))</span>
<span id="cb49-51"><a href="ChapModelSelection.html#cb49-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-52"><a href="ChapModelSelection.html#cb49-52" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.train, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(Rmse.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.train,</span>
<span id="cb49-53"><a href="ChapModelSelection.html#cb49-53" aria-hidden="true" tabindex="-1"></a>    <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(AIC.train, <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb49-54"><a href="ChapModelSelection.html#cb49-54" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb49-55"><a href="ChapModelSelection.html#cb49-55" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Train&quot;</span>, <span class="st">&quot;Rmse - Test&quot;</span>, <span class="st">&quot;MAE - Train&quot;</span>, <span class="st">&quot;MAE - Test&quot;</span>,</span>
<span id="cb49-56"><a href="ChapModelSelection.html#cb49-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;AIC - Train&quot;</span>)</span>
<span id="cb49-57"><a href="ChapModelSelection.html#cb49-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-58"><a href="ChapModelSelection.html#cb49-58" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Model Selection based on in-sample AIC and out-of-sample MSE and MAE from lognormal model**&quot;</span>,</span>
<span id="cb49-59"><a href="ChapModelSelection.html#cb49-59" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-60">Table 5.3: </span><strong>Model Selection based on in-sample AIC and out-of-sample MSE and MAE from lognormal model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Train</td>
<td align="right">1.083</td>
<td align="right">0.763</td>
<td align="right">0.760</td>
</tr>
<tr class="even">
<td align="left">Rmse - Test</td>
<td align="right">1.128</td>
<td align="right">0.815</td>
<td align="right">0.812</td>
</tr>
<tr class="odd">
<td align="left">MAE - Train</td>
<td align="right">0.800</td>
<td align="right">0.535</td>
<td align="right">0.529</td>
</tr>
<tr class="even">
<td align="left">MAE - Test</td>
<td align="right">0.830</td>
<td align="right">0.565</td>
<td align="right">0.566</td>
</tr>
<tr class="odd">
<td align="left">AIC - Train</td>
<td align="right">1212.218</td>
<td align="right">864.776</td>
<td align="right">868.794</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="ChapModelSelection.html#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fit gamma models</span></span>
<span id="cb50-2"><a href="ChapModelSelection.html#cb50-2" aria-hidden="true" tabindex="-1"></a>model0 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb50-3"><a href="ChapModelSelection.html#cb50-3" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb50-4"><a href="ChapModelSelection.html#cb50-4" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> x2, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb50-5"><a href="ChapModelSelection.html#cb50-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-6"><a href="ChapModelSelection.html#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate Rmse and MAE based on the predicted mean from gamma distributions</span></span>
<span id="cb50-7"><a href="ChapModelSelection.html#cb50-7" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model0))</span>
<span id="cb50-8"><a href="ChapModelSelection.html#cb50-8" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model1))</span>
<span id="cb50-9"><a href="ChapModelSelection.html#cb50-9" aria-hidden="true" tabindex="-1"></a>Rmse.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model2))</span>
<span id="cb50-10"><a href="ChapModelSelection.html#cb50-10" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model0, test))</span>
<span id="cb50-11"><a href="ChapModelSelection.html#cb50-11" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model1, test))</span>
<span id="cb50-12"><a href="ChapModelSelection.html#cb50-12" aria-hidden="true" tabindex="-1"></a>Rmse.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model2, test))</span>
<span id="cb50-13"><a href="ChapModelSelection.html#cb50-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-14"><a href="ChapModelSelection.html#cb50-14" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model0))</span>
<span id="cb50-15"><a href="ChapModelSelection.html#cb50-15" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model1))</span>
<span id="cb50-16"><a href="ChapModelSelection.html#cb50-16" aria-hidden="true" tabindex="-1"></a>mae.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model2))</span>
<span id="cb50-17"><a href="ChapModelSelection.html#cb50-17" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model0, test))</span>
<span id="cb50-18"><a href="ChapModelSelection.html#cb50-18" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model1, test))</span>
<span id="cb50-19"><a href="ChapModelSelection.html#cb50-19" aria-hidden="true" tabindex="-1"></a>mae.test[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model2, test))</span>
<span id="cb50-20"><a href="ChapModelSelection.html#cb50-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-21"><a href="ChapModelSelection.html#cb50-21" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model0)</span>
<span id="cb50-22"><a href="ChapModelSelection.html#cb50-22" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model1)</span>
<span id="cb50-23"><a href="ChapModelSelection.html#cb50-23" aria-hidden="true" tabindex="-1"></a>AIC.train[<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model2)</span>
<span id="cb50-24"><a href="ChapModelSelection.html#cb50-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-25"><a href="ChapModelSelection.html#cb50-25" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.train, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(Rmse.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.train,</span>
<span id="cb50-26"><a href="ChapModelSelection.html#cb50-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(mae.test, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(AIC.train, <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb50-27"><a href="ChapModelSelection.html#cb50-27" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb50-28"><a href="ChapModelSelection.html#cb50-28" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Train&quot;</span>, <span class="st">&quot;Rmse - Test&quot;</span>, <span class="st">&quot;MAE - Train&quot;</span>, <span class="st">&quot;MAE - Test&quot;</span>,</span>
<span id="cb50-29"><a href="ChapModelSelection.html#cb50-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;AIC - Train&quot;</span>)</span>
<span id="cb50-30"><a href="ChapModelSelection.html#cb50-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-31"><a href="ChapModelSelection.html#cb50-31" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Model Selection based on in-sample AIC and out-of-sample MSE and MAE from gamma model**&quot;</span>,</span>
<span id="cb50-32"><a href="ChapModelSelection.html#cb50-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-60">Table 5.3: </span><strong>Model Selection based on in-sample AIC and out-of-sample MSE and MAE from gamma model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Train</td>
<td align="right">1.553</td>
<td align="right">1.476</td>
<td align="right">1.475</td>
</tr>
<tr class="even">
<td align="left">Rmse - Test</td>
<td align="right">1.594</td>
<td align="right">1.523</td>
<td align="right">1.522</td>
</tr>
<tr class="odd">
<td align="left">MAE - Train</td>
<td align="right">1.121</td>
<td align="right">1.226</td>
<td align="right">1.227</td>
</tr>
<tr class="even">
<td align="left">MAE - Test</td>
<td align="right">1.138</td>
<td align="right">1.253</td>
<td align="right">1.253</td>
</tr>
<tr class="odd">
<td align="left">AIC - Train</td>
<td align="right">1249.211</td>
<td align="right">852.292</td>
<td align="right">856.850</td>
</tr>
</tbody>
</table>
</div>
<p>Chapter <a href="ChapPremiumFoundations.html#ChapPremiumFoundations">9</a> describes another measure, the
<a href="#" class="tooltip" style="color:green"><em>Gini index</em><span style="font-size:8pt">A measure for assessing income inequality. it measures the discrepancy between the income and population distributions and is calculated from the lorenz curve.</span></a>, that may be useful in actuarial
applications particularly when there is a large proportion of zeros in
claims data (corresponding to no claims) that may invalidate the
aforementioned model validation statistics.</p>
</div>
<div id="S:MS:Cross-Validation" class="section level3 hasAnchor" number="5.3.5">
<h3><span class="header-section-number">5.3.5</span> Model Selection Based on Cross-Validation<a href="ChapModelSelection.html#S:MS:Cross-Validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although out-of-sample validation is the gold standard in predictive
modeling, it is not always practical to do so. The main reason is that
we have limited sample sizes and the out-of-sample model selection
criterion in equation <a href="ChapModelSelection.html#eq:OutSampleCriter">(5.6)</a> depends on a <em>random</em>
split of the data. This means that different analysts, even when working
the same dataset and same approach to modeling, may select different
models. This is likely in actuarial applications because we work with
skewed datasets where there is a large chance of getting some very large
outcomes and large outcomes may have a great influence on the parameter
estimates.</p>
<p><strong>Cross-Validation Procedure.</strong> Alternatively, one may use
<strong>cross-validation</strong>, as follows.</p>
<ul>
<li>The procedure begins by using a random mechanism to split the data
into <span class="math inline">\(K\)</span> subsets of roughly equal size known as <em>folds</em>, where
analysts typically use 5 to 10.</li>
<li>Next, one uses the first <span class="math inline">\(K\)</span>-1 subsamples to estimate model
parameters. Then, predict the outcomes for the <span class="math inline">\(K\)</span>th subsample and
use a measure such as in equation <a href="ChapModelSelection.html#eq:OutSampleCriter">(5.6)</a> to
summarize the fit.</li>
<li>Now, repeat this by holding out each of the <span class="math inline">\(K\)</span> subsamples,
summarizing with an out-of-sample statistic. Thus, summarize these
<span class="math inline">\(K\)</span> statistics, typically by averaging, to give a single overall
statistic for comparison purposes.</li>
</ul>
<p>Repeat these steps for several candidate models and choose the model
with the lowest overall cross-validation statistic.</p>
<p>In Example 2.3.1, you have seen that the MSE criteria seems to work with
k-fold cross-validation in selecting the correct mean structure for
claims outcome data generated from linear models with constant variance.
From Examples 5.3.5 and 5.3.6, however, the out-of-sample MSE and MAE
criterion does not seem to provide consistent performance for selecting
the distributional form and the mean structure under right-skewed claims
distributions. Thus, we may use the k-folder cross-validation instead of
out-of-sample prediction to see whether the MSE and MAE types of
criterion work for right-skewed distributions based on lognormal and
gamma regression with a log link function.</p>
<hr />
<p><strong>Example 5.3.7. Cross-validation in right-skewed outcomes - lognormal
claims</strong> For lognormal claims, we use the data generating mechanism from
Example 5.3.5 to generate a total of 100 samples, and use the k-fold
cross validation procedure in Example 2.3.1 to select the distributional
form and mean structure. Using cross-validation, we note that both AIC
and out-of-sample MSE and MAE seem to be working for selecting the model
with the correct distribution and mean structure, even with a total of
100 samples.</p>
<h5 style="text-align: center;">
<a id="displayCode.ValidationStat.4" href="javascript:togglecode('toggleCode.ValidationStat.4','displayCode.ValidationStat.4');"><i><strong>Show R Code for cross-validation with lognormal outputs</strong></i></a>
</h5>
<div id="toggleCode.ValidationStat.4" style="display: none">
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="ChapModelSelection.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb51-2"><a href="ChapModelSelection.html#cb51-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb51-3"><a href="ChapModelSelection.html#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb51-4"><a href="ChapModelSelection.html#cb51-4" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb51-5"><a href="ChapModelSelection.html#cb51-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>((u <span class="sc">==</span> <span class="dv">4</span>) <span class="sc">+</span> (u <span class="sc">==</span> <span class="dv">5</span>))</span>
<span id="cb51-6"><a href="ChapModelSelection.html#cb51-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(u)</span>
<span id="cb51-7"><a href="ChapModelSelection.html#cb51-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">*</span> (x1 <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb51-8"><a href="ChapModelSelection.html#cb51-8" aria-hidden="true" tabindex="-1"></a>exp.y <span class="ot">&lt;-</span> <span class="fu">exp</span>(y)</span>
<span id="cb51-9"><a href="ChapModelSelection.html#cb51-9" aria-hidden="true" tabindex="-1"></a>xyData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x1, x2, y, exp.y)</span>
<span id="cb51-10"><a href="ChapModelSelection.html#cb51-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-11"><a href="ChapModelSelection.html#cb51-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of folds</span></span>
<span id="cb51-12"><a href="ChapModelSelection.html#cb51-12" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb51-13"><a href="ChapModelSelection.html#cb51-13" aria-hidden="true" tabindex="-1"></a>splt <span class="ot">&lt;-</span> <span class="fu">split</span>(<span class="fu">sample</span>(n), <span class="dv">1</span><span class="sc">:</span>k)</span>
<span id="cb51-14"><a href="ChapModelSelection.html#cb51-14" aria-hidden="true" tabindex="-1"></a>Rmse.mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> k, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="ot">-&gt;</span> MAE.mat <span class="ot">-&gt;</span> AIC.mat</span>
<span id="cb51-15"><a href="ChapModelSelection.html#cb51-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-16"><a href="ChapModelSelection.html#cb51-16" aria-hidden="true" tabindex="-1"></a><span class="co"># lognormal model</span></span>
<span id="cb51-17"><a href="ChapModelSelection.html#cb51-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb51-18"><a href="ChapModelSelection.html#cb51-18" aria-hidden="true" tabindex="-1"></a>    test.id <span class="ot">&lt;-</span> splt[[i]]</span>
<span id="cb51-19"><a href="ChapModelSelection.html#cb51-19" aria-hidden="true" tabindex="-1"></a>    test <span class="ot">&lt;-</span> xyData[test.id, ]</span>
<span id="cb51-20"><a href="ChapModelSelection.html#cb51-20" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">&lt;-</span> xyData[<span class="sc">-</span>test.id, ]</span>
<span id="cb51-21"><a href="ChapModelSelection.html#cb51-21" aria-hidden="true" tabindex="-1"></a>    model0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train)</span>
<span id="cb51-22"><a href="ChapModelSelection.html#cb51-22" aria-hidden="true" tabindex="-1"></a>    model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> train)</span>
<span id="cb51-23"><a href="ChapModelSelection.html#cb51-23" aria-hidden="true" tabindex="-1"></a>    model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x2, <span class="at">data =</span> train)</span>
<span id="cb51-24"><a href="ChapModelSelection.html#cb51-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-25"><a href="ChapModelSelection.html#cb51-25" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb51-26"><a href="ChapModelSelection.html#cb51-26" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb51-27"><a href="ChapModelSelection.html#cb51-27" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb51-28"><a href="ChapModelSelection.html#cb51-28" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb51-29"><a href="ChapModelSelection.html#cb51-29" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb51-30"><a href="ChapModelSelection.html#cb51-30" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb51-31"><a href="ChapModelSelection.html#cb51-31" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model0<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0),</span>
<span id="cb51-32"><a href="ChapModelSelection.html#cb51-32" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sigma</span>(model0), <span class="at">log =</span> T))</span>
<span id="cb51-33"><a href="ChapModelSelection.html#cb51-33" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model1<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1),</span>
<span id="cb51-34"><a href="ChapModelSelection.html#cb51-34" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sigma</span>(model1), <span class="at">log =</span> T))</span>
<span id="cb51-35"><a href="ChapModelSelection.html#cb51-35" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model2<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2),</span>
<span id="cb51-36"><a href="ChapModelSelection.html#cb51-36" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sigma</span>(model2), <span class="at">log =</span> T))</span>
<span id="cb51-37"><a href="ChapModelSelection.html#cb51-37" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-38"><a href="ChapModelSelection.html#cb51-38" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(Rmse.mat), <span class="at">digits =</span> <span class="dv">3</span>),</span>
<span id="cb51-39"><a href="ChapModelSelection.html#cb51-39" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(MAE.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(MAE.mat), <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(AIC.mat),</span>
<span id="cb51-40"><a href="ChapModelSelection.html#cb51-40" aria-hidden="true" tabindex="-1"></a>        <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb51-41"><a href="ChapModelSelection.html#cb51-41" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb51-42"><a href="ChapModelSelection.html#cb51-42" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Fold 1&quot;</span>, <span class="st">&quot;Rmse - Fold 2&quot;</span>, <span class="st">&quot;Rmse - Fold 3&quot;</span>, <span class="st">&quot;Rmse - Fold 4&quot;</span>,</span>
<span id="cb51-43"><a href="ChapModelSelection.html#cb51-43" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Rmse - Fold 5&quot;</span>, <span class="st">&quot;Rmse - Average&quot;</span>, <span class="st">&quot;MAE - Fold 1&quot;</span>, <span class="st">&quot;MAE - Fold 2&quot;</span>, <span class="st">&quot;MAE - Fold 3&quot;</span>,</span>
<span id="cb51-44"><a href="ChapModelSelection.html#cb51-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;MAE - Fold 4&quot;</span>, <span class="st">&quot;MAE - Fold 5&quot;</span>, <span class="st">&quot;MAE - Average&quot;</span>, <span class="st">&quot;AIC - Average&quot;</span>)</span>
<span id="cb51-45"><a href="ChapModelSelection.html#cb51-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-46"><a href="ChapModelSelection.html#cb51-46" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from lognormal model**&quot;</span>,</span>
<span id="cb51-47"><a href="ChapModelSelection.html#cb51-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-61">Table 5.4: </span><strong>Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from lognormal model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Fold 1</td>
<td align="right">1.808</td>
<td align="right">1.750</td>
<td align="right">1.891</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 2</td>
<td align="right">2.145</td>
<td align="right">1.773</td>
<td align="right">1.813</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 3</td>
<td align="right">3.461</td>
<td align="right">3.335</td>
<td align="right">3.333</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 4</td>
<td align="right">1.425</td>
<td align="right">1.723</td>
<td align="right">1.865</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 5</td>
<td align="right">4.848</td>
<td align="right">4.450</td>
<td align="right">4.454</td>
</tr>
<tr class="even">
<td align="left">Rmse - Average</td>
<td align="right">2.738</td>
<td align="right">2.606</td>
<td align="right">2.671</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 1</td>
<td align="right">1.341</td>
<td align="right">1.408</td>
<td align="right">1.502</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 2</td>
<td align="right">1.881</td>
<td align="right">1.264</td>
<td align="right">1.255</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 3</td>
<td align="right">2.037</td>
<td align="right">2.142</td>
<td align="right">2.146</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 4</td>
<td align="right">1.225</td>
<td align="right">1.345</td>
<td align="right">1.476</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 5</td>
<td align="right">2.421</td>
<td align="right">2.022</td>
<td align="right">2.051</td>
</tr>
<tr class="even">
<td align="left">MAE - Average</td>
<td align="right">1.781</td>
<td align="right">1.636</td>
<td align="right">1.686</td>
</tr>
<tr class="odd">
<td align="left">AIC - Average</td>
<td align="right">286.257</td>
<td align="right">266.223</td>
<td align="right">271.200</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="ChapModelSelection.html#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># gamma model</span></span>
<span id="cb52-2"><a href="ChapModelSelection.html#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb52-3"><a href="ChapModelSelection.html#cb52-3" aria-hidden="true" tabindex="-1"></a>    test.id <span class="ot">&lt;-</span> splt[[i]]</span>
<span id="cb52-4"><a href="ChapModelSelection.html#cb52-4" aria-hidden="true" tabindex="-1"></a>    test <span class="ot">&lt;-</span> xyData[test.id, ]</span>
<span id="cb52-5"><a href="ChapModelSelection.html#cb52-5" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">&lt;-</span> xyData[<span class="sc">-</span>test.id, ]</span>
<span id="cb52-6"><a href="ChapModelSelection.html#cb52-6" aria-hidden="true" tabindex="-1"></a>    model0 <span class="ot">&lt;-</span> <span class="fu">glm</span>(exp.y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb52-7"><a href="ChapModelSelection.html#cb52-7" aria-hidden="true" tabindex="-1"></a>    model1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(exp.y <span class="sc">~</span> x1, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb52-8"><a href="ChapModelSelection.html#cb52-8" aria-hidden="true" tabindex="-1"></a>    model2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(exp.y <span class="sc">~</span> x2, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb52-9"><a href="ChapModelSelection.html#cb52-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-10"><a href="ChapModelSelection.html#cb52-10" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0))</span>
<span id="cb52-11"><a href="ChapModelSelection.html#cb52-11" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1))</span>
<span id="cb52-12"><a href="ChapModelSelection.html#cb52-12" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2))</span>
<span id="cb52-13"><a href="ChapModelSelection.html#cb52-13" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model0))</span>
<span id="cb52-14"><a href="ChapModelSelection.html#cb52-14" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model1))</span>
<span id="cb52-15"><a href="ChapModelSelection.html#cb52-15" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>exp.y, <span class="fu">predict</span>(model2))</span>
<span id="cb52-16"><a href="ChapModelSelection.html#cb52-16" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model0)</span>
<span id="cb52-17"><a href="ChapModelSelection.html#cb52-17" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model1)</span>
<span id="cb52-18"><a href="ChapModelSelection.html#cb52-18" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model2)</span>
<span id="cb52-19"><a href="ChapModelSelection.html#cb52-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb52-20"><a href="ChapModelSelection.html#cb52-20" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(Rmse.mat), <span class="at">digits =</span> <span class="dv">3</span>),</span>
<span id="cb52-21"><a href="ChapModelSelection.html#cb52-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(MAE.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(MAE.mat), <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(AIC.mat),</span>
<span id="cb52-22"><a href="ChapModelSelection.html#cb52-22" aria-hidden="true" tabindex="-1"></a>        <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb52-23"><a href="ChapModelSelection.html#cb52-23" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb52-24"><a href="ChapModelSelection.html#cb52-24" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Fold 1&quot;</span>, <span class="st">&quot;Rmse - Fold 2&quot;</span>, <span class="st">&quot;Rmse - Fold 3&quot;</span>, <span class="st">&quot;Rmse - Fold 4&quot;</span>,</span>
<span id="cb52-25"><a href="ChapModelSelection.html#cb52-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Rmse - Fold 5&quot;</span>, <span class="st">&quot;Rmse - Average&quot;</span>, <span class="st">&quot;MAE - Fold 1&quot;</span>, <span class="st">&quot;MAE - Fold 2&quot;</span>, <span class="st">&quot;MAE - Fold 3&quot;</span>,</span>
<span id="cb52-26"><a href="ChapModelSelection.html#cb52-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;MAE - Fold 4&quot;</span>, <span class="st">&quot;MAE - Fold 5&quot;</span>, <span class="st">&quot;MAE - Average&quot;</span>, <span class="st">&quot;AIC - Average&quot;</span>)</span>
<span id="cb52-27"><a href="ChapModelSelection.html#cb52-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-28"><a href="ChapModelSelection.html#cb52-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-29"><a href="ChapModelSelection.html#cb52-29" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from gamma model**&quot;</span>,</span>
<span id="cb52-30"><a href="ChapModelSelection.html#cb52-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-61">Table 5.4: </span><strong>Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from gamma model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Fold 1</td>
<td align="right">2.557</td>
<td align="right">2.642</td>
<td align="right">2.677</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 2</td>
<td align="right">1.930</td>
<td align="right">1.999</td>
<td align="right">2.005</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 3</td>
<td align="right">4.088</td>
<td align="right">4.155</td>
<td align="right">4.187</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 4</td>
<td align="right">1.181</td>
<td align="right">1.273</td>
<td align="right">1.318</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 5</td>
<td align="right">5.232</td>
<td align="right">5.262</td>
<td align="right">5.286</td>
</tr>
<tr class="even">
<td align="left">Rmse - Average</td>
<td align="right">2.998</td>
<td align="right">3.066</td>
<td align="right">3.095</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 1</td>
<td align="right">1.929</td>
<td align="right">2.069</td>
<td align="right">2.114</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 2</td>
<td align="right">1.060</td>
<td align="right">1.116</td>
<td align="right">1.124</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 3</td>
<td align="right">2.488</td>
<td align="right">2.660</td>
<td align="right">2.725</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 4</td>
<td align="right">0.887</td>
<td align="right">0.949</td>
<td align="right">0.999</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 5</td>
<td align="right">2.251</td>
<td align="right">2.312</td>
<td align="right">2.345</td>
</tr>
<tr class="even">
<td align="left">MAE - Average</td>
<td align="right">1.723</td>
<td align="right">1.821</td>
<td align="right">1.861</td>
</tr>
<tr class="odd">
<td align="left">AIC - Average</td>
<td align="right">299.063</td>
<td align="right">281.455</td>
<td align="right">282.816</td>
</tr>
</tbody>
</table>
</div>
<hr />
<p><strong>Example 5.3.8. Cross-validation in right-skewed outcomes - gamma
claims</strong> For gamma claims, we use the data generating mechanism from
Example 5.3.6 to generate a total of 100 samples, and use the k-fold
cross validation procedure to select the distributional form and mean
structure. Using cross-validation, we note that in-sample AIC seems to
be working for selecting the model with the correct distribution and
mean structure, while out-of-sample MSE and MAE seem to fail in
selecting the distributional form or the mean structure correctly even
after we increase the sample size to 1000.</p>
<h5 style="text-align: center;">
<a id="displayCode.ValidationStat.5" href="javascript:togglecode('toggleCode.ValidationStat.5','displayCode.ValidationStat.5');"><i><strong>Show R Code for cross-validation with gamma outputs</strong></i></a>
</h5>
<div id="toggleCode.ValidationStat.5" style="display: none">
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="ChapModelSelection.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Metrics)</span>
<span id="cb53-2"><a href="ChapModelSelection.html#cb53-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb53-3"><a href="ChapModelSelection.html#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb53-4"><a href="ChapModelSelection.html#cb53-4" aria-hidden="true" tabindex="-1"></a>u <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb53-5"><a href="ChapModelSelection.html#cb53-5" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>((u <span class="sc">==</span> <span class="dv">4</span>) <span class="sc">+</span> (u <span class="sc">==</span> <span class="dv">5</span>))</span>
<span id="cb53-6"><a href="ChapModelSelection.html#cb53-6" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(u)</span>
<span id="cb53-7"><a href="ChapModelSelection.html#cb53-7" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">as.numeric</span>(x1 <span class="sc">==</span> <span class="dv">1</span>))  <span class="co"># gamma mean</span></span>
<span id="cb53-8"><a href="ChapModelSelection.html#cb53-8" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb53-9"><a href="ChapModelSelection.html#cb53-9" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> alpha<span class="sc">/</span>mu</span>
<span id="cb53-10"><a href="ChapModelSelection.html#cb53-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(n, alpha, beta)</span>
<span id="cb53-11"><a href="ChapModelSelection.html#cb53-11" aria-hidden="true" tabindex="-1"></a>log.y <span class="ot">&lt;-</span> <span class="fu">log</span>(y)</span>
<span id="cb53-12"><a href="ChapModelSelection.html#cb53-12" aria-hidden="true" tabindex="-1"></a>xyData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x1, x2, y, log.y)</span>
<span id="cb53-13"><a href="ChapModelSelection.html#cb53-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-14"><a href="ChapModelSelection.html#cb53-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of folds</span></span>
<span id="cb53-15"><a href="ChapModelSelection.html#cb53-15" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb53-16"><a href="ChapModelSelection.html#cb53-16" aria-hidden="true" tabindex="-1"></a>splt <span class="ot">&lt;-</span> <span class="fu">split</span>(<span class="fu">sample</span>(n), <span class="dv">1</span><span class="sc">:</span>k)</span>
<span id="cb53-17"><a href="ChapModelSelection.html#cb53-17" aria-hidden="true" tabindex="-1"></a>Rmse.mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> k, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="ot">-&gt;</span> MAE.mat <span class="ot">-&gt;</span> AIC.mat</span>
<span id="cb53-18"><a href="ChapModelSelection.html#cb53-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-19"><a href="ChapModelSelection.html#cb53-19" aria-hidden="true" tabindex="-1"></a><span class="co"># lognormal model</span></span>
<span id="cb53-20"><a href="ChapModelSelection.html#cb53-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb53-21"><a href="ChapModelSelection.html#cb53-21" aria-hidden="true" tabindex="-1"></a>    test.id <span class="ot">&lt;-</span> splt[[i]]</span>
<span id="cb53-22"><a href="ChapModelSelection.html#cb53-22" aria-hidden="true" tabindex="-1"></a>    test <span class="ot">&lt;-</span> xyData[test.id, ]</span>
<span id="cb53-23"><a href="ChapModelSelection.html#cb53-23" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">&lt;-</span> xyData[<span class="sc">-</span>test.id, ]</span>
<span id="cb53-24"><a href="ChapModelSelection.html#cb53-24" aria-hidden="true" tabindex="-1"></a>    model0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train)</span>
<span id="cb53-25"><a href="ChapModelSelection.html#cb53-25" aria-hidden="true" tabindex="-1"></a>    model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.y <span class="sc">~</span> x1, <span class="at">data =</span> train)</span>
<span id="cb53-26"><a href="ChapModelSelection.html#cb53-26" aria-hidden="true" tabindex="-1"></a>    model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.y <span class="sc">~</span> x2, <span class="at">data =</span> train)</span>
<span id="cb53-27"><a href="ChapModelSelection.html#cb53-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-28"><a href="ChapModelSelection.html#cb53-28" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb53-29"><a href="ChapModelSelection.html#cb53-29" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb53-30"><a href="ChapModelSelection.html#cb53-30" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb53-31"><a href="ChapModelSelection.html#cb53-31" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model0, test) <span class="sc">+</span> <span class="fu">sigma</span>(model0)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb53-32"><a href="ChapModelSelection.html#cb53-32" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model1, test) <span class="sc">+</span> <span class="fu">sigma</span>(model1)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb53-33"><a href="ChapModelSelection.html#cb53-33" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">exp</span>(<span class="fu">predict</span>(model2, test) <span class="sc">+</span> <span class="fu">sigma</span>(model2)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb53-34"><a href="ChapModelSelection.html#cb53-34" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model0<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model0),</span>
<span id="cb53-35"><a href="ChapModelSelection.html#cb53-35" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sigma</span>(model0), <span class="at">log =</span> T))</span>
<span id="cb53-36"><a href="ChapModelSelection.html#cb53-36" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model1<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model1),</span>
<span id="cb53-37"><a href="ChapModelSelection.html#cb53-37" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sigma</span>(model1), <span class="at">log =</span> T))</span>
<span id="cb53-38"><a href="ChapModelSelection.html#cb53-38" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> (model2<span class="sc">$</span>rank <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(<span class="fu">dlnorm</span>(train<span class="sc">$</span>y, <span class="fu">predict</span>(model2),</span>
<span id="cb53-39"><a href="ChapModelSelection.html#cb53-39" aria-hidden="true" tabindex="-1"></a>        <span class="fu">sigma</span>(model2), <span class="at">log =</span> T))</span>
<span id="cb53-40"><a href="ChapModelSelection.html#cb53-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb53-41"><a href="ChapModelSelection.html#cb53-41" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(Rmse.mat), <span class="at">digits =</span> <span class="dv">3</span>),</span>
<span id="cb53-42"><a href="ChapModelSelection.html#cb53-42" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(MAE.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(MAE.mat), <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(AIC.mat),</span>
<span id="cb53-43"><a href="ChapModelSelection.html#cb53-43" aria-hidden="true" tabindex="-1"></a>        <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb53-44"><a href="ChapModelSelection.html#cb53-44" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb53-45"><a href="ChapModelSelection.html#cb53-45" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Fold 1&quot;</span>, <span class="st">&quot;Rmse - Fold 2&quot;</span>, <span class="st">&quot;Rmse - Fold 3&quot;</span>, <span class="st">&quot;Rmse - Fold 4&quot;</span>,</span>
<span id="cb53-46"><a href="ChapModelSelection.html#cb53-46" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Rmse - Fold 5&quot;</span>, <span class="st">&quot;Rmse - Average&quot;</span>, <span class="st">&quot;MAE - Fold 1&quot;</span>, <span class="st">&quot;MAE - Fold 2&quot;</span>, <span class="st">&quot;MAE - Fold 3&quot;</span>,</span>
<span id="cb53-47"><a href="ChapModelSelection.html#cb53-47" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;MAE - Fold 4&quot;</span>, <span class="st">&quot;MAE - Fold 5&quot;</span>, <span class="st">&quot;MAE - Average&quot;</span>, <span class="st">&quot;AIC - Average&quot;</span>)</span>
<span id="cb53-48"><a href="ChapModelSelection.html#cb53-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-49"><a href="ChapModelSelection.html#cb53-49" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from lognormal model**&quot;</span>,</span>
<span id="cb53-50"><a href="ChapModelSelection.html#cb53-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-62">Table 5.5: </span><strong>Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from lognormal model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Fold 1</td>
<td align="right">1.080</td>
<td align="right">0.794</td>
<td align="right">0.799</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 2</td>
<td align="right">0.953</td>
<td align="right">0.639</td>
<td align="right">0.639</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 3</td>
<td align="right">1.354</td>
<td align="right">0.914</td>
<td align="right">0.916</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 4</td>
<td align="right">1.097</td>
<td align="right">0.725</td>
<td align="right">0.727</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 5</td>
<td align="right">1.171</td>
<td align="right">0.695</td>
<td align="right">0.695</td>
</tr>
<tr class="even">
<td align="left">Rmse - Average</td>
<td align="right">1.131</td>
<td align="right">0.753</td>
<td align="right">0.755</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 1</td>
<td align="right">0.837</td>
<td align="right">0.579</td>
<td align="right">0.583</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 2</td>
<td align="right">0.755</td>
<td align="right">0.473</td>
<td align="right">0.474</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 3</td>
<td align="right">0.952</td>
<td align="right">0.600</td>
<td align="right">0.602</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 4</td>
<td align="right">0.852</td>
<td align="right">0.523</td>
<td align="right">0.525</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 5</td>
<td align="right">0.897</td>
<td align="right">0.503</td>
<td align="right">0.507</td>
</tr>
<tr class="even">
<td align="left">MAE - Average</td>
<td align="right">0.859</td>
<td align="right">0.536</td>
<td align="right">0.538</td>
</tr>
<tr class="odd">
<td align="left">AIC - Average</td>
<td align="right">1980.018</td>
<td align="right">1381.321</td>
<td align="right">1388.351</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="ChapModelSelection.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># gamma model</span></span>
<span id="cb54-2"><a href="ChapModelSelection.html#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>k) {</span>
<span id="cb54-3"><a href="ChapModelSelection.html#cb54-3" aria-hidden="true" tabindex="-1"></a>    test.id <span class="ot">&lt;-</span> splt[[i]]</span>
<span id="cb54-4"><a href="ChapModelSelection.html#cb54-4" aria-hidden="true" tabindex="-1"></a>    test <span class="ot">&lt;-</span> xyData[test.id, ]</span>
<span id="cb54-5"><a href="ChapModelSelection.html#cb54-5" aria-hidden="true" tabindex="-1"></a>    train <span class="ot">&lt;-</span> xyData[<span class="sc">-</span>test.id, ]</span>
<span id="cb54-6"><a href="ChapModelSelection.html#cb54-6" aria-hidden="true" tabindex="-1"></a>    model0 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb54-7"><a href="ChapModelSelection.html#cb54-7" aria-hidden="true" tabindex="-1"></a>    model1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> x1, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb54-8"><a href="ChapModelSelection.html#cb54-8" aria-hidden="true" tabindex="-1"></a>    model2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> x2, <span class="at">data =</span> train, <span class="at">family =</span> <span class="fu">Gamma</span>(<span class="at">link =</span> log))</span>
<span id="cb54-9"><a href="ChapModelSelection.html#cb54-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-10"><a href="ChapModelSelection.html#cb54-10" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model0))</span>
<span id="cb54-11"><a href="ChapModelSelection.html#cb54-11" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model1))</span>
<span id="cb54-12"><a href="ChapModelSelection.html#cb54-12" aria-hidden="true" tabindex="-1"></a>    Rmse.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">rmse</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model2))</span>
<span id="cb54-13"><a href="ChapModelSelection.html#cb54-13" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model0))</span>
<span id="cb54-14"><a href="ChapModelSelection.html#cb54-14" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model1))</span>
<span id="cb54-15"><a href="ChapModelSelection.html#cb54-15" aria-hidden="true" tabindex="-1"></a>    MAE.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">mae</span>(test<span class="sc">$</span>y, <span class="fu">predict</span>(model2))</span>
<span id="cb54-16"><a href="ChapModelSelection.html#cb54-16" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model0)</span>
<span id="cb54-17"><a href="ChapModelSelection.html#cb54-17" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model1)</span>
<span id="cb54-18"><a href="ChapModelSelection.html#cb54-18" aria-hidden="true" tabindex="-1"></a>    AIC.mat[i, <span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model2)</span>
<span id="cb54-19"><a href="ChapModelSelection.html#cb54-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb54-20"><a href="ChapModelSelection.html#cb54-20" aria-hidden="true" tabindex="-1"></a>OutMat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">round</span>(Rmse.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(Rmse.mat), <span class="at">digits =</span> <span class="dv">3</span>),</span>
<span id="cb54-21"><a href="ChapModelSelection.html#cb54-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">round</span>(MAE.mat, <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(MAE.mat), <span class="at">digits =</span> <span class="dv">3</span>), <span class="fu">round</span>(<span class="fu">colMeans</span>(AIC.mat),</span>
<span id="cb54-22"><a href="ChapModelSelection.html#cb54-22" aria-hidden="true" tabindex="-1"></a>        <span class="at">digits =</span> <span class="dv">3</span>))</span>
<span id="cb54-23"><a href="ChapModelSelection.html#cb54-23" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Community Rating&quot;</span>, <span class="st">&quot;Two Levels&quot;</span>, <span class="st">&quot;Six Levels&quot;</span>)</span>
<span id="cb54-24"><a href="ChapModelSelection.html#cb54-24" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(OutMat) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Rmse - Fold 1&quot;</span>, <span class="st">&quot;Rmse - Fold 2&quot;</span>, <span class="st">&quot;Rmse - Fold 3&quot;</span>, <span class="st">&quot;Rmse - Fold 4&quot;</span>,</span>
<span id="cb54-25"><a href="ChapModelSelection.html#cb54-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Rmse - Fold 5&quot;</span>, <span class="st">&quot;Rmse - Average&quot;</span>, <span class="st">&quot;MAE - Fold 1&quot;</span>, <span class="st">&quot;MAE - Fold 2&quot;</span>, <span class="st">&quot;MAE - Fold 3&quot;</span>,</span>
<span id="cb54-26"><a href="ChapModelSelection.html#cb54-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;MAE - Fold 4&quot;</span>, <span class="st">&quot;MAE - Fold 5&quot;</span>, <span class="st">&quot;MAE - Average&quot;</span>, <span class="st">&quot;AIC - Average&quot;</span>)</span>
<span id="cb54-27"><a href="ChapModelSelection.html#cb54-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-28"><a href="ChapModelSelection.html#cb54-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-29"><a href="ChapModelSelection.html#cb54-29" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(OutMat, <span class="at">caption =</span> <span class="st">&quot;**Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from gamma model**&quot;</span>,</span>
<span id="cb54-30"><a href="ChapModelSelection.html#cb54-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> T)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-62">Table 5.5: </span><strong>Cross-validation based on in-sample AIC, and out-of-sample MSE and MAE from gamma model</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Community Rating</th>
<th align="right">Two Levels</th>
<th align="right">Six Levels</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Rmse - Fold 1</td>
<td align="right">1.455</td>
<td align="right">1.620</td>
<td align="right">1.620</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 2</td>
<td align="right">1.347</td>
<td align="right">1.543</td>
<td align="right">1.543</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 3</td>
<td align="right">1.865</td>
<td align="right">2.006</td>
<td align="right">2.005</td>
</tr>
<tr class="even">
<td align="left">Rmse - Fold 4</td>
<td align="right">1.558</td>
<td align="right">1.738</td>
<td align="right">1.738</td>
</tr>
<tr class="odd">
<td align="left">Rmse - Fold 5</td>
<td align="right">1.690</td>
<td align="right">1.838</td>
<td align="right">1.838</td>
</tr>
<tr class="even">
<td align="left">Rmse - Average</td>
<td align="right">1.583</td>
<td align="right">1.749</td>
<td align="right">1.749</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 1</td>
<td align="right">1.003</td>
<td align="right">1.223</td>
<td align="right">1.223</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 2</td>
<td align="right">0.975</td>
<td align="right">1.195</td>
<td align="right">1.195</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 3</td>
<td align="right">1.301</td>
<td align="right">1.478</td>
<td align="right">1.479</td>
</tr>
<tr class="even">
<td align="left">MAE - Fold 4</td>
<td align="right">1.118</td>
<td align="right">1.342</td>
<td align="right">1.342</td>
</tr>
<tr class="odd">
<td align="left">MAE - Fold 5</td>
<td align="right">1.228</td>
<td align="right">1.420</td>
<td align="right">1.420</td>
</tr>
<tr class="even">
<td align="left">MAE - Average</td>
<td align="right">1.125</td>
<td align="right">1.332</td>
<td align="right">1.332</td>
</tr>
<tr class="odd">
<td align="left">AIC - Average</td>
<td align="right">2047.108</td>
<td align="right">1349.855</td>
<td align="right">1357.246</td>
</tr>
</tbody>
</table>
</div>
<p>Cross-validation is widely used because it retains the predictive flavor
of the out-of-sample model validation process but, due to the re-use of
the data, is more stable over random samples. In addition, Example
7.3.1. in Chapter <a href="ChapSimulation.html#ChapSimulation">7</a> uses the Wisconsin Property Fund to
perform k-fold cross-validation of the gamma and Pareto models based on
the Kolmogorov-Smirnov goodness of fit statistic. Additional information
and examples regarding re-sampling procedures including leave-one-out
cross-validation and bootstrap can also be found in Chapter
(ChapSimulation).</p>
</div>
<div id="S:MS:Modified-Data" class="section level3 hasAnchor" number="5.3.6">
<h3><span class="header-section-number">5.3.6</span> Model Selection for Modified Data<a href="ChapModelSelection.html#S:MS:Modified-Data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So far, you have learned covered model selection using unmodified data.
For modified data including grouped, censored and truncated data, you
have learned parametric and nonparametric estimation of distribution
functions in Section <a href="ChapModelSelection.html#S:MS:ModifiedData">5.2</a>. For model selection, the
tools from Section <a href="ChapModelSelection.html#S:MS:ModelSelection">5.3</a> can be extended to cases
of modified data.</p>
<p>For selection of distributions, the nonparametric tools introduced in
Section <a href="ChapModelSelection.html#S:MS:ToolsModelSelection">5.3.1</a> are based on estimated
parametric and nonparametric distribution functions, and thus can be
extended to modified data for which both types of estimators exist.</p>
<p>For graphical comparisons, the <span class="math inline">\(pp\)</span> and <span class="math inline">\(qq\)</span> plots introduced earlier
can be created for modified data by plotting the parametric estimates
from Section <a href="ChapModelSelection.html#S:MS:ModifiedData1">5.2.1</a> against nonparametric estimates
of the probability or distribution functions from Section
<a href="ChapModelSelection.html#S:MS:NonParModified">5.2.2</a>. For example, the <code>qqPlotCensored</code> and
<code>qqtrunc</code> functions in <code>R</code> generate <span class="math inline">\(qq\)</span> plots respectively for censored
(left or right) and truncated data, whereas the <code>probPlot</code> function
creates both <span class="math inline">\(pp\)</span> and <span class="math inline">\(qq\)</span> plots with a larger selection of
distributions for right-censored and unmodified data. Additional
graphical tools such as cumulative hazard plots are available in the <code>R</code>
package <code>GofCens</code>.</p>
<hr />
<p><strong>Example 5.4.1. Bodily Injury Claims.</strong> For the Boston auto bodily
injury claims data from Example 5.1.6, we include the full dataset with
right-censoring, and use the <span class="math inline">\(qq\)</span>-plot to compare the estimated
quantiles from lognormal, normal and exponential distributions with
those from the nonparametric Kaplan-Meier method. From the <span class="math inline">\(qq\)</span>-plots in
Figure <a href="#fig:qqCensored"><strong>??</strong></a>, the lognormal distribution functions seems
to fit the censored data much better those based on the normal and
exponential distributions.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qqCensored-1"></span>
<img src="LossDataAnalytics_files/figure-html/qqCensored-1.png" alt="Quantile-Quantile (\(qq\)) Plots for Bodily Injury Claims. The horizontal axis gives the empirical quantiles at each observation. The vertical axis gives the quantiles from the fitted distributions; lognormal quantiles are in the left panels, normal quantiles are in the right panels." width="672" />
<p class="caption">
Figure 5.15: <strong>Quantile-Quantile (<span class="math inline">\(qq\)</span>) Plots for Bodily Injury Claims. The horizontal axis gives the empirical quantiles at each observation. The vertical axis gives the quantiles from the fitted distributions; lognormal quantiles are in the left panels, normal quantiles are in the right panels.</strong>
</p>
</div>
<pre><code>$Distribution
[1] &quot;Log-normal&quot;

$Parameters
 location     scale 
8.7479091 0.6406153 </code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qqCensored-2"></span>
<img src="LossDataAnalytics_files/figure-html/qqCensored-2.png" alt="Quantile-Quantile (\(qq\)) Plots for Bodily Injury Claims. The horizontal axis gives the empirical quantiles at each observation. The vertical axis gives the quantiles from the fitted distributions; lognormal quantiles are in the left panels, normal quantiles are in the right panels." width="672" />
<p class="caption">
Figure 5.16: <strong>Quantile-Quantile (<span class="math inline">\(qq\)</span>) Plots for Bodily Injury Claims. The horizontal axis gives the empirical quantiles at each observation. The vertical axis gives the quantiles from the fitted distributions; lognormal quantiles are in the left panels, normal quantiles are in the right panels.</strong>
</p>
</div>
<pre><code>$Distribution
[1] &quot;Normal&quot;

$Parameters
location    scale 
7463.069 4575.343 </code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:qqCensored-3"></span>
<img src="LossDataAnalytics_files/figure-html/qqCensored-3.png" alt="Quantile-Quantile (\(qq\)) Plots for Bodily Injury Claims. The horizontal axis gives the empirical quantiles at each observation. The vertical axis gives the quantiles from the fitted distributions; lognormal quantiles are in the left panels, normal quantiles are in the right panels." width="672" />
<p class="caption">
Figure 5.17: <strong>Quantile-Quantile (<span class="math inline">\(qq\)</span>) Plots for Bodily Injury Claims. The horizontal axis gives the empirical quantiles at each observation. The vertical axis gives the quantiles from the fitted distributions; lognormal quantiles are in the left panels, normal quantiles are in the right panels.</strong>
</p>
</div>
<pre><code>$Distribution
[1] &quot;Exponential&quot;

$scale
[1] 7710.53</code></pre>
<h5 style="text-align: center;">
<a id="displayCode.qqCensored.4f" href="javascript:togglecode('toggleCode.qqCensored.4f','displayCode.qqCensored.4f');"><i><strong>Show R Code</strong></i></a>
</h5>
<div id="toggleCode.qqCensored.4f" style="display: none">

</div>
<p>In addition to graphical tools, you may use tools from Section
<a href="ChapModelSelection.html#S:MS:Tools:Stats">5.3.1.2</a> for statistical comparisons of models fitted
from modified data based on parametric and nonparametric estimates of
distribution functions. For example, the <code>R</code> package <code>GofCens</code> provides
functions calculating the three goodness of fit statistics from Section
<a href="ChapModelSelection.html#S:MS:Tools:Stats">5.3.1.2</a> for both right-censored and unmodified data. The
<code>R</code> package <code>truncgof</code>, on the other hand, provides functions for
calculating the three goodness of fit statistics for left-truncated
data.</p>
<p><strong>Example 5.4.2. Bodily Injury Claims.</strong> For the Boston auto bodily
injury claims with right-censoring, we may use the goodness of fit
statistics to evaluate the fitted lognormal, normal and exponential
distributions from Example 5.4.1. For the Kolmogorov-Smirnov, Cramer-von
Mises and Anderson-Darling statistics, the lognormal distribution gives
values that are much lower than those from normal and exponential
distributions. The conclusion from the goodness of fit statistics is
consistent to that revealed by the <span class="math inline">\(qq\)</span> plots.</p>
<table>
<caption><span id="tab:KsCensored">Table 5.6: </span><strong>Nonparametric goodness of fit statistics for right-censored Bodily Injury Claims</strong></caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Kolmogorov-Smirnov</th>
<th align="right">Cramer-von Mises</th>
<th align="right">Anderson-Darling</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Lognormal</td>
<td align="right">1.994</td>
<td align="right">0.304</td>
<td align="right">1.770</td>
</tr>
<tr class="even">
<td align="left">Normal</td>
<td align="right">3.096</td>
<td align="right">1.335</td>
<td align="right">9.437</td>
</tr>
<tr class="odd">
<td align="left">Exponential</td>
<td align="right">4.811</td>
<td align="right">4.065</td>
<td align="right">21.659</td>
</tr>
</tbody>
</table>
<h5 style="text-align: center;">
<a id="displayCode.KsCensored.4f" href="javascript:togglecode('toggleCode.KsCensored.4f','displayCode.KsCensored.4f');"><i><strong>Show R Code</strong></i></a>
</h5>
<div id="toggleCode.KsCensored.4f" style="display: none">

</div>
<p>Other than selecting the distributional form, model comparison measures
such as the likelihood ratio test and information criterion including
the AIC from Section <a href="ChapModelSelection.html#S:MS:Tools:Stats:Likelihood">5.3.3</a> can be obtained
for models fitted based on likelihood criteria based on the likelihood
functions introduced earlier for modified data. For modified data, the
<code>survreg</code> and <code>flexsurvreg</code> functions in <code>R</code> fit parametric regression
models on censored and/or truncated outcomes based on maximum likelihood
estimation which allows use of likelihood ratio tests and information
criterion such as AIC for in-sample model comparisons. For censored and
truncated data, the functions also provide output of residuals that
allow calculation of model validation statistics such as the MSE and MAE
for the iterative model selection procedure introduced in Section
<a href="ChapModelSelection.html#S:MS:Iterative:Selection">5.3.2</a>.</p>
<div id="surveyElement42">

</div>
<div id="surveyResult42">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz42.1" href="javascript:toggleQuiz
('display.Quiz42.2','display.Quiz42.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz42.2" style="display: none">
<p id="Quiz42Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz42.js">
</script>
</div>
</div>
<div id="MS:further-reading-and-resources" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Further Resources and Contributors<a href="ChapModelSelection.html#MS:further-reading-and-resources" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercises-2" class="section level4 unnumbered hasAnchor">
<h4>Exercises<a href="ChapModelSelection.html#exercises-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Here are a set of exercises that guide the viewer through some of the
theoretical foundations of <strong>Loss Data Analytics</strong>. Each tutorial is
based on one or more questions from the professional actuarial
examinations, typically the Society of Actuaries Exam C/STAM.</p>
<p style="text-align: center;">
<p><a href="http://www.ssc.wisc.edu/~jfrees/loss-data-analytics/loss-data-analytics-model-selection/">Model Selection Guided
Tutorials</a></p>
</p>
</div>
<div id="contributors-4" class="section level4 unnumbered hasAnchor">
<h4>Contributors<a href="ChapModelSelection.html#contributors-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Edward W. (Jed) Frees</strong> and <strong>Lisa Gao</strong>, University of
Wisconsin-Madison, are the principal authors of the initial version
of this chapter. Email:
<a href="mailto:jfrees@bus.wisc.edu" class="email">jfrees@bus.wisc.edu</a> for
chapter comments and suggested improvements.</li>
<li>Chapter reviewers include: Vytaras Brazauskas, Yvonne Chueh, Eren
Dodd, Hirokazu (Iwahiro) Iwasawa, Joseph Kim, Andrew Kwon-Nakamura,
Jiandong Ren, and Di (Cindy) Xu.</li>
</ul>

</div>
</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-aalen1978" class="csl-entry">
Aalen, Odd. 1978. <span>Nonparametric Inference for a Family of Counting Processes.</span> <em>The Annals of Statistics</em> 6 (4): 70126.
</div>
<div id="ref-box1980sampling" class="csl-entry">
Box, George E. P. 1980. <span>Sampling and Bayes Inference in Scientific Modelling and Robustness.</span> <em>Journal of the Royal Statistical Society. Series A (General)</em>, 383430.
</div>
<div id="ref-derrig2001applications" class="csl-entry">
Derrig, Richard A, Krzysztof M Ostaszewski, and Grzegorz A Rempala. 2001. <span>Applications of Resampling Methods in Actuarial Practice.</span> In <em>Proceedings of the Casualty Actuarial Society</em>, 87:32264. Casualty Actuarial Society.
</div>
<div id="ref-greenwood1926" class="csl-entry">
Greenwood, Major. 1926. <span>The Errors of Sampling of the Survivorship Tables.</span> In <em>Reports on Public Health and Statistical Subjects</em>. Vol. 33. London: Her Majestys Stationary Office.
</div>
<div id="ref-james2013introduction" class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer.
</div>
<div id="ref-kaplan1958" class="csl-entry">
Kaplan, Edward L., and Paul Meier. 1958. <span>Nonparametric Estimation from Incomplete Observations.</span> <em>Journal of the American Statistical Association</em> 53 (282): 45781.
</div>
<div id="ref-picard1990data" class="csl-entry">
Picard, Richard R., and Kenneth N. Berk. 1990. <span>Data Splitting.</span> <em>The American Statistician</em> 44 (2): 14047.
</div>
<div id="ref-snee1977validation" class="csl-entry">
Snee, Ronald D. 1977. <span>Validation of Regression Models: Methods and Examples.</span> <em>Technometrics</em> 19 (4): 41528.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ChapSeverity.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ChapAggLossModels.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
