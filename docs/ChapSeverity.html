<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Modeling Loss Severity | Loss Data Analytics</title>
  <meta name="description" content="Chapter 4 Modeling Loss Severity | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Modeling Loss Severity | Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 4 Modeling Loss Severity | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="github-repo" content="https://github.com/openacttexts/Loss-Data-Analytics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Modeling Loss Severity | Loss Data Analytics" />
  
  <meta name="twitter:description" content="Chapter 4 Modeling Loss Severity | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ChapFrequency-Modeling.html"/>
<link rel="next" href="ChapClaimSeverity.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<script>
function markdownConverterEWF() {  
//Create showdown markdown converter
var converter = new showdown.Converter();
converter.setOption('ghCompatibleHeaderId', true);
survey
    .onTextMarkdown
    .add(function (survey, options) {
        //convert the markdown text to html
        var str = converter.makeHtml(options.text);
        //remove root paragraphs <p></p>
        str = str.substring(3);
        str = str.substring(0, str.length - 4);
        //set html
        options.html = str;
        MathJax.Hub.Queue(['Typeset',MathJax.Hub, 'options']);
    });  
};

// Quiz Header info
const jsonHeader = { 
    showProgressBar: "bottom",
    showTimerPanel: "none",
    maxTimeToFinishPage: 10000,
    maxTimeToFinish: 25000,
    firstPageIsStarted: true,
    startSurveyText: "Start Quiz" //,
//    title: "Does This Make Sense?"
}


// One and Two question quizzes
function jsonSummary1EWF(json) {  
let jsonEnd1 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
};  
return jsonEnd1;
};


function jsonSummary2EWF(json) {  
let jsonEnd2 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
};  
return jsonEnd2;
};

// Three, four, and five question quizzes
function jsonSummary3EWF(json) {  
let jsonEnd3 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][3]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][3]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][3]["questions"][0]["correctAnswer"]
};  
return jsonEnd3;
};

function jsonSummary4EWF(json) {  
jsonEnd4 = jsonSummary3EWF(json);
jsonEnd4.completedHtml = jsonEnd4.completedHtml +  
"<br>"+
json["pages"][4]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][4]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][4]["questions"][0]["correctAnswer"]
;  
return jsonEnd4;
};

function jsonSummary5EWF(json) {  
jsonEnd5 = jsonSummary4EWF(json);
jsonEnd5.completedHtml = jsonEnd5.completedHtml +  
"<br>"+
json["pages"][5]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][5]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][5]["questions"][0]["correctAnswer"]
;  
return jsonEnd5;
};

function jsonSummary6EWF(json) {  
jsonEnd6 = jsonSummary5EWF(json);
jsonEnd6.completedHtml = jsonEnd6.completedHtml +  
"<br>"+
json["pages"][6]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][6]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][6]["questions"][0]["correctAnswer"]
;  
return jsonEnd6;
};

function jsonSummary7EWF(json) {  
jsonEnd7 = jsonSummary6EWF(json);
jsonEnd7.completedHtml = jsonEnd7.completedHtml +  
"<br>"+
json["pages"][7]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][7]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][7]["questions"][0]["correctAnswer"]
;  
return jsonEnd7;
};

function jsonSummary8EWF(json) {  
jsonEnd8 = jsonSummary7EWF(json);
jsonEnd8.completedHtml = jsonEnd8.completedHtml +  
"<br>"+
json["pages"][8]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][8]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][8]["questions"][0]["correctAnswer"]
;  
return jsonEnd8;
};

function jsonSummary9EWF(json) {  
jsonEnd9 = jsonSummary8EWF(json);
jsonEnd9.completedHtml = jsonEnd9.completedHtml +  
"<br>"+
json["pages"][9]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][9]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][9]["questions"][0]["correctAnswer"]
;  
return jsonEnd9;
};


function jsonSummary10EWF(json) {  
jsonEnd10 = jsonSummary9EWF(json);
jsonEnd10.completedHtml = jsonEnd10.completedHtml +  
"<br>"+
json["pages"][10]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][10]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][10]["questions"][0]["correctAnswer"]
;  
return jsonEnd10;
};


function jsonSummary11EWF(json) {  
jsonEnd11 = jsonSummary10EWF(json);
jsonEnd11.completedHtml = jsonEnd11.completedHtml +  
"<br>"+
json["pages"][11]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][11]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][11]["questions"][0]["correctAnswer"]
;  
return jsonEnd11;
};

Survey.StylesManager.applyTheme("modern");

</script>  
<!-- This completes the code for the quizzes -->

<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>

<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  if (t = document.getElementById("webex-total_correct")) {
    var correct = document.getElementsByClassName("webex-correct").length;
    var solvemes = document.getElementsByClassName("webex-solveme").length;
    var radiogroups = document.getElementsByClassName("webex-radiogroup").length;
    var selects = document.getElementsByClassName("webex-select").length;
    
    t.innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");
  
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");
  
  var cl = this.classList
  
  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;
  
  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }
  
  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

window.onload = function() {
  console.log("onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }
  
  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
  }

  update_total_correct();
}

</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="Format/style.css" type="text/css" />
<link rel="stylesheet" href="includeWebex/webex.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reviewers"><i class="fa fa-check"></i>Reviewers</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#other-collaborators"><i class="fa fa-check"></i>Other Collaborators</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version"><i class="fa fa-check"></i>Version</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#for-our-readers"><i class="fa fa-check"></i>For our Readers</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ChapIntro.html"><a href="ChapIntro.html"><i class="fa fa-check"></i><b>1</b> Loss Data and Insurance Activities</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ChapIntro.html"><a href="ChapIntro.html#S:Intro"><i class="fa fa-check"></i><b>1.1</b> Data Driven Insurance Activities</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="ChapIntro.html"><a href="ChapIntro.html#nature-and-relevance-of-insurance"><i class="fa fa-check"></i><b>1.1.1</b> Nature and Relevance of Insurance</a></li>
<li class="chapter" data-level="1.1.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:DataDriven"><i class="fa fa-check"></i><b>1.1.2</b> Why Data Driven?</a></li>
<li class="chapter" data-level="1.1.3" data-path="ChapIntro.html"><a href="ChapIntro.html#S:InsProcesses"><i class="fa fa-check"></i><b>1.1.3</b> Insurance Processes</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:PredModApps"><i class="fa fa-check"></i><b>1.2</b> Insurance Company Operations</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ChapIntro.html"><a href="ChapIntro.html#initiating-insurance"><i class="fa fa-check"></i><b>1.2.1</b> Initiating Insurance</a></li>
<li class="chapter" data-level="1.2.2" data-path="ChapIntro.html"><a href="ChapIntro.html#renewing-insurance"><i class="fa fa-check"></i><b>1.2.2</b> Renewing Insurance</a></li>
<li class="chapter" data-level="1.2.3" data-path="ChapIntro.html"><a href="ChapIntro.html#claims-and-product-management"><i class="fa fa-check"></i><b>1.2.3</b> Claims and Product Management</a></li>
<li class="chapter" data-level="1.2.4" data-path="ChapIntro.html"><a href="ChapIntro.html#S:Reserving"><i class="fa fa-check"></i><b>1.2.4</b> Loss Reserving</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ChapIntro.html"><a href="ChapIntro.html#S:LGPIF"><i class="fa fa-check"></i><b>1.3</b> Case Study: Wisconsin Property Fund</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="ChapIntro.html"><a href="ChapIntro.html#S:OutComes"><i class="fa fa-check"></i><b>1.3.1</b> Fund Claims Variables: Frequency and Severity</a></li>
<li class="chapter" data-level="1.3.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:FundVariables"><i class="fa fa-check"></i><b>1.3.2</b> Fund Rating Variables</a></li>
<li class="chapter" data-level="1.3.3" data-path="ChapIntro.html"><a href="ChapIntro.html#fund-operations"><i class="fa fa-check"></i><b>1.3.3</b> Fund Operations</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ChapIntro.html"><a href="ChapIntro.html#exercises"><i class="fa fa-check"></i><b>1.4</b> Exercises</a></li>
<li class="chapter" data-level="1.5" data-path="ChapIntro.html"><a href="ChapIntro.html#Intro-further-reading-and-resources"><i class="fa fa-check"></i><b>1.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html"><i class="fa fa-check"></i><b>2</b> Introduction to Data Analytics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:Elements"><i class="fa fa-check"></i><b>2.1</b> Elements of Data Analytics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#key-data-analytic-concepts"><i class="fa fa-check"></i><b>2.1.1</b> Key Data Analytic Concepts</a></li>
<li class="chapter" data-level="2.1.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:DataAlgorithm"><i class="fa fa-check"></i><b>2.1.2</b> Data versus Algorithmic Modeling</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:Process"><i class="fa fa-check"></i><b>2.2</b> Data Analysis Process</a></li>
<li class="chapter" data-level="2.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:SingleVarAnalytics"><i class="fa fa-check"></i><b>2.3</b> Single Variable Analytics</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:VarTypes"><i class="fa fa-check"></i><b>2.3.1</b> Variable Types</a></li>
<li class="chapter" data-level="2.3.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:EDACDA"><i class="fa fa-check"></i><b>2.3.2</b> Exploratory versus Confirmatory</a></li>
<li class="chapter" data-level="2.3.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#model-construction"><i class="fa fa-check"></i><b>2.3.3</b> Model Construction</a></li>
<li class="chapter" data-level="2.3.4" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#model-selection"><i class="fa fa-check"></i><b>2.3.4</b> Model Selection</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:ManyVarAnalytics"><i class="fa fa-check"></i><b>2.4</b> Analytics with Many Variables</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#supervised-and-unsupervised-learning"><i class="fa fa-check"></i><b>2.4.1</b> Supervised and Unsupervised Learning</a></li>
<li class="chapter" data-level="2.4.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#algorithmic-modeling"><i class="fa fa-check"></i><b>2.4.2</b> Algorithmic Modeling</a></li>
<li class="chapter" data-level="2.4.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-modeling"><i class="fa fa-check"></i><b>2.4.3</b> Data Modeling</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:DataLearn"><i class="fa fa-check"></i><b>2.5</b> Data</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-types"><i class="fa fa-check"></i><b>2.5.1</b> Data Types</a></li>
<li class="chapter" data-level="2.5.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-structures-and-storage"><i class="fa fa-check"></i><b>2.5.2</b> Data Structures and Storage</a></li>
<li class="chapter" data-level="2.5.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#data-cleaning"><i class="fa fa-check"></i><b>2.5.3</b> Data Cleaning</a></li>
<li class="chapter" data-level="2.5.4" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#Sec:BigDataAnalysis"><i class="fa fa-check"></i><b>2.5.4</b> Big Data Analysis</a></li>
<li class="chapter" data-level="2.5.5" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#ethical-issues"><i class="fa fa-check"></i><b>2.5.5</b> Ethical Issues</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#DS:further-reading-and-resources"><i class="fa fa-check"></i><b>2.6</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#S:MultiEDA"><i class="fa fa-check"></i><b>2.6.1</b> Technical Supplement: Multivariate Exploratory Analysis</a></li>
<li class="chapter" data-level="2.6.2" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#tree-based-models"><i class="fa fa-check"></i><b>2.6.2</b> Tree-based Models</a></li>
<li class="chapter" data-level="2.6.3" data-path="ChapDataAnalytics.html"><a href="ChapDataAnalytics.html#technical-supplement-some-r-functions"><i class="fa fa-check"></i><b>2.6.3</b> Technical Supplement: Some R Functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html"><i class="fa fa-check"></i><b>3</b> Frequency Modeling</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:frequency-distributions"><i class="fa fa-check"></i><b>3.1</b> Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:how-frequency-augments-severity-information"><i class="fa fa-check"></i><b>3.1.1</b> How Frequency Augments Severity Information</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:basic-frequency-distributions"><i class="fa fa-check"></i><b>3.2</b> Basic Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:foundations"><i class="fa fa-check"></i><b>3.2.1</b> Foundations</a></li>
<li class="chapter" data-level="3.2.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:generating-functions"><i class="fa fa-check"></i><b>3.2.2</b> Moment and Probability Generating Functions</a></li>
<li class="chapter" data-level="3.2.3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:important-frequency-distributions"><i class="fa fa-check"></i><b>3.2.3</b> Important Frequency Distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:the-a-b-0-class"><i class="fa fa-check"></i><b>3.3</b> The (<em>a</em>, <em>b</em>, 0) Class</a></li>
<li class="chapter" data-level="3.4" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:estimating-frequency-distributions"><i class="fa fa-check"></i><b>3.4</b> Estimating Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:parameter-estimation"><i class="fa fa-check"></i><b>3.4.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="3.4.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:frequency-distributions-mle"><i class="fa fa-check"></i><b>3.4.2</b> Frequency Distributions MLE</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:other-frequency-distributions"><i class="fa fa-check"></i><b>3.5</b> Other Frequency Distributions</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:zero-truncation-or-modification"><i class="fa fa-check"></i><b>3.5.1</b> Zero Truncation or Modification</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:mixture-distributions"><i class="fa fa-check"></i><b>3.6</b> Mixture Distributions</a></li>
<li class="chapter" data-level="3.7" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:goodness-of-fit"><i class="fa fa-check"></i><b>3.7</b> Goodness of Fit</a></li>
<li class="chapter" data-level="3.8" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
<li class="chapter" data-level="3.9" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#Freq-further-reading-and-resources"><i class="fa fa-check"></i><b>3.9</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:rcode"><i class="fa fa-check"></i><b>3.9.1</b> TS 3.A. R Code for Plots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ChapSeverity.html"><a href="ChapSeverity.html"><i class="fa fa-check"></i><b>4</b> Modeling Loss Severity</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:BasicQuantities"><i class="fa fa-check"></i><b>4.1</b> Basic Distributional Quantities</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Chap3Moments"><i class="fa fa-check"></i><b>4.1.1</b> Moments</a></li>
<li class="chapter" data-level="4.1.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LS:Quantiles"><i class="fa fa-check"></i><b>4.1.2</b> Quantiles</a></li>
<li class="chapter" data-level="4.1.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#moment-generating-function"><i class="fa fa-check"></i><b>4.1.3</b> Moment Generating Function</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:ContinuousDistn"><i class="fa fa-check"></i><b>4.2</b> Continuous Distributions for Modeling Loss Severity</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Loss:Gamma"><i class="fa fa-check"></i><b>4.2.1</b> Gamma Distribution</a></li>
<li class="chapter" data-level="4.2.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#pareto-distribution"><i class="fa fa-check"></i><b>4.2.2</b> Pareto Distribution</a></li>
<li class="chapter" data-level="4.2.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LS:Weibull"><i class="fa fa-check"></i><b>4.2.3</b> Weibull Distribution</a></li>
<li class="chapter" data-level="4.2.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#the-generalized-beta-distribution-of-the-second-kind"><i class="fa fa-check"></i><b>4.2.4</b> The Generalized Beta Distribution of the Second Kind</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#MethodsCreation"><i class="fa fa-check"></i><b>4.3</b> Methods of Creating New Distributions</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#functions-of-random-variables-and-their-distributions"><i class="fa fa-check"></i><b>4.3.1</b> Functions of Random Variables and their Distributions</a></li>
<li class="chapter" data-level="4.3.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#multiplication-by-a-constant"><i class="fa fa-check"></i><b>4.3.2</b> Multiplication by a Constant</a></li>
<li class="chapter" data-level="4.3.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LossSev:Raising"><i class="fa fa-check"></i><b>4.3.3</b> Raising to a Power</a></li>
<li class="chapter" data-level="4.3.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#exponentiation"><i class="fa fa-check"></i><b>4.3.4</b> Exponentiation</a></li>
<li class="chapter" data-level="4.3.5" data-path="ChapSeverity.html"><a href="ChapSeverity.html#finite-mixtures"><i class="fa fa-check"></i><b>4.3.5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="4.3.6" data-path="ChapSeverity.html"><a href="ChapSeverity.html#continuous-mixtures"><i class="fa fa-check"></i><b>4.3.6</b> Continuous Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#estimating-loss-distributions"><i class="fa fa-check"></i><b>4.4</b> Estimating Loss Distributions</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:MS:NonParEst"><i class="fa fa-check"></i><b>4.4.1</b> Nonparametric Estimation</a></li>
<li class="chapter" data-level="4.4.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#parametric-estimation"><i class="fa fa-check"></i><b>4.4.2</b> Parametric Estimation</a></li>
<li class="chapter" data-level="4.4.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#maximum-likelihood-estimators-for-complete-data"><i class="fa fa-check"></i><b>4.4.3</b> Maximum Likelihood Estimators for Complete Data</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ChapSeverity.html"><a href="ChapSeverity.html#LM-further-reading-and-resources"><i class="fa fa-check"></i><b>4.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html"><i class="fa fa-check"></i><b>5</b> Modeling Claim Severity</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:CoverageModifications"><i class="fa fa-check"></i><b>5.1</b> Coverage Modifications</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:PolicyDeduct"><i class="fa fa-check"></i><b>5.1.1</b> Policy Deductibles</a></li>
<li class="chapter" data-level="5.1.2" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:PolicyLimits"><i class="fa fa-check"></i><b>5.1.2</b> Policy Limits</a></li>
<li class="chapter" data-level="5.1.3" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#coinsurance-and-inflation"><i class="fa fa-check"></i><b>5.1.3</b> Coinsurance and Inflation</a></li>
<li class="chapter" data-level="5.1.4" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:Chap3Reinsurance"><i class="fa fa-check"></i><b>5.1.4</b> Reinsurance</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:MS:ModifiedData1"><i class="fa fa-check"></i><b>5.2</b> Parametric Estimation using Modified Data</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:MS:GroupedData"><i class="fa fa-check"></i><b>5.2.1</b> Parametric Estimation using Grouped Data</a></li>
<li class="chapter" data-level="5.2.2" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#censored-data"><i class="fa fa-check"></i><b>5.2.2</b> Censored Data</a></li>
<li class="chapter" data-level="5.2.3" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#truncated-data"><i class="fa fa-check"></i><b>5.2.3</b> Truncated Data</a></li>
<li class="chapter" data-level="5.2.4" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#parametric-estimation-using-censored-and-truncated-data"><i class="fa fa-check"></i><b>5.2.4</b> Parametric Estimation using Censored and Truncated Data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#nonparametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>5.3</b> Nonparametric Estimation using Modified Data</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#grouped-data"><i class="fa fa-check"></i><b>5.3.1</b> Grouped Data</a></li>
<li class="chapter" data-level="5.3.2" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:MS:PlugIn"><i class="fa fa-check"></i><b>5.3.2</b> Plug-in Principle</a></li>
<li class="chapter" data-level="5.3.3" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#S:MS:RightCensored"><i class="fa fa-check"></i><b>5.3.3</b> Right-Censored Empirical Distribution Function</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#MS:further-reading-and-resources"><i class="fa fa-check"></i><b>5.4</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html"><i class="fa fa-check"></i><b>6</b> Model Selection and Estimation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ModelSelection"><i class="fa fa-check"></i><b>6.1</b> Model Selection</a></li>
<li class="chapter" data-level="6.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ToolsModelSelection"><i class="fa fa-check"></i><b>6.2</b> Tools for Model Selection and Diagnostics</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:GraphComparison"><i class="fa fa-check"></i><b>6.2.1</b> Graphical Comparison of Distributions</a></li>
<li class="chapter" data-level="6.2.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Tools:Stats"><i class="fa fa-check"></i><b>6.2.2</b> Statistical Comparison of Distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Iterative:Selection"><i class="fa fa-check"></i><b>6.3</b> Iterative Model Selection</a></li>
<li class="chapter" data-level="6.4" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Tools:Stats:Likelihood"><i class="fa fa-check"></i><b>6.4</b> Model Selection Based on a Training Dataset</a></li>
<li class="chapter" data-level="6.5" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#model-selection-based-on-a-test-dataset"><i class="fa fa-check"></i><b>6.5</b> Model Selection Based on a Test Dataset</a></li>
<li class="chapter" data-level="6.6" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Cross-Validation"><i class="fa fa-check"></i><b>6.6</b> Model Selection Based on Cross-Validation</a></li>
<li class="chapter" data-level="6.7" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Modified-Data"><i class="fa fa-check"></i><b>6.7</b> Model Selection for Modified Data</a></li>
<li class="chapter" data-level="6.8" data-path="ChapClaimSeverity.html"><a href="ChapClaimSeverity.html#MS:further-reading-and-resources"><i class="fa fa-check"></i><b>6.8</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html"><i class="fa fa-check"></i><b>7</b> Aggregate Loss Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#introduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#individual-risk-model"><i class="fa fa-check"></i><b>7.2</b> Individual Risk Model</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#moments-and-distribution"><i class="fa fa-check"></i><b>7.2.1</b> Moments and Distribution</a></li>
<li class="chapter" data-level="7.2.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#aggregate-loss-distribution"><i class="fa fa-check"></i><b>7.2.2</b> Aggregate Loss Distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:AggLoss:CRM"><i class="fa fa-check"></i><b>7.3</b> Collective Risk Model</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#moments-and-distribution-1"><i class="fa fa-check"></i><b>7.3.1</b> Moments and Distribution</a></li>
<li class="chapter" data-level="7.3.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#stop-loss-insurance"><i class="fa fa-check"></i><b>7.3.2</b> Stop-loss Insurance</a></li>
<li class="chapter" data-level="7.3.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#closed-form-distributions"><i class="fa fa-check"></i><b>7.3.3</b> Closed-form Distributions</a></li>
<li class="chapter" data-level="7.3.4" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:AggLoss:Tweedie"><i class="fa fa-check"></i><b>7.3.4</b> Tweedie Distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#computing-the-aggregate-claims-distribution"><i class="fa fa-check"></i><b>7.4</b> Computing the Aggregate Claims Distribution</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#recursive-method"><i class="fa fa-check"></i><b>7.4.1</b> Recursive Method</a></li>
<li class="chapter" data-level="7.4.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#simulation"><i class="fa fa-check"></i><b>7.4.2</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#effects-of-coverage-modifications"><i class="fa fa-check"></i><b>7.5</b> Effects of Coverage Modifications</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#impact-of-exposure-on-frequency"><i class="fa fa-check"></i><b>7.5.1</b> Impact of Exposure on Frequency</a></li>
<li class="chapter" data-level="7.5.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:MS:DedImpactClmFreq"><i class="fa fa-check"></i><b>7.5.2</b> Impact of Deductibles on Claim Frequency</a></li>
<li class="chapter" data-level="7.5.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#impact-of-policy-modifications-on-aggregate-claims"><i class="fa fa-check"></i><b>7.5.3</b> Impact of Policy Modifications on Aggregate Claims</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#AL-further-reading-and-resources"><i class="fa fa-check"></i><b>7.6</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#ts-6.a.1.-individual-risk-model-properties"><i class="fa fa-check"></i>TS 6.A.1. Individual Risk Model Properties</a></li>
<li class="chapter" data-level="" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#ts-6.a.2.-relationship-between-probability-generating-functions-of-x_i-and-x_it"><i class="fa fa-check"></i>TS 6.A.2. Relationship Between Probability Generating Functions of <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_i^T\)</span></a></li>
<li class="chapter" data-level="" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#ts-6.a.3.-moment-generating-function-of-aggregate-loss-s_n-in-example-6.3.8"><i class="fa fa-check"></i>TS 6.A.3. Moment Generating Function of Aggregate Loss <span class="math inline">\(S_N\)</span> in Example 6.3.8</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ChapSimulation.html"><a href="ChapSimulation.html"><i class="fa fa-check"></i><b>8</b> Simulation and Resampling</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:SimulationFundamentals"><i class="fa fa-check"></i><b>8.1</b> Simulation Fundamentals</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#generating-independent-uniform-observations"><i class="fa fa-check"></i><b>8.1.1</b> Generating Independent Uniform Observations</a></li>
<li class="chapter" data-level="8.1.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:InverseTransform"><i class="fa fa-check"></i><b>8.1.2</b> Inverse Transform Method</a></li>
<li class="chapter" data-level="8.1.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#simulation-precision"><i class="fa fa-check"></i><b>8.1.3</b> Simulation Precision</a></li>
<li class="chapter" data-level="8.1.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:SimulationStatInference"><i class="fa fa-check"></i><b>8.1.4</b> Simulation and Statistical Inference</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:Bootstrap"><i class="fa fa-check"></i><b>8.2</b> Bootstrapping and Resampling</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#bootstrap-foundations"><i class="fa fa-check"></i><b>8.2.1</b> Bootstrap Foundations</a></li>
<li class="chapter" data-level="8.2.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:Sim:Precision"><i class="fa fa-check"></i><b>8.2.2</b> Bootstrap Precision: Bias, Standard Deviation, and Mean Square Error</a></li>
<li class="chapter" data-level="8.2.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#confidence-intervals"><i class="fa fa-check"></i><b>8.2.3</b> Confidence Intervals</a></li>
<li class="chapter" data-level="8.2.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:ParametricBootStrap"><i class="fa fa-check"></i><b>8.2.4</b> Parametric Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:CrossValidation"><i class="fa fa-check"></i><b>8.3</b> Cross-Validation</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>8.3.1</b> k-Fold Cross-Validation</a></li>
<li class="chapter" data-level="8.3.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>8.3.2</b> Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="8.3.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#cross-validation-and-bootstrap"><i class="fa fa-check"></i><b>8.3.3</b> Cross-Validation and Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:ImportanceSampling"><i class="fa fa-check"></i><b>8.4</b> Importance Sampling</a></li>
<li class="chapter" data-level="8.5" data-path="ChapSimulation.html"><a href="ChapSimulation.html#Simulation:further-reading-and-resources"><i class="fa fa-check"></i><b>8.5</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#ts-7.a.-bootstrap-applications-in-predictive-modeling"><i class="fa fa-check"></i><b>8.5.1</b> TS 7.A. Bootstrap Applications in Predictive Modeling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ChBayes.html"><a href="ChBayes.html"><i class="fa fa-check"></i><b>9</b> Bayesian Inference and Modeling</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecIntro"><i class="fa fa-check"></i><b>9.1</b> A Gentle Introduction to Bayesian Statistics</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubSecBayesVsFreq"><i class="fa fa-check"></i><b>9.1.1</b> Bayesian versus Frequentist Statistics</a></li>
<li class="chapter" data-level="9.1.2" data-path="ChBayes.html"><a href="ChBayes.html#a-brief-history-lesson"><i class="fa fa-check"></i><b>9.1.2</b> A Brief History Lesson</a></li>
<li class="chapter" data-level="9.1.3" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecBayesRule"><i class="fa fa-check"></i><b>9.1.3</b> Bayes Rule</a></li>
<li class="chapter" data-level="9.1.4" data-path="ChBayes.html"><a href="ChBayes.html#an-introductory-example-of-bayes-rule"><i class="fa fa-check"></i><b>9.1.4</b> An Introductory Example of Bayes Rule</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecBuildingBlocks"><i class="fa fa-check"></i><b>9.2</b> Building Blocks of Bayesian Inference</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecPosterior"><i class="fa fa-check"></i><b>9.2.1</b> Posterior Distribution</a></li>
<li class="chapter" data-level="9.2.2" data-path="ChBayes.html"><a href="ChBayes.html#likelihood-function"><i class="fa fa-check"></i><b>9.2.2</b> Likelihood Function</a></li>
<li class="chapter" data-level="9.2.3" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecPrior"><i class="fa fa-check"></i><b>9.2.3</b> Prior Distribution</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecConjugate"><i class="fa fa-check"></i><b>9.3</b> Conjugate Families</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecBetaBin"><i class="fa fa-check"></i><b>9.3.1</b> The BetaBinomial Conjugate Family</a></li>
<li class="chapter" data-level="9.3.2" data-path="ChBayes.html"><a href="ChBayes.html#the-gammapoisson-conjugate-family"><i class="fa fa-check"></i><b>9.3.2</b> The GammaPoisson Conjugate Family</a></li>
<li class="chapter" data-level="9.3.3" data-path="ChBayes.html"><a href="ChBayes.html#the-normalnormal-conjugate-family"><i class="fa fa-check"></i><b>9.3.3</b> The NormalNormal Conjugate Family</a></li>
<li class="chapter" data-level="9.3.4" data-path="ChBayes.html"><a href="ChBayes.html#criticism-of-conjugate-family-models"><i class="fa fa-check"></i><b>9.3.4</b> Criticism of Conjugate Family Models</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecPosterior"><i class="fa fa-check"></i><b>9.4</b> Posterior Simulation</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="ChBayes.html"><a href="ChBayes.html#introduction-to-markov-chain-monte-carlo-methods"><i class="fa fa-check"></i><b>9.4.1</b> Introduction to Markov Chain Monte Carlo Methods</a></li>
<li class="chapter" data-level="9.4.2" data-path="ChBayes.html"><a href="ChBayes.html#the-gibbs-sampler"><i class="fa fa-check"></i><b>9.4.2</b> The Gibbs Sampler</a></li>
<li class="chapter" data-level="9.4.3" data-path="ChBayes.html"><a href="ChBayes.html#the-metropolishastings-algorithm"><i class="fa fa-check"></i><b>9.4.3</b> The MetropolisHastings Algorithm</a></li>
<li class="chapter" data-level="9.4.4" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SubsecDiag"><i class="fa fa-check"></i><b>9.4.4</b> Markov Chain Diagnostics</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ChBayes.html"><a href="ChBayes.html#ChBayes:SecFurther"><i class="fa fa-check"></i><b>9.5</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChBayes.html"><a href="ChBayes.html#contributors-8"><i class="fa fa-check"></i>Contributors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html"><i class="fa fa-check"></i><b>10</b> Premium Foundations</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:IntroductionRatemaking"><i class="fa fa-check"></i><b>10.1</b> Introduction to Ratemaking</a></li>
<li class="chapter" data-level="10.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:AggRateMaking"><i class="fa fa-check"></i><b>10.2</b> Aggregate Ratemaking Methods</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:PurePremium"><i class="fa fa-check"></i><b>10.2.1</b> Pure Premium Method</a></li>
<li class="chapter" data-level="10.2.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:LossRatio"><i class="fa fa-check"></i><b>10.2.2</b> Loss Ratio Method</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:PricingPrinciples"><i class="fa fa-check"></i><b>10.3</b> Pricing Principles</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#premium-principles"><i class="fa fa-check"></i><b>10.3.1</b> Premium Principles</a></li>
<li class="chapter" data-level="10.3.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#properties-of-premium-principles"><i class="fa fa-check"></i><b>10.3.2</b> Properties of Premium Principles</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:HeterogeneousRisks"><i class="fa fa-check"></i><b>10.4</b> Heterogeneous Risks</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:ExposureToRisk"><i class="fa fa-check"></i><b>10.4.1</b> Exposure to Risk</a></li>
<li class="chapter" data-level="10.4.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:RatingFactors"><i class="fa fa-check"></i><b>10.4.2</b> Rating Factors</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:TrendDevelopment"><i class="fa fa-check"></i><b>10.5</b> Development and Trending</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#exposures-and-premiums"><i class="fa fa-check"></i><b>10.5.1</b> Exposures and Premiums</a></li>
<li class="chapter" data-level="10.5.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#losses-claims-and-payments"><i class="fa fa-check"></i><b>10.5.2</b> Losses, Claims, and Payments</a></li>
<li class="chapter" data-level="10.5.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:CompareMethods"><i class="fa fa-check"></i><b>10.5.3</b> Comparing Pure Premium and Loss Ratio Methods</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:GiniStatistic"><i class="fa fa-check"></i><b>10.6</b> Selecting a Premium</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#classic-lorenz-curve"><i class="fa fa-check"></i><b>10.6.1</b> Classic Lorenz Curve</a></li>
<li class="chapter" data-level="10.6.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#performance-curve-and-a-gini-statistic"><i class="fa fa-check"></i><b>10.6.2</b> Performance Curve and a Gini Statistic</a></li>
<li class="chapter" data-level="10.6.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#out-of-sample-validation"><i class="fa fa-check"></i><b>10.6.3</b> Out-of-Sample Validation</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#further-resources-and-contributors"><i class="fa fa-check"></i><b>10.7</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#ts-9.a.-rate-regulation"><i class="fa fa-check"></i>TS 9.A. Rate Regulation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html"><i class="fa fa-check"></i><b>11</b> Risk Classification</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:Introduction"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:PoissonRegression"><i class="fa fa-check"></i><b>11.2</b> Poisson Regression Model</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:Need.Poi.reg"><i class="fa fa-check"></i><b>11.2.1</b> Need for Poisson Regression</a></li>
<li class="chapter" data-level="11.2.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#poisson-regression"><i class="fa fa-check"></i><b>11.2.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="11.2.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#incorporating-exposure"><i class="fa fa-check"></i><b>11.2.3</b> Incorporating Exposure</a></li>
<li class="chapter" data-level="11.2.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#exercises-5"><i class="fa fa-check"></i><b>11.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:CatVarMultiTarriff"><i class="fa fa-check"></i><b>11.3</b> Categorical Variables and Multiplicative Tariff</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#rating-factors-and-tariff"><i class="fa fa-check"></i><b>11.3.1</b> Rating Factors and Tariff</a></li>
<li class="chapter" data-level="11.3.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#multiplicative-tariff-model"><i class="fa fa-check"></i><b>11.3.2</b> Multiplicative Tariff Model</a></li>
<li class="chapter" data-level="11.3.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#poisson-regression-for-multiplicative-tariff"><i class="fa fa-check"></i><b>11.3.3</b> Poisson Regression for Multiplicative Tariff</a></li>
<li class="chapter" data-level="11.3.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#numerical-examples"><i class="fa fa-check"></i><b>11.3.4</b> Numerical Examples</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#RC:further-reading-and-resources"><i class="fa fa-check"></i><b>11.4</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#ts-10.a.-estimating-poisson-regression-models"><i class="fa fa-check"></i>TS 10.A. Estimating Poisson Regression Models</a></li>
<li class="chapter" data-level="" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#ts-10.b.-selecting-rating-factors"><i class="fa fa-check"></i>TS 10.B. Selecting Rating Factors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ChapCredibility.html"><a href="ChapCredibility.html"><i class="fa fa-check"></i><b>12</b> Experience Rating Using Credibility Theory</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#introduction-to-applications-of-credibility-theory"><i class="fa fa-check"></i><b>12.1</b> Introduction to Applications of Credibility Theory</a></li>
<li class="chapter" data-level="12.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#limited-fluctuation-credibility"><i class="fa fa-check"></i><b>12.2</b> Limited Fluctuation Credibility</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:frequency"><i class="fa fa-check"></i><b>12.2.1</b> Full Credibility for Claim Frequency</a></li>
<li class="chapter" data-level="12.2.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-for-aggregate-losses-and-pure-premium"><i class="fa fa-check"></i><b>12.2.2</b> Full Credibility for Aggregate Losses and Pure Premium</a></li>
<li class="chapter" data-level="12.2.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-for-severity"><i class="fa fa-check"></i><b>12.2.3</b> Full Credibility for Severity</a></li>
<li class="chapter" data-level="12.2.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#partial-credibility"><i class="fa fa-check"></i><b>12.2.4</b> Partial Credibility</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:Cred:Buhlmann"><i class="fa fa-check"></i><b>12.3</b> Bhlmann Credibility</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:EPV-VHM-Z"><i class="fa fa-check"></i><b>12.3.1</b> Credibility <em>Z</em>, <em>EPV</em>, and <em>VHM</em></a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#bhlmann-straub-credibility"><i class="fa fa-check"></i><b>12.4</b> Bhlmann-Straub Credibility</a></li>
<li class="chapter" data-level="12.5" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:Cred:BayesInf"><i class="fa fa-check"></i><b>12.5</b> Bayesian Inference and Bhlmann Credibility</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#Sec:Cred:gammaPoisson"><i class="fa fa-check"></i><b>12.5.1</b> Gamma-Poisson Model</a></li>
<li class="chapter" data-level="12.5.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#beta-binomial-model"><i class="fa fa-check"></i><b>12.5.2</b> Beta-Binomial Model</a></li>
<li class="chapter" data-level="12.5.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#exact-credibility"><i class="fa fa-check"></i><b>12.5.3</b> Exact Credibility</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="ChapCredibility.html"><a href="ChapCredibility.html#estimating-credibility-parameters"><i class="fa fa-check"></i><b>12.6</b> Estimating Credibility Parameters</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-standard-for-limited-fluctuation-credibility"><i class="fa fa-check"></i><b>12.6.1</b> Full Credibility Standard for Limited Fluctuation Credibility</a></li>
<li class="chapter" data-level="12.6.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#nonparametric-estimation-for-bhlmann-and-bhlmann-straub-models"><i class="fa fa-check"></i><b>12.6.2</b> Nonparametric Estimation for Bhlmann and Bhlmann-Straub Models</a></li>
<li class="chapter" data-level="12.6.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#semiparametric-estimation-for-bhlmann-and-bhlmann-straub-models"><i class="fa fa-check"></i><b>12.6.3</b> Semiparametric Estimation for Bhlmann and Bhlmann-Straub Models</a></li>
<li class="chapter" data-level="12.6.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#balancing-credibility-estimators"><i class="fa fa-check"></i><b>12.6.4</b> Balancing Credibility Estimators</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="ChapCredibility.html"><a href="ChapCredibility.html#Cred-further-reading-and-resources"><i class="fa fa-check"></i><b>12.7</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html"><i class="fa fa-check"></i><b>13</b> Insurance Portfolio Management including Reinsurance</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#introduction-to-insurance-portfolios"><i class="fa fa-check"></i><b>13.1</b> Introduction to Insurance Portfolios</a></li>
<li class="chapter" data-level="13.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:Tails"><i class="fa fa-check"></i><b>13.2</b> Tails of Distributions</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#classification-based-on-moments"><i class="fa fa-check"></i><b>13.2.1</b> Classification Based on Moments</a></li>
<li class="chapter" data-level="13.2.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#comparison-based-on-limiting-tail-behavior"><i class="fa fa-check"></i><b>13.2.2</b> Comparison Based on Limiting Tail Behavior</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:RiskMeasure"><i class="fa fa-check"></i><b>13.3</b> Risk Measures</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#coherent-risk-measures"><i class="fa fa-check"></i><b>13.3.1</b> Coherent Risk Measures</a></li>
<li class="chapter" data-level="13.3.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#value-at-risk"><i class="fa fa-check"></i><b>13.3.2</b> Value-at-Risk</a></li>
<li class="chapter" data-level="13.3.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#tail-value-at-risk"><i class="fa fa-check"></i><b>13.3.3</b> Tail Value-at-Risk</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:Reinsurance"><i class="fa fa-check"></i><b>13.4</b> Reinsurance</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:ProportionalRe"><i class="fa fa-check"></i><b>13.4.1</b> Proportional Reinsurance</a></li>
<li class="chapter" data-level="13.4.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:NonProportionalRe"><i class="fa fa-check"></i><b>13.4.2</b> Non-Proportional Reinsurance</a></li>
<li class="chapter" data-level="13.4.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:AdditionalRe"><i class="fa fa-check"></i><b>13.4.3</b> Additional Reinsurance Treaties</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#further-resources-and-contributors-1"><i class="fa fa-check"></i><b>13.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html"><i class="fa fa-check"></i><b>14</b> Loss Reserving</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:motivation"><i class="fa fa-check"></i><b>14.1</b> Motivation</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:claim-types"><i class="fa fa-check"></i><b>14.1.1</b> Closed, IBNR, and RBNS Claims</a></li>
<li class="chapter" data-level="14.1.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#why-reserving"><i class="fa fa-check"></i><b>14.1.2</b> Why Reserving?</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Data"><i class="fa fa-check"></i><b>14.2</b> Loss Reserve Data</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#from-micro-to-macro"><i class="fa fa-check"></i><b>14.2.1</b> From Micro to Macro</a></li>
<li class="chapter" data-level="14.2.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#run-off-triangles"><i class="fa fa-check"></i><b>14.2.2</b> Run-off Triangles</a></li>
<li class="chapter" data-level="14.2.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#loss-reserve-notation"><i class="fa fa-check"></i><b>14.2.3</b> Loss Reserve Notation</a></li>
<li class="chapter" data-level="14.2.4" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Rcode"><i class="fa fa-check"></i><b>14.2.4</b> R Code to Summarize Loss Reserve Data</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Chain-ladder"><i class="fa fa-check"></i><b>14.3</b> The Chain-Ladder Method</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:DeterministicCL"><i class="fa fa-check"></i><b>14.3.1</b> The Deterministic Chain-Ladder</a></li>
<li class="chapter" data-level="14.3.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#macks-distribution-free-chain-ladder-model"><i class="fa fa-check"></i><b>14.3.2</b> Macks Distribution-Free Chain-Ladder Model</a></li>
<li class="chapter" data-level="14.3.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#r-code-for-chain-ladder-predictions"><i class="fa fa-check"></i><b>14.3.3</b> R code for Chain-Ladder Predictions</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:GLMs"><i class="fa fa-check"></i><b>14.4</b> GLMs and Bootstrap for Loss Reserves</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#model-specification"><i class="fa fa-check"></i><b>14.4.1</b> Model Specification</a></li>
<li class="chapter" data-level="14.4.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#model-estimation-and-prediction"><i class="fa fa-check"></i><b>14.4.2</b> Model Estimation and Prediction</a></li>
<li class="chapter" data-level="14.4.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#bootstrap"><i class="fa fa-check"></i><b>14.4.3</b> Bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#LossRe:further-reading-and-resources"><i class="fa fa-check"></i><b>14.5</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html"><i class="fa fa-check"></i><b>15</b> Experience Rating using Bonus-Malus</a>
<ul>
<li class="chapter" data-level="15.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:Intro"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:NCD"><i class="fa fa-check"></i><b>15.2</b> <em>NCD</em> System in Several Countries</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#ncd-system-in-malaysia"><i class="fa fa-check"></i><b>15.2.1</b> <em>NCD</em> System in Malaysia</a></li>
<li class="chapter" data-level="15.2.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#ncd-systems-in-other-countries"><i class="fa fa-check"></i><b>15.2.2</b> NCD Systems in Other Countries</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:BMS"><i class="fa fa-check"></i><b>15.3</b> <em>BMS</em> and Markov Chain Model</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#transition-probability"><i class="fa fa-check"></i><b>15.3.1</b> Transition Probability</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:StatDist"><i class="fa fa-check"></i><b>15.4</b> <em>BMS</em> and Stationary Distribution</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#stationary-distribution"><i class="fa fa-check"></i><b>15.4.1</b> Stationary Distribution</a></li>
<li class="chapter" data-level="15.4.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-code-for-a-stationary-distribution"><i class="fa fa-check"></i><b>15.4.2</b> <code>R</code> Code for a Stationary Distribution</a></li>
<li class="chapter" data-level="15.4.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#premium-evolution"><i class="fa fa-check"></i><b>15.4.3</b> Premium Evolution</a></li>
<li class="chapter" data-level="15.4.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-program-for-premium-evolution"><i class="fa fa-check"></i><b>15.4.4</b> <code>R</code> Program for Premium Evolution</a></li>
<li class="chapter" data-level="15.4.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#convergence-rate"><i class="fa fa-check"></i><b>15.4.5</b> Convergence Rate</a></li>
<li class="chapter" data-level="15.4.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-program-for-convergence-rate"><i class="fa fa-check"></i><b>15.4.6</b> <code>R</code> Program for Convergence Rate</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:PremRtg"><i class="fa fa-check"></i><b>15.5</b> <em>BMS</em> and Premium Rating</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#premium-rating"><i class="fa fa-check"></i><b>15.5.1</b> Premium Rating</a></li>
<li class="chapter" data-level="15.5.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#a-priori-risk-classification"><i class="fa fa-check"></i><b>15.5.2</b> A Priori Risk Classification</a></li>
<li class="chapter" data-level="15.5.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#modelling-of-residual-heterogeneity"><i class="fa fa-check"></i><b>15.5.3</b> Modelling of Residual Heterogeneity</a></li>
<li class="chapter" data-level="15.5.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#stationary-distribution-allowing-for-residual-heterogeneity"><i class="fa fa-check"></i><b>15.5.4</b> Stationary Distribution Allowing for Residual Heterogeneity</a></li>
<li class="chapter" data-level="15.5.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#determination-of-optimal-relativities"><i class="fa fa-check"></i><b>15.5.5</b> Determination of Optimal Relativities</a></li>
<li class="chapter" data-level="15.5.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#numerical-illustrations"><i class="fa fa-check"></i><b>15.5.6</b> Numerical Illustrations</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:Further"><i class="fa fa-check"></i><b>15.6</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>15.6.1</b> Further Reading and References</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html"><i class="fa fa-check"></i><b>16</b> Dependence Modeling</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#multivariate-variables"><i class="fa fa-check"></i><b>16.1</b> Multivariate Variables</a></li>
<li class="chapter" data-level="16.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:Measures"><i class="fa fa-check"></i><b>16.2</b> Classic Measures of Scalar Associations</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#association-measures-for-quantitative-variables"><i class="fa fa-check"></i><b>16.2.1</b> Association Measures for Quantitative Variables</a></li>
<li class="chapter" data-level="16.2.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#rank-based-measures"><i class="fa fa-check"></i><b>16.2.2</b> Rank Based Measures</a></li>
<li class="chapter" data-level="16.2.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#nominal-variables"><i class="fa fa-check"></i><b>16.2.3</b> Nominal Variables</a></li>
<li class="chapter" data-level="16.2.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#ordinal-variables"><i class="fa fa-check"></i><b>16.2.4</b> Ordinal Variables</a></li>
<li class="chapter" data-level="16.2.5" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#interval-variables"><i class="fa fa-check"></i><b>16.2.5</b> Interval Variables</a></li>
<li class="chapter" data-level="16.2.6" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#discrete-and-continuous-variables"><i class="fa fa-check"></i><b>16.2.6</b> Discrete and Continuous Variables</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:Copula"><i class="fa fa-check"></i><b>16.3</b> Introduction to Copulas</a></li>
<li class="chapter" data-level="16.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopAppl"><i class="fa fa-check"></i><b>16.4</b> Application Using Copulas</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#data-description"><i class="fa fa-check"></i><b>16.4.1</b> Data Description</a></li>
<li class="chapter" data-level="16.4.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#marginal-models"><i class="fa fa-check"></i><b>16.4.2</b> Marginal Models</a></li>
<li class="chapter" data-level="16.4.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#probability-integral-transformation"><i class="fa fa-check"></i><b>16.4.3</b> Probability Integral Transformation</a></li>
<li class="chapter" data-level="16.4.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#joint-modeling-with-copula-function"><i class="fa fa-check"></i><b>16.4.4</b> Joint Modeling with Copula Function</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopTyp"><i class="fa fa-check"></i><b>16.5</b> Types of Copulas</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#normal-gaussian-copulas"><i class="fa fa-check"></i><b>16.5.1</b> Normal (Gaussian) Copulas</a></li>
<li class="chapter" data-level="16.5.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#t--and-elliptical-copulas"><i class="fa fa-check"></i><b>16.5.2</b> <em>t</em>- and Elliptical Copulas</a></li>
<li class="chapter" data-level="16.5.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#archimedean-copulas"><i class="fa fa-check"></i><b>16.5.3</b> Archimedean Copulas</a></li>
<li class="chapter" data-level="16.5.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#properties-of-copulas"><i class="fa fa-check"></i><b>16.5.4</b> Properties of Copulas</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopImp"><i class="fa fa-check"></i><b>16.6</b> Why is Dependence Modeling Important?</a></li>
<li class="chapter" data-level="16.7" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#Dep:further-reading-and-resources"><i class="fa fa-check"></i><b>16.7</b> Further Resources and Contributors</a>
<ul>
<li class="chapter" data-level="" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#ts-15.a.-other-classic-measures-of-scalar-associations"><i class="fa fa-check"></i>TS 15.A. Other Classic Measures of Scalar Associations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="CAppA.html"><a href="CAppA.html"><i class="fa fa-check"></i><b>17</b> Appendix A: Review of Statistical Inference</a>
<ul>
<li class="chapter" data-level="17.1" data-path="CAppA.html"><a href="CAppA.html#S:AppA:BASIC"><i class="fa fa-check"></i><b>17.1</b> Basic Concepts</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="CAppA.html"><a href="CAppA.html#random-sampling"><i class="fa fa-check"></i><b>17.1.1</b> Random Sampling</a></li>
<li class="chapter" data-level="17.1.2" data-path="CAppA.html"><a href="CAppA.html#sampling-distribution"><i class="fa fa-check"></i><b>17.1.2</b> Sampling Distribution</a></li>
<li class="chapter" data-level="17.1.3" data-path="CAppA.html"><a href="CAppA.html#central-limit-theorem"><i class="fa fa-check"></i><b>17.1.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="CAppA.html"><a href="CAppA.html#S:AppA:PE"><i class="fa fa-check"></i><b>17.2</b> Point Estimation and Properties</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="CAppA.html"><a href="CAppA.html#method-of-moments-estimation"><i class="fa fa-check"></i><b>17.2.1</b> Method of Moments Estimation</a></li>
<li class="chapter" data-level="17.2.2" data-path="CAppA.html"><a href="CAppA.html#S:AppA:MLE"><i class="fa fa-check"></i><b>17.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="CAppA.html"><a href="CAppA.html#S:AppA:IE"><i class="fa fa-check"></i><b>17.3</b> Interval Estimation</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="CAppA.html"><a href="CAppA.html#S:AppA:IE:ED"><i class="fa fa-check"></i><b>17.3.1</b> Exact Distribution for Normal Sample Mean</a></li>
<li class="chapter" data-level="17.3.2" data-path="CAppA.html"><a href="CAppA.html#large-sample-properties-of-mle"><i class="fa fa-check"></i><b>17.3.2</b> Large-sample Properties of <em>MLE</em></a></li>
<li class="chapter" data-level="17.3.3" data-path="CAppA.html"><a href="CAppA.html#confidence-interval"><i class="fa fa-check"></i><b>17.3.3</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT"><i class="fa fa-check"></i><b>17.4</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="CAppA.html"><a href="CAppA.html#basic-concepts"><i class="fa fa-check"></i><b>17.4.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="17.4.2" data-path="CAppA.html"><a href="CAppA.html#student-t-test-based-on-mle"><i class="fa fa-check"></i><b>17.4.2</b> Student-<em>t</em> test based on <em>mle</em></a></li>
<li class="chapter" data-level="17.4.3" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT:LRT"><i class="fa fa-check"></i><b>17.4.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="17.4.4" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT:IC"><i class="fa fa-check"></i><b>17.4.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="CAppB.html"><a href="CAppB.html"><i class="fa fa-check"></i><b>18</b> Appendix B: Iterated Expectations</a>
<ul>
<li class="chapter" data-level="18.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:CD"><i class="fa fa-check"></i><b>18.1</b> Conditional Distribution and Conditional Expectation</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="CAppB.html"><a href="CAppB.html#conditional-distribution"><i class="fa fa-check"></i><b>18.1.1</b> Conditional Distribution</a></li>
<li class="chapter" data-level="18.1.2" data-path="CAppB.html"><a href="CAppB.html#conditional-expectation-and-conditional-variance"><i class="fa fa-check"></i><b>18.1.2</b> Conditional Expectation and Conditional Variance</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="CAppB.html"><a href="CAppB.html#S:AppB:IE"><i class="fa fa-check"></i><b>18.2</b> Iterated Expectations and Total Variance</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:LIE"><i class="fa fa-check"></i><b>18.2.1</b> Law of Iterated Expectations</a></li>
<li class="chapter" data-level="18.2.2" data-path="CAppB.html"><a href="CAppB.html#law-of-total-variance"><i class="fa fa-check"></i><b>18.2.2</b> Law of Total Variance</a></li>
<li class="chapter" data-level="18.2.3" data-path="CAppB.html"><a href="CAppB.html#application"><i class="fa fa-check"></i><b>18.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="CAppB.html"><a href="CAppB.html#S:AppConjugateDistributions"><i class="fa fa-check"></i><b>18.3</b> Conjugate Distributions</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="CAppB.html"><a href="CAppB.html#linear-exponential-family"><i class="fa fa-check"></i><b>18.3.1</b> Linear Exponential Family</a></li>
<li class="chapter" data-level="18.3.2" data-path="CAppB.html"><a href="CAppB.html#S:IterExp:Conjugate"><i class="fa fa-check"></i><b>18.3.2</b> Conjugate Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="CAppC.html"><a href="CAppC.html"><i class="fa fa-check"></i><b>19</b> Appendix C: Maximum Likelihood Theory</a>
<ul>
<li class="chapter" data-level="19.1" data-path="CAppC.html"><a href="CAppC.html#S:AppC:LF"><i class="fa fa-check"></i><b>19.1</b> Likelihood Function</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="CAppC.html"><a href="CAppC.html#likelihood-and-log-likelihood-functions"><i class="fa fa-check"></i><b>19.1.1</b> Likelihood and Log-likelihood Functions</a></li>
<li class="chapter" data-level="19.1.2" data-path="CAppC.html"><a href="CAppC.html#properties-of-likelihood-functions"><i class="fa fa-check"></i><b>19.1.2</b> Properties of Likelihood Functions</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="CAppC.html"><a href="CAppC.html#S:AppC:MLE"><i class="fa fa-check"></i><b>19.2</b> Maximum Likelihood Estimators</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="CAppC.html"><a href="CAppC.html#definition-and-derivation-of-mle"><i class="fa fa-check"></i><b>19.2.1</b> Definition and Derivation of <em>MLE</em></a></li>
<li class="chapter" data-level="19.2.2" data-path="CAppC.html"><a href="CAppC.html#asymptotic-properties-of-mle"><i class="fa fa-check"></i><b>19.2.2</b> Asymptotic Properties of <em>MLE</em></a></li>
<li class="chapter" data-level="19.2.3" data-path="CAppC.html"><a href="CAppC.html#use-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>19.2.3</b> Use of Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="CAppC.html"><a href="CAppC.html#S:AppC:SI"><i class="fa fa-check"></i><b>19.3</b> Statistical Inference Based on Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="CAppC.html"><a href="CAppC.html#hypothesis-testing"><i class="fa fa-check"></i><b>19.3.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="19.3.2" data-path="CAppC.html"><a href="CAppC.html#S:AppC:MLEModelVal"><i class="fa fa-check"></i><b>19.3.2</b> <em>MLE</em> and Model Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html"><i class="fa fa-check"></i><b>20</b> Appendix D: Summary of Distributions</a>
<ul>
<li class="chapter" data-level="20.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:DiscreteDistributions"><i class="fa fa-check"></i><b>20.1</b> Discrete Distributions</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab0-class"><i class="fa fa-check"></i><b>20.1.1</b> The <em>(a,b,0)</em> Class</a></li>
<li class="chapter" data-level="20.1.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab1-class"><i class="fa fa-check"></i><b>20.1.2</b> The <em>(a,b,1)</em> Class</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:ContinuousDistributions"><i class="fa fa-check"></i><b>20.2</b> Continuous Distributions</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#one-parameter-distributions"><i class="fa fa-check"></i><b>20.2.1</b> One Parameter Distributions</a></li>
<li class="chapter" data-level="20.2.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#two-parameter-distributions"><i class="fa fa-check"></i><b>20.2.2</b> Two Parameter Distributions</a></li>
<li class="chapter" data-level="20.2.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#three-parameter-distributions"><i class="fa fa-check"></i><b>20.2.3</b> Three Parameter Distributions</a></li>
<li class="chapter" data-level="20.2.4" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#four-parameter-distribution"><i class="fa fa-check"></i><b>20.2.4</b> Four Parameter Distribution</a></li>
<li class="chapter" data-level="20.2.5" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#other-distributions"><i class="fa fa-check"></i><b>20.2.5</b> Other Distributions</a></li>
<li class="chapter" data-level="20.2.6" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#distributions-with-finite-support"><i class="fa fa-check"></i><b>20.2.6</b> Distributions with Finite Support</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#limited-expected-values"><i class="fa fa-check"></i><b>20.3</b> Limited Expected Values</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html"><i class="fa fa-check"></i><b>21</b> Appendix E: Conventions for Notation</a>
<ul>
<li class="chapter" data-level="21.1" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:General"><i class="fa fa-check"></i><b>21.1</b> General Conventions</a></li>
<li class="chapter" data-level="21.2" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Abbreviations"><i class="fa fa-check"></i><b>21.2</b> Abbreviations</a></li>
<li class="chapter" data-level="21.3" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:StatSymbols"><i class="fa fa-check"></i><b>21.3</b> Common Statistical Symbols and Operators</a></li>
<li class="chapter" data-level="21.4" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Symbols"><i class="fa fa-check"></i><b>21.4</b> Common Mathematical Symbols and Functions</a></li>
<li class="chapter" data-level="21.5" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#further-readings"><i class="fa fa-check"></i><b>21.5</b> Further Readings</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="DataResources.html"><a href="DataResources.html"><i class="fa fa-check"></i><b>22</b> Appendix. Data Resources</a>
<ul>
<li class="chapter" data-level="22.1" data-path="DataResources.html"><a href="DataResources.html#S:WiscPropFundA"><i class="fa fa-check"></i><b>22.1</b> Wisconsin Property Fund</a></li>
<li class="chapter" data-level="22.2" data-path="DataResources.html"><a href="DataResources.html#Sec:DataTravel"><i class="fa fa-check"></i><b>22.2</b> ANU Corporate Travel Data</a></li>
<li class="chapter" data-level="22.3" data-path="DataResources.html"><a href="DataResources.html#Sec:DataGPA"><i class="fa fa-check"></i><b>22.3</b> ANU Group Personal Accident Data</a></li>
<li class="chapter" data-level="22.4" data-path="DataResources.html"><a href="DataResources.html#Sec:DataAuto"><i class="fa fa-check"></i><b>22.4</b> ANU Motor Vehicle Data</a></li>
<li class="chapter" data-level="22.5" data-path="DataResources.html"><a href="DataResources.html#spanish-personal-insurance-data"><i class="fa fa-check"></i><b>22.5</b> Spanish Personal Insurance Data</a></li>
<li class="chapter" data-level="22.6" data-path="DataResources.html"><a href="DataResources.html#r-package-casdatasets"><i class="fa fa-check"></i><b>22.6</b> R Package CASdatasets</a></li>
<li class="chapter" data-level="22.7" data-path="DataResources.html"><a href="DataResources.html#other-data-sources"><i class="fa fa-check"></i><b>22.7</b> Other Data Sources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTexts/Loss-Data-Analytics" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ChapSeverity" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Modeling Loss Severity<a href="ChapSeverity.html#ChapSeverity" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Chapter Preview.</em> The traditional loss distribution approach to modeling <a href="#" class="tooltip" style="color:green"><em>aggregate losses</em><span style="font-size:8pt">Aggregate claims, or total claims observed in the time period</span></a> starts by separately fitting a frequency distribution to the number of losses and a severity distribution to the size of losses. The estimated aggregate loss distribution combines the loss frequency distribution and the loss severity distribution by convolution. Discrete distributions often referred to as counting or frequency distributions were used in Chapter <a href="ChapFrequency-Modeling.html#ChapFrequency-Modeling">3</a> to describe the number of events such as number of accidents to the driver or number of claims to the insurer. Lifetimes, asset values, losses and claim sizes are usually modeled as continuous random variables and as such are modeled using continuous distributions, often referred to as loss or severity distributions. A <a href="#" class="tooltip" style="color:green"><em>mixture distribution</em><span style="font-size:8pt">A weighted average of other distributions, which may be continuous or discrete</span></a> is a weighted combination of simpler distributions that is used to model phenomenon investigated in a heterogeneous population, such as modeling more than one type of claims in <a href="#" class="tooltip" style="color:green"><em>liability insurance</em><span style="font-size:8pt">Insurance that compensates an insured for loss due to legal liability towards others</span></a> (small frequent claims and large relatively rare claims). In this chapter we explore the use of continuous as well as mixture distributions to model the random size of loss. Sections <a href="ChapSeverity.html#S:BasicQuantities">4.1</a> and <a href="ChapSeverity.html#S:ContinuousDistn">4.2</a> present key attributes that characterize continuous models and means of creating new distributions from existing ones. Section <a href="ChapClaimSeverity.html#S:CoverageModifications">5.1</a> describes the effect of coverage modifications, which change the conditions that trigger a payment, such as applying deductibles, limits, or adjusting for inflation, on the distribution of individual loss amounts. For calibrating models, Section <a href="#S:MaxLikeEstimation"><strong>??</strong></a> deepens our understanding of maximum likelihood methods. The frequency distributions from Chapter <a href="ChapFrequency-Modeling.html#ChapFrequency-Modeling">3</a> will be combined with the ideas from this chapter to describe the aggregate losses over the whole portfolio in Chapter <a href="ChapAggLossModels.html#ChapAggLossModels">7</a>.</p>
<div id="S:BasicQuantities" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Basic Distributional Quantities<a href="ChapSeverity.html#S:BasicQuantities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to define some basic distributional quantities:</p>
<ul>
<li>moments,</li>
<li>percentiles, and</li>
<li>generating functions.</li>
</ul>
<hr />
<div id="S:Chap3Moments" class="section level3 hasAnchor" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Moments<a href="ChapSeverity.html#S:Chap3Moments" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(X\)</span> be a <a href="#" class="tooltip" style="color:green"><em>continuous random variable</em><span style="font-size:8pt">Random variable which can take infinitely many values in its specified domain</span></a> with probability density function (<em>pdf</em>) <span class="math inline">\(f_{X}\left( x \right)\)</span> and distribution function <span class="math inline">\(F_{X}\left( x \right)\)</span>. The <em>k</em>-th <a href="#" class="tooltip" style="color:green"><em>raw moment</em><span style="font-size:8pt">The kth moment of a random variable x is the average (expected) value of x^k</span></a> of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\mu_{k}^{\prime}\)</span>, is the <a href="#" class="tooltip" style="color:green"><em>expected value</em><span style="font-size:8pt">Average</span></a> of the <em>k</em>-th power of <span class="math inline">\(X\)</span>, provided it exists. The first raw moment <span class="math inline">\(\mu_{1}^{\prime}\)</span> is the mean of <span class="math inline">\(X\)</span> usually denoted by <span class="math inline">\(\mu\)</span>. The formula for <span class="math inline">\(\mu_{k}^{\prime}\)</span> is given as</p>
<p><span class="math display">\[
\mu_{k}^{\prime} = \mathrm{E}\left( X^{k} \right) = \int_{0}^{\infty}{x^{k}f_{X}\left( x \right)dx } .
\]</span>
The support of the random variable <span class="math inline">\(X\)</span> is assumed to be nonnegative since actuarial phenomena are rarely negative. For example, an easy integration by parts shows that the raw moments for nonnegative variables can also be computed using</p>
<p><span class="math display">\[
\mu_{k}^{\prime} = \int_{0}^{\infty}{k~x^{k-1}\left[1- F_{X}(x) \right]dx },
\]</span>
that is based on the survival function, denoted as <span class="math inline">\(S_X(x) = 1-F_{X}(x)\)</span>. This formula is particularly useful when <span class="math inline">\(k=1\)</span>. Section <a href="ChapClaimSeverity.html#S:PolicyLimits">5.1.2</a> discusses this approach in more detail.</p>
<p>The <em>k</em>-th <a href="#" class="tooltip" style="color:green"><em>central moment</em><span style="font-size:8pt">The kth central moment of a random variable x is the expected value of (x-its mean)^k</span></a> of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\mu_{k}\)</span>, is the expected value of the <em>k</em>-th power of the deviation of <span class="math inline">\(X\)</span> from its mean <span class="math inline">\(\mu\)</span>. The formula for <span class="math inline">\(\mu_{k}\)</span> is given as</p>
<p><span class="math display">\[
\mu_{k} = \mathrm{E}\left\lbrack {(X - \mu)}^{k} \right\rbrack = \int_{0}^{\infty}{\left( x - \mu \right)^{k}f_{X}\left( x \right) dx }.
\]</span>
The second central moment <span class="math inline">\(\mu_{2}\)</span> defines the <a href="#" class="tooltip" style="color:green"><em>variance</em><span style="font-size:8pt">Second central moment of a random variable x, measuring the expected squared deviation of between the variable and its mean</span></a> of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\sigma^{2}\)</span>. The square root of the variance is the <a href="#" class="tooltip" style="color:green"><em>standard deviation</em><span style="font-size:8pt">The square-root of variance</span></a> <span class="math inline">\(\sigma\)</span>.</p>
<p>From a classical perspective, further characterization of the shape of the distribution includes its degree of symmetry as well as its flatness compared to the normal distribution. The ratio of the third central moment to the cube of the standard deviation <span class="math inline">\(\left( \mu_{3} / \sigma^{3} \right)\)</span> defines the coefficient of <a href="#" class="tooltip" style="color:green"><em>skewness</em><span style="font-size:8pt">Measure of the symmetry of a distribution, 3rd central moment/standard deviation^3</span></a> which is a measure of symmetry. A positive coefficient of skewness indicates that the distribution is skewed to the right (positively skewed). The ratio of the fourth central moment to the fourth power of the standard deviation <span class="math inline">\(\left(\mu_{4} / \sigma^{4} \right)\)</span> defines the coefficient of <a href="#" class="tooltip" style="color:green"><em>kurtosis</em><span style="font-size:8pt">Measure of the peaked-ness of a distribution, 4th central moment/standard deviation^4</span></a>. The normal distribution has a coefficient of kurtosis of 3. Distributions with a coefficient of kurtosis greater than 3 have heavier tails than the normal, whereas distributions with a coefficient of kurtosis less than 3 have lighter tails and are flatter. Section <a href="ChapPortMgt.html#S:Tails">13.2</a> describes the tails of distributions from an insurance and actuarial perspective.</p>
<p><strong>Example 4.1.1. Actuarial Exam Question.</strong>
Assume that the <a href="#" class="tooltip" style="color:green"><em>rv</em><span style="font-size:8pt">Random variable</span></a> <span class="math inline">\(X\)</span> has a gamma distribution with mean 8 and skewness 1. Find the variance of <span class="math inline">\(X\)</span>. (<em>Hint</em>: The gamma distribution is reviewed in Section <a href="ChapSeverity.html#S:Loss:Gamma">4.2.1</a>.)</p>
<h5 style="text-align: center;">
<a id="displayExample.4.1.1" href="javascript:toggleEX('toggleExample.4.1.1','displayExample.4.1.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.1.1" style="display: none">
<p><strong>Solution.</strong> The <em>pdf</em> of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[
f_{X}\left( x \right) = \frac{\left( x / \theta \right)^{\alpha}}{x ~\Gamma\left( \alpha \right)} e^{- x / \theta}
\]</span>
for <span class="math inline">\(x &gt; 0\)</span>. For <span class="math inline">\(\alpha&gt;0\)</span>, the <em>k</em>-th raw moment is</p>
<p><span class="math display">\[
\mu_{k}^{\prime} = \mathrm{E}\left( X^{k} \right) = \int_{0}^{\infty}{\frac{1}{\Gamma\left( \alpha \right)\theta^{\alpha}}x^{k + \alpha - 1}e^{- x / \theta} dx} = \frac{\Gamma\left( k + \alpha \right)}{\Gamma\left( \alpha \right)}\theta^{k}
\]</span>
Given <span class="math inline">\(\Gamma\left( r + 1 \right) = r\Gamma\left( r \right)\)</span> and <span class="math inline">\(\Gamma\left( 1 \right) = 1\)</span>, then <span class="math inline">\(\mu_{1}^{\prime} = \mathrm{E}\left( X \right) = \alpha\theta\)</span>, <span class="math inline">\(\mu_{2}^{\prime} = \mathrm{E}\left( X^{2} \right) = \left( \alpha + 1 \right)\alpha\theta^{2}\)</span>, <span class="math inline">\(\mu_{3}^{\prime} = \mathrm{E}\left( X^{3} \right) = \left( \alpha + 2 \right)\left( \alpha + 1 \right)\alpha\theta^{3}\)</span>, and
<span class="math inline">\(\mathrm{Var}\left( X \right) = (\alpha + 1)\alpha\theta^2 - (\alpha\theta)^2 = \alpha\theta^{2}\)</span>.</p>
<p><span class="math display">\[
\begin{array}{ll}
\text{Skewness}  &amp;= \frac{\mathrm{E}\left\lbrack {(X - \mu_{1}^{\prime})}^{3} \right\rbrack}{{\left( \mathrm{Var}X \right)}^{3/2}} = \frac{\mu_{3}^{\prime} - 3\mu_{2}^{\prime}\mu_{1}^{\prime} + 2{\mu_{1}^{\prime}}^{3}}{{\left(\mathrm{Var} X \right)}^{3/2}} \\
&amp;= \frac{\left( \alpha + 2 \right)\left( \alpha + 1 \right)\alpha\theta^{3} - 3\left( \alpha + 1 \right)\alpha^{2}\theta^{3} + 2\alpha^{3}\theta^{3}}{\left( \alpha\theta^{2} \right)^{3/2}} \\
&amp;= \frac{2}{\alpha^{1/2}} = 1.
\end{array}
\]</span></p>
<p>Hence, <span class="math inline">\(\alpha = 4\)</span>. Since, <span class="math inline">\(\mathrm{E}\left( X \right) = \alpha\theta = 8\)</span>, then <span class="math inline">\(\theta = 2\)</span> and finally, <span class="math inline">\(\mathrm{Var}\left( X \right) = \alpha\theta^{2} = 16\)</span>.</p>
</div>
<hr />
</div>
<div id="S:LS:Quantiles" class="section level3 hasAnchor" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Quantiles<a href="ChapSeverity.html#S:LS:Quantiles" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Quantiles can also be used to describe the characteristics of the distribution of <span class="math inline">\(X\)</span>. When the distribution of <span class="math inline">\(X\)</span> is continuous, for a given fraction <span class="math inline">\(0 \leq p \leq 1\)</span> the corresponding quantile is the solution of the equation
<span class="math display">\[
F_{X}\left( \pi_{p} \right) = p .
\]</span>
For example, the middle point of the distribution, <span class="math inline">\(\pi_{0.5}\)</span>, is the <a href="#" class="tooltip" style="color:green"><em>median</em><span style="font-size:8pt">50th percentile of a definition, or middle value where half of the distribution lies below</span></a>. A <a href="#" class="tooltip" style="color:green"><em>percentile</em><span style="font-size:8pt">The pth percentile of a random variable x is the smallest value x_p such that the probability of not exceeding it is p%</span></a> is a type of quantile; a <span class="math inline">\(100p\)</span> percentile is the number such that <span class="math inline">\(100 \times p\)</span> percent of the data is below it.</p>
<p><strong>Example 4.1.1. Actuarial Exam Question.</strong>
Let <span class="math inline">\(X\)</span> be a continuous random variable with density function <span class="math inline">\(f_{X}\left( x \right) = \theta e^{- \theta x}\)</span>, for <span class="math inline">\(x &gt; 0\)</span> and 0 elsewhere. If the median of this distribution is <span class="math inline">\(\frac{1}{3}\)</span>, find <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.1.2" href="javascript:toggleEX('toggleExample.4.1.2','displayExample.4.1.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.1.2" style="display: none">
<p><strong>Solution.</strong></p>
<p>The distribution function is <span class="math inline">\(F_{X}\left( x \right) = 1 - e^{- \theta x}\)</span>. So, <span class="math inline">\(F_{X}\left( \pi_{0.5} \right) = 1 - e^{- \theta\pi_{0.5}} = 0.5\)</span>. As, <span class="math inline">\(\pi_{0.5} = \frac{1}{3}\)</span>, we have <span class="math inline">\(F_X\left(\frac{1}{3}\right) = 1 - e^{-\theta / 3} = 0.5\)</span> and <span class="math inline">\(\theta = 3 \log 2\)</span>.</p>
</div>
<hr />
<p>Section <a href="ChapSeverity.html#S:MS:QuantileEstimator">4.1.2.1</a> will extend the definition of quantiles to include distributions that are discrete, continuous, or a hybrid combination.</p>
<div id="S:MS:QuantileEstimator" class="section level4 hasAnchor" number="4.1.2.1">
<h4><span class="header-section-number">4.1.2.1</span> Quartiles, Percentiles and Quantiles<a href="ChapSeverity.html#S:MS:QuantileEstimator" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We have already seen in Section <a href="ChapSeverity.html#S:Chap3Moments">4.1.1</a> the <a href="#" class="tooltip" style="color:green"><em>median</em><span style="font-size:8pt">50th percentile of a definition, or middle value where half of the distribution lies below</span></a>, which is the number such that approximately half of a data set is below (or above) it. The <a href="#" class="tooltip" style="color:green"><em>first quartile</em><span style="font-size:8pt">The 25th percentile; the number such that approximately 25% of the data is below it.</span></a> is the number such that approximately 25% of the data is below it and the <a href="#" class="tooltip" style="color:green"><em>third quartile</em><span style="font-size:8pt">The 75th percentile; the number such that approximately 75% of the data is below it.</span></a> is the number such that approximately 75% of the data is below it. A <span class="math inline">\(100p\)</span> <a href="#" class="tooltip" style="color:green"><em>percentile</em><span style="font-size:8pt">A 100p-th percentile is the number such that 100 times p percent of the data is below it.</span></a> is the number such that <span class="math inline">\(100 \times p\)</span> percent of the data is below it.</p>
<p>To generalize this concept, consider a distribution function <span class="math inline">\(F(\cdot)\)</span>, which may or may not be continuous, and let <span class="math inline">\(q\)</span> be a fraction so that <span class="math inline">\(0&lt;q&lt;1\)</span>. We want to define a <a href="#" class="tooltip" style="color:green"><em>quantile</em><span style="font-size:8pt">The q-th quantile is the point(s) at which the distribution function is equal to q, i.e.the inverse of the cumulative distribution function.</span></a>, say <span class="math inline">\(q_F\)</span>, to be a number such that <span class="math inline">\(F(q_F) \approx q\)</span>. Notice that when <span class="math inline">\(q = 0.5\)</span>, <span class="math inline">\(q_F\)</span> is the median; when <span class="math inline">\(q = 0.25\)</span>, <span class="math inline">\(q_F\)</span> is the first quartile, and so on. In the same way, when <span class="math inline">\(q = 0, 0.01, 0.02, \ldots, 0.99, 1.00\)</span>, the resulting <span class="math inline">\(q_F\)</span> is a percentile. So, a quantile generalizes the concepts of median, quartiles, and percentiles.</p>
<p>To be precise, for a given <span class="math inline">\(0&lt;q&lt;1\)</span>, define the <span class="math inline">\(q\)</span><strong>th quantile</strong> <span class="math inline">\(q_F\)</span> to be <em>any</em> number that satisfies</p>
<p><span class="math display" id="eq:Quantile">\[\begin{equation}
F(q_F-) \le q \le F(q_F)
\tag{4.1}
\end{equation}\]</span></p>
<p>Here, the notation <span class="math inline">\(F(x-)\)</span> means to evaluate the function <span class="math inline">\(F(\cdot)\)</span> as a left-hand limit.</p>
<p>To get a better understanding of this definition, let us look at a few special cases. First, consider the case where <span class="math inline">\(X\)</span> is a continuous random variable so that the distribution function <span class="math inline">\(F(\cdot)\)</span> has no jump points, as illustrated in Figure <a href="ChapSeverity.html#fig:Quantile1">4.1</a>. In this figure, a few fractions, <span class="math inline">\(q_1\)</span>, <span class="math inline">\(q_2\)</span>, and <span class="math inline">\(q_3\)</span> are shown with their corresponding quantiles <span class="math inline">\(q_{F,1}\)</span>, <span class="math inline">\(q_{F,2}\)</span>, and <span class="math inline">\(q_{F,3}\)</span>. In each case, it can be seen that <span class="math inline">\(F(q_F-)= F(q_F)\)</span> so that there is a unique quantile. Because we can find a unique inverse of the distribution function at any <span class="math inline">\(0&lt;q&lt;1\)</span>, we can write <span class="math inline">\(q_F= F^{-1}(q)\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Quantile1"></span>
<img src="LossDataAnalytics_files/figure-html/Quantile1-1.png" alt="Continuous Quantile Case" width="60%" />
<p class="caption">
Figure 4.1: <strong>Continuous Quantile Case</strong>
</p>
</div>
<p>Figure <a href="ChapSeverity.html#fig:Quantile2">4.2</a> shows three cases for distribution functions. The left panel corresponds to the continuous case just discussed. The middle panel displays a jump point similar to those we already saw in the empirical distribution function of Figure <a href="ChapSeverity.html#fig:EDFToy">4.6</a>. For the value of <span class="math inline">\(q\)</span> shown in this panel, we still have a unique value of the quantile <span class="math inline">\(q_F\)</span>. Even though there are many values of <span class="math inline">\(q\)</span> such that <span class="math inline">\(F(q_F-) \le q \le F(q_F)\)</span>, for a particular value of <span class="math inline">\(q\)</span>, there is only one solution to equation <a href="ChapSeverity.html#eq:Quantile">(4.1)</a>. The right panel depicts a situation in which the quantile cannot be uniquely determined for the <span class="math inline">\(q\)</span> shown as there is a range of <span class="math inline">\(q_F\)</span>s satisfying equation <a href="ChapSeverity.html#eq:Quantile">(4.1)</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Quantile2"></span>
<img src="LossDataAnalytics_files/figure-html/Quantile2-1.png" alt="Three Quantile Cases" width="90%" />
<p class="caption">
Figure 4.2: <strong>Three Quantile Cases</strong>
</p>
</div>
<hr />
<p><strong>Example 5.1.2. Toy Data Set: Continued.</strong>
Determine quantiles corresponding to the 20th, 50th, and 95th percentiles.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.2" href="javascript:toggleEX('toggleExample.5.1.2','displayExample.5.1.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.2" style="display: none">
<p><strong>Solution</strong>.
Consider Figure <a href="ChapSeverity.html#fig:EDFToy">4.6</a>. The case of <span class="math inline">\(q=0.20\)</span> corresponds to the middle panel of Figure Figure <a href="ChapSeverity.html#fig:Quantile2">4.2</a>, so the 20th percentile is 15. The case of <span class="math inline">\(q=0.50\)</span> corresponds to the right panel, so the median is any number between 20 and 23 inclusive. Many software packages use the average 21.5 (e.g.<code>R</code>, as seen below). For the 95th percentile, the solution is 30. We can see from Figure <a href="ChapSeverity.html#fig:EDFToy">4.6</a> that 30 also corresponds to the 99th and the 99.99th percentiles.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="ChapSeverity.html#cb35-1" aria-hidden="true" tabindex="-1"></a>xExample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="fu">rep</span>(<span class="dv">15</span>, <span class="dv">3</span>), <span class="dv">20</span>, <span class="fu">rep</span>(<span class="dv">23</span>, <span class="dv">4</span>), <span class="dv">30</span>)</span>
<span id="cb35-2"><a href="ChapSeverity.html#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(xExample, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.5</span>, <span class="fl">0.95</span>), <span class="at">type =</span> <span class="dv">6</span>)</span></code></pre></div>
<pre><code> 20%  50%  95% 
15.0 21.5 30.0 </code></pre>
</div>
<hr />
<p>By taking a weighted average between data observations, smoothed empirical quantiles can handle cases such as the right panel in Figure <a href="ChapSeverity.html#fig:Quantile2">4.2</a>. The <span class="math inline">\(q\)</span>th <a href="#" class="tooltip" style="color:green"><em>smoothed empirical quantile</em><span style="font-size:8pt">A quantile obtained by linear interpolation between two empirical quantiles, i.e.data points.</span></a> is defined as
<span class="math display">\[
\hat{\pi}_q = (1-h) X_{(j)} + h X_{(j+1)}
\]</span>
where <span class="math inline">\(j=\lfloor(n+1)q\rfloor\)</span>, <span class="math inline">\(h=(n+1)q-j\)</span>, and <span class="math inline">\(X_{(1)}, \ldots, X_{(n)}\)</span> are the ordered values (known as the <em>order statistics</em>) corresponding to <span class="math inline">\(X_1, \ldots, X_n\)</span>. (Recall that the brackets <span class="math inline">\(\lfloor \cdot\rfloor\)</span> are the floor function denoting the greatest integer value.) Note that <span class="math inline">\(\hat{\pi}_q\)</span> is simply a linear interpolation between <span class="math inline">\(X_{(j)}\)</span> and <span class="math inline">\(X_{(j+1)}\)</span>.</p>
<p><strong>Example 5.1.3. Toy Data Set: Continued.</strong>
Determine the 50th and 20th smoothed percentiles.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.3" href="javascript:toggleEX('toggleExample.5.1.3','displayExample.5.1.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.3" style="display: none">
<p><strong>Solution</strong>
Take <span class="math inline">\(n=10\)</span> and <span class="math inline">\(q=0.5\)</span>. Then, <span class="math inline">\(j=\lfloor(11)(0.5) \rfloor= \lfloor 5.5 \rfloor=5\)</span> and <span class="math inline">\(h=(11)(0.5)-5=0.5\)</span>. Then the 0.5-th smoothed empirical quantile is
<span class="math display">\[\hat{\pi}_{0.5} = (1-0.5) X_{(5)} + (0.5) X_{(6)} = 0.5 (20) + (0.5)(23) = 21.5.\]</span>
Now take <span class="math inline">\(n=10\)</span> and <span class="math inline">\(q=0.2\)</span>. In this case, <span class="math inline">\(j=\lfloor(11)(0.2)\rfloor=\lfloor 2.2 \rfloor=2\)</span> and <span class="math inline">\(h=(11)(0.2)-2=0.2\)</span>. Then the 0.2-th smoothed empirical quantile is
<span class="math display">\[\hat{\pi}_{0.2} = (1-0.2) X_{(2)} + (0.2) X_{(3)} = 0.8 (15) + (0.2)(15) = 15.\]</span></p>
</div>
<hr />
</div>
</div>
<div id="moment-generating-function" class="section level3 hasAnchor" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Moment Generating Function<a href="ChapSeverity.html#moment-generating-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="#" class="tooltip" style="color:green"><em>moment generating function (mgf)</em><span style="font-size:8pt">The mgf of random variable n is defined the expectation of exp(tn), as a function of t</span></a>, denoted by <span class="math inline">\(M_{X}(t)\)</span> uniquely characterizes the distribution of <span class="math inline">\(X\)</span>. While it is possible for two different distributions to have the same moments and yet still differ, this is not the case with the moment generating function. That is, if two random variables have the same moment generating function, then they have the same distribution. The moment generating function is given by
<span class="math display">\[
M_{X}(t) = \mathrm{E}\left( e^{tX} \right) = \int_{0}^{\infty}{e^{\text{tx}}f_{X}\left( x \right) dx }
\]</span>
for all <span class="math inline">\(t\)</span> for which the expected value exists. The <em>mgf</em> is a real function whose <em>k</em>-th derivative at zero is equal to the <em>k</em>-th raw moment of <span class="math inline">\(X\)</span>. In symbols, this is
<span class="math display">\[
\left.\frac{d^k}{dt^k} M_{X}(t)\right|_{t=0} = \mathrm{E}\left( X^{k} \right) .
\]</span></p>
<p><strong>Example 4.1.3. Actuarial Exam Question.</strong>
The random variable <span class="math inline">\(X\)</span> has an exponential distribution with mean <span class="math inline">\(\frac{1}{b}\)</span>. It is found that <span class="math inline">\(M_{X}\left( - b^{2} \right) = 0.2\)</span>. Find <span class="math inline">\(b\)</span>. (<em>Hint</em>: The exponential is a special case of the gamma distribution which is reviewed in Section <a href="ChapSeverity.html#S:Loss:Gamma">4.2.1</a>.)</p>
<h5 style="text-align: center;">
<a id="displayExample.4.1.3" href="javascript:toggleEX('toggleExample.4.1.3','displayExample.4.1.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.1.3" style="display: none">
<p><strong>Solution.</strong></p>
<p>With <span class="math inline">\(X\)</span> having an exponential distribution with mean <span class="math inline">\(\frac{1}{b}\)</span>, we have that
<span class="math display">\[
M_{X}(t) = \mathrm{E}\left( e^{tX} \right) = \int_{0}^{\infty}{e^{\text{tx}}be^{- bx} dx} = \int_{0}^{\infty}{be^{- x\left( b - t \right)} dx} = \frac{b}{\left( b - t \right)}.
\]</span></p>
<p>Then,
<span class="math display">\[
M_{X}\left( - b^{2} \right) = \frac{b}{\left( b + b^{2} \right)} = \frac{1}{\left( 1 + b \right)} = 0.2.
\]</span>
Thus, <span class="math inline">\(b = 4\)</span>.</p>
</div>
<hr />
<p><strong>Example 4.1.4. Actuarial Exam Question.</strong>
Let <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> be <a href="#" class="tooltip" style="color:green"><em>independent</em><span style="font-size:8pt">Two variables are independent if conditional information given about one variable provides no information regarding the other variable</span></a> random variables, where <span class="math inline">\(X_i\)</span> has a gamma distribution with parameters <span class="math inline">\(\alpha_{i}\)</span> and <span class="math inline">\(\theta\)</span>. Find the distribution of <span class="math inline">\(S = \sum_{i = 1}^{n}X_{i}\)</span>, the mean <span class="math inline">\(\mathrm{E}(S)\)</span>, and the variance <span class="math inline">\(\mathrm{Var}(S)\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.1.4" href="javascript:toggleEX('toggleExample.4.1.4','displayExample.4.1.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.1.4" style="display: none">
<p><strong>Solution.</strong></p>
<p>The <em>mgf</em> of <span class="math inline">\(S\)</span> is
<span class="math display">\[
M_{S}(t) = \text{E}\left( e^{\text{tS}} \right) = \mathrm{E}\left( e^{t\sum_{i = 1}^{n}X_{i}} \right)
= \mathrm{E}\left( \prod_{i = 1}^{n}e^{tX_{i}} \right) .
\]</span>
Using independence, we get<br />
<span class="math display">\[
M_{S}(t) = \prod_{i = 1}^{n}{\mathrm{E}\left( e^{tX_{i}} \right) = \prod_{i = 1}^{n}{M_{X_{i}}(t)}} .
\]</span></p>
<p>The moment generating function of the gamma distribution <span class="math inline">\(X_i\)</span> is <span class="math inline">\(M_{X_i}(t) = (1-\theta t)^{\alpha_i}\)</span>. Then,
<span class="math display">\[
M_{S}(t) = \prod_{i = 1}^{n}\left( 1 - \theta t \right)^{- \alpha_{i}} = \left( 1 - \theta t \right)^{- \sum_{i = 1}^{n}\alpha_{i}} .
\]</span>
This indicates that the distribution of <span class="math inline">\(S\)</span> is gamma with parameters <span class="math inline">\(\sum_{i = 1}^{n}\alpha_{i}\)</span> and <span class="math inline">\(\theta\)</span>.</p>
<p>This is a demonstration of how we can use the uniqueness property of the moment generating function to determine the probability distribution of a function of random variables.</p>
<p>We can find the mean and variance from the properties of the gamma distribution. Alternatively, by finding the first and second derivatives of <span class="math inline">\(M_{S}(t)\)</span> at zero, we can show that <span class="math inline">\(\mathrm{E}\left( S \right) = \left. \ \frac{\partial M_{S}(t)}{\partial t} \right|_{t = 0} = \alpha\theta\)</span> where <span class="math inline">\(\alpha = \sum_{i = 1}^{n}\alpha_{i}\)</span>, and</p>
<p><span class="math display">\[
\mathrm{E}\left( S^{2} \right) = \left. \ \frac{\partial^{2}M_{S}(t)}{\partial t^{2}} \right|_{t = 0} = \left( \alpha + 1 \right)\alpha\theta^{2}.
\]</span>
Hence, <span class="math inline">\(\mathrm{Var}\left( S \right) = \alpha\theta^{2}\)</span>.</p>
</div>
<hr />
<p>One can also use the moment generating function to compute the probability generating function</p>
<p><span class="math display">\[
P_{X}(z) = \mathrm{E}\left( z^{X} \right) = M_{X}\left( \log z \right) .
\]</span></p>
<p>As introduced in Section <a href="ChapFrequency-Modeling.html#S:generating-functions">3.2.2</a>, the probability generating function is more useful for discrete random variables.</p>
<div id="surveyElement31">

</div>
<div id="surveyResult31">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz31.1" href="javascript:toggleQuiz
('display.Quiz31.2','display.Quiz31.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz31.2" style="display: none">
<p id="Quiz31Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz31.js">
</script>
</div>
</div>
<div id="S:ContinuousDistn" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Continuous Distributions for Modeling Loss Severity<a href="ChapSeverity.html#S:ContinuousDistn" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to define and apply four fundamental severity distributions:</p>
<ul>
<li>gamma,</li>
<li>Pareto,</li>
<li>Weibull, and</li>
<li>generalized beta distribution of the second kind.</li>
</ul>
<hr />
<div id="S:Loss:Gamma" class="section level3 hasAnchor" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Gamma Distribution<a href="ChapSeverity.html#S:Loss:Gamma" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that the traditional approach in modeling losses is to fit separate models for frequency and claim severity. When frequency and severity are modeled separately it is common for actuaries to use the Poisson distribution (introduced in Section <a href="ChapFrequency-Modeling.html#S:poisson-distribution">3.2.3.2</a>) for claim count and the gamma distribution to model severity. An alternative approach for modeling losses that has recently gained popularity is to create a single model for pure premium (average claim cost) that will be described in Chapter <a href="ChapModelSelection.html#ChapModelSelection">6</a>.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the gamma distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\theta\)</span> if its probability
density function is given by
<span class="math display">\[
f_{X}\left( x \right) = \frac{\left( x/ \theta  \right)^{\alpha}}{x~ \Gamma\left( \alpha \right)}\exp \left( -x/ \theta \right) \ \ \ \text{for } x &gt; 0 .
\]</span>
Note that <span class="math inline">\(\alpha &gt; 0,\ \theta &gt; 0\)</span>.</p>
<p>The two panels in Figure <a href="ChapSeverity.html#fig:gammapdf">4.3</a> demonstrate the effect of the scale and shape parameters on the gamma density function.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:gammapdf"></span>
<img src="LossDataAnalytics_files/figure-html/gammapdf-1.png" alt="Gamma Densities. The left-hand panel is with shape=2 and varying scale. The right-hand panel is with scale=100 and varying shape." width="120%" />
<p class="caption">
Figure 4.3: <strong>Gamma Densities</strong>. The left-hand panel is with shape=2 and varying scale. The right-hand panel is with scale=100 and varying shape.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.gamma.1" href="javascript:togglecode('toggleCode.gamma.1','displayCode.gamma.1');"><i><strong>R Code for Gamma Density Plots</strong></i></a>
</h5>
<div id="toggleCode.gamma.1" style="display: none">
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="ChapSeverity.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>))</span>
<span id="cb37-2"><a href="ChapSeverity.html#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="ChapSeverity.html#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Varying Scale Gamma Densities</span></span>
<span id="cb37-4"><a href="ChapSeverity.html#cb37-4" aria-hidden="true" tabindex="-1"></a>scaleparam <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">100</span>, <span class="dv">250</span>, <span class="at">by =</span> <span class="dv">50</span>)</span>
<span id="cb37-5"><a href="ChapSeverity.html#cb37-5" aria-hidden="true" tabindex="-1"></a>shapeparam <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">5</span></span>
<span id="cb37-6"><a href="ChapSeverity.html#cb37-6" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1000</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb37-7"><a href="ChapSeverity.html#cb37-7" aria-hidden="true" tabindex="-1"></a>fgamma <span class="ot">&lt;-</span> <span class="fu">dgamma</span>(x, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> scaleparam[<span class="dv">1</span>])</span>
<span id="cb37-8"><a href="ChapSeverity.html#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, fgamma, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Gamma Density&quot;</span>)</span>
<span id="cb37-9"><a href="ChapSeverity.html#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(scaleparam)) {</span>
<span id="cb37-10"><a href="ChapSeverity.html#cb37-10" aria-hidden="true" tabindex="-1"></a>    fgamma <span class="ot">&lt;-</span> <span class="fu">dgamma</span>(x, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> scaleparam[k])</span>
<span id="cb37-11"><a href="ChapSeverity.html#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(x, fgamma, <span class="at">col =</span> k)</span>
<span id="cb37-12"><a href="ChapSeverity.html#cb37-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-13"><a href="ChapSeverity.html#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;scale=100&quot;</span>, <span class="st">&quot;scale=150&quot;</span>, <span class="st">&quot;scale=200&quot;</span>, <span class="st">&quot;scale=250&quot;</span>), <span class="at">lty =</span> <span class="dv">1</span>,</span>
<span id="cb37-14"><a href="ChapSeverity.html#cb37-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb37-15"><a href="ChapSeverity.html#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="ChapSeverity.html#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Varying Shape Gamma Densities</span></span>
<span id="cb37-17"><a href="ChapSeverity.html#cb37-17" aria-hidden="true" tabindex="-1"></a>fgamma <span class="ot">&lt;-</span> <span class="fu">dgamma</span>(x, <span class="at">shape =</span> shapeparam[<span class="dv">1</span>], <span class="at">scale =</span> <span class="dv">100</span>)</span>
<span id="cb37-18"><a href="ChapSeverity.html#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, fgamma, <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Gamma Density&quot;</span>)</span>
<span id="cb37-19"><a href="ChapSeverity.html#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(shapeparam)) {</span>
<span id="cb37-20"><a href="ChapSeverity.html#cb37-20" aria-hidden="true" tabindex="-1"></a>    fgamma <span class="ot">&lt;-</span> <span class="fu">dgamma</span>(x, <span class="at">shape =</span> shapeparam[k], <span class="at">scale =</span> <span class="dv">100</span>)</span>
<span id="cb37-21"><a href="ChapSeverity.html#cb37-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(x, fgamma, <span class="at">col =</span> k)</span>
<span id="cb37-22"><a href="ChapSeverity.html#cb37-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-23"><a href="ChapSeverity.html#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;shape=2&quot;</span>, <span class="st">&quot;shape=3&quot;</span>, <span class="st">&quot;shape=4&quot;</span>, <span class="st">&quot;shape=5&quot;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span></code></pre></div>
</div>
<p>When <span class="math inline">\(\alpha = 1\)</span> the gamma reduces to an <a href="#" class="tooltip" style="color:green"><em>exponential distribution</em><span style="font-size:8pt">A single parameter continous probability distribution that is defined by its rate parameter</span></a> and when <span class="math inline">\(\alpha = \frac{n}{2}\)</span> and <span class="math inline">\(\theta = 2\)</span> the gamma reduces to a <a href="#" class="tooltip" style="color:green"><em>chi-square distribution</em><span style="font-size:8pt">A common distribution used in chi-square tests for determining goodness of fit of observed data to a theorized distribution</span></a> with <span class="math inline">\(n\)</span> degrees of freedom. As we will see in Section <a href="CAppA.html#S:AppA:HT">17.4</a>, the chi-square distribution is used extensively in statistical hypothesis testing.</p>
<p>The distribution function of the gamma model is the <em>incomplete gamma function</em>, denoted by <span class="math inline">\(\Gamma\left(\alpha; \frac{x}{\theta} \right)\)</span>, and defined as
<span class="math display">\[
F_{X}\left( x \right) = \Gamma\left( \alpha; \frac{x}{\theta} \right) = \frac{1}{\Gamma\left( \alpha \right)}\int_{0}^{x /\theta}t^{\alpha - 1}e^{- t}~dt ,
\]</span>
with <span class="math inline">\(\alpha &gt; 0,\ \theta &gt; 0\)</span>. For an integer <span class="math inline">\(\alpha\)</span>, it can be written as <span class="math inline">\(\Gamma\left( \alpha; \frac{x}{\theta} \right) = 1 - e^{-x/\theta}\sum_{k = 0}^{\alpha-1}\frac{(x/\theta)^k}{k!}\)</span>.</p>
<p>The <span class="math inline">\(k\)</span>-th raw moment of the gamma distributed random variable for any positive <span class="math inline">\(k\)</span> is given by
<span class="math display">\[
\mathrm{E}\left( X^{k} \right) = \theta^{k} \frac{\Gamma\left( \alpha + k \right)}{\Gamma\left( \alpha \right)} .
\]</span>
The mean and variance are given by <span class="math inline">\(\mathrm{E}\left( X \right) = \alpha\theta\)</span> and <span class="math inline">\(\mathrm{Var}\left( X \right) = \alpha\theta^{2}\)</span>, respectively.</p>
<p>Since all moments exist for any positive <span class="math inline">\(k\)</span>, the gamma distribution is considered a <a href="#" class="tooltip" style="color:green"><em>light tailed distribution</em><span style="font-size:8pt">A distribution with thinner tails than the benchmark exponential distribution</span></a>, which may not be suitable for
modeling risky assets as it will not provide a realistic assessment of the likelihood of severe losses.</p>
</div>
<div id="pareto-distribution" class="section level3 hasAnchor" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Pareto Distribution<a href="ChapSeverity.html#pareto-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="#" class="tooltip" style="color:green"><em>Pareto distribution</em><span style="font-size:8pt">A heavy-tailed and positively skewed distribution with 2 parameters</span></a>, named after the Italian economist Vilfredo Pareto (1843-1923), has many economic and financial applications. It is a positively skewed and heavy-tailed distribution which makes it suitable for modeling income, high-risk insurance claims and severity of large casualty losses. The survival function of the Pareto distribution which decays slowly to zero was first used to describe the distribution of income where a small percentage of the population holds a large proportion of the total wealth. For extreme insurance claims, the tail of the severity distribution (losses in excess of a threshold) can be modeled using a Generalized Pareto distribution.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the (two parameter) Pareto distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\theta\)</span> if its <a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt">Probability density function</span></a> is given by</p>
<p><span class="math display" id="eq:Pareto">\[\begin{equation}
f_{X}\left( x \right) = \frac{\alpha\theta^{\alpha}}{\left( x + \theta \right)^{\alpha + 1}} \ \ \  x  &gt;  0, \ \alpha &gt;  0, \ \theta &gt; 0.
\tag{4.2}
\end{equation}\]</span></p>
<p>The two panels in Figure <a href="ChapSeverity.html#fig:Paretopdf">4.4</a> demonstrate the effect of the scale and shape parameters on the Pareto density function. There are other formulations of the Pareto distribution including a one parameter version given in Appendix Section <a href="ChapSummaryDistributions.html#S:ContinuousDistributions">20.2</a>. Henceforth, when we refer the Pareto distribution, we mean the version given through the <em>pdf</em> in equation <a href="ChapSeverity.html#eq:Pareto">(4.2)</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Paretopdf"></span>
<img src="LossDataAnalytics_files/figure-html/Paretopdf-1.png" alt="Pareto Densities. The left-hand panel is with scale=2000 and varying shape. The right-hand panel is with shape=3 and varying scale." width="672" />
<p class="caption">
Figure 4.4: <strong>Pareto Densities</strong>. The left-hand panel is with scale=2000 and varying shape. The right-hand panel is with shape=3 and varying scale.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Pareto.1" href="javascript:togglecode('toggleCode.Pareto.1','displayCode.Pareto.1');"><i><strong>R Code for Pareto Density Plots</strong></i></a>
</h5>
<div id="toggleCode.Pareto.1" style="display: none">
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="ChapSeverity.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>))</span>
<span id="cb38-2"><a href="ChapSeverity.html#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="ChapSeverity.html#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Varying Scale Pareto Densities</span></span>
<span id="cb38-4"><a href="ChapSeverity.html#cb38-4" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">3000</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb38-5"><a href="ChapSeverity.html#cb38-5" aria-hidden="true" tabindex="-1"></a>scaleparam <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">2000</span>, <span class="dv">3500</span>, <span class="dv">500</span>)</span>
<span id="cb38-6"><a href="ChapSeverity.html#cb38-6" aria-hidden="true" tabindex="-1"></a>shapeparam <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span></span>
<span id="cb38-7"><a href="ChapSeverity.html#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="ChapSeverity.html#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="co"># varying the shape parameter</span></span>
<span id="cb38-9"><a href="ChapSeverity.html#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, actuar<span class="sc">::</span><span class="fu">dpareto</span>(x, <span class="at">shape =</span> shapeparam[<span class="dv">1</span>], <span class="at">scale =</span> <span class="dv">2000</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.002</span>),</span>
<span id="cb38-10"><a href="ChapSeverity.html#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Pareto density&quot;</span>)</span>
<span id="cb38-11"><a href="ChapSeverity.html#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(shapeparam)) {</span>
<span id="cb38-12"><a href="ChapSeverity.html#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(x, actuar<span class="sc">::</span><span class="fu">dpareto</span>(x, <span class="at">shape =</span> shapeparam[k], <span class="at">scale =</span> <span class="dv">2000</span>), <span class="at">col =</span> k)</span>
<span id="cb38-13"><a href="ChapSeverity.html#cb38-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-14"><a href="ChapSeverity.html#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="fu">expression</span>(alpha <span class="sc">~</span> <span class="st">&quot;=1&quot;</span>), <span class="fu">expression</span>(alpha <span class="sc">~</span> <span class="st">&quot;=2&quot;</span>), <span class="fu">expression</span>(alpha <span class="sc">~</span></span>
<span id="cb38-15"><a href="ChapSeverity.html#cb38-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;=3&quot;</span>), <span class="fu">expression</span>(alpha <span class="sc">~</span> <span class="st">&quot;=4&quot;</span>)), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb38-16"><a href="ChapSeverity.html#cb38-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-17"><a href="ChapSeverity.html#cb38-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Varying Shape Pareto Densities</span></span>
<span id="cb38-18"><a href="ChapSeverity.html#cb38-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, actuar<span class="sc">::</span><span class="fu">dpareto</span>(x, <span class="at">shape =</span> <span class="dv">3</span>, <span class="at">scale =</span> scaleparam[<span class="dv">1</span>]), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Pareto density&quot;</span>)</span>
<span id="cb38-19"><a href="ChapSeverity.html#cb38-19" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(scaleparam)) {</span>
<span id="cb38-20"><a href="ChapSeverity.html#cb38-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(x, actuar<span class="sc">::</span><span class="fu">dpareto</span>(x, <span class="at">shape =</span> <span class="dv">3</span>, <span class="at">scale =</span> scaleparam[k]), <span class="at">col =</span> k)</span>
<span id="cb38-21"><a href="ChapSeverity.html#cb38-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-22"><a href="ChapSeverity.html#cb38-22" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="fu">expression</span>(theta <span class="sc">~</span> <span class="st">&quot;=2000&quot;</span>), <span class="fu">expression</span>(theta <span class="sc">~</span> <span class="st">&quot;=2500&quot;</span>), <span class="fu">expression</span>(theta <span class="sc">~</span></span>
<span id="cb38-23"><a href="ChapSeverity.html#cb38-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;=3000&quot;</span>), <span class="fu">expression</span>(theta <span class="sc">~</span> <span class="st">&quot;=3500&quot;</span>)), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span></code></pre></div>
</div>
<p>The distribution function of the Pareto distribution is given by
<span class="math display">\[
F_{X}\left( x \right) = 1 - \left( \frac{\theta}{x + \theta} \right)^{\alpha}  \ \ \ x &gt; 0,\ \alpha &gt; 0,\ \theta &gt; 0.
\]</span></p>
<p>It can be easily seen that the <a href="#" class="tooltip" style="color:green"><em>hazard function</em><span style="font-size:8pt">Ratio of the probability density function and the survival function: f(x)/s(x), and represents an instantaneous probability within a small time frame</span></a> of the Pareto distribution is a decreasing function in <span class="math inline">\(x\)</span>, another indication that the distribution is heavy tailed. Again using the analogy of the income of a population, when the hazard function decreases over time the population dies off at a decreasing rate resulting in a heavier tail for the distribution. The hazard function reveals information about the tail distribution and is often used to model data distributions in survival analysis. The hazard function is defined as the instantaneous potential that the event of interest occurs within a very narrow time frame.</p>
<p>The <span class="math inline">\(k\)</span>-th raw moment of the Pareto distributed random variable exists, if and only if, <span class="math inline">\(\alpha &gt; k\)</span>. If <span class="math inline">\(k\)</span> is a positive integer then
<span class="math display">\[
\mathrm{E}\left( X^{k} \right) = \frac{\theta^{k}~ k!}{\left( \alpha - 1 \right)\cdots\left( \alpha - k \right)} \ \ \ \alpha &gt; k.
\]</span>
The mean and variance are given by <span class="math display">\[\mathrm{E}\left( X \right) = \frac{\theta}{\alpha - 1} \ \ \ \text{for } \alpha &gt; 1\]</span> and
<span class="math display">\[\mathrm{Var}\left( X \right) = \frac{\alpha\theta^{2}}{\left( \alpha - 1 \right)^{2}\left( \alpha - 2 \right)} \ \ \ \text{for } \alpha &gt; 2,\]</span>respectively.</p>
<p><strong>Example 4.2.1. </strong>
The claim size of an insurance portfolio follows the Pareto distribution with mean and variance of 40 and 1800, respectively. Find</p>
<ol style="list-style-type: lower-alpha">
<li>The shape and scale parameters.</li>
<li>The 95-th percentile of this distribution.</li>
</ol>
<h5 style="text-align: center;">
<a id="displayExample.4.2.1" href="javascript:toggleEX('toggleExample.4.2.1','displayExample.4.2.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.2.1" style="display: none">
<p><strong>Solution.</strong></p>
<p><strong>a.</strong> As, <span class="math inline">\(X\sim Pa(\alpha,\theta)\)</span>, we have <span class="math inline">\(\mathrm{E}\left( X \right) = \frac{\theta}{\alpha - 1} = 40\)</span> and
<span class="math inline">\(\mathrm{Var}\left( X \right) = \frac{\alpha\theta^{2}}{\left( \alpha - 1 \right)^{2}\left( \alpha - 2 \right)} = 1800\)</span>.
By dividing the square of the first equation by the second we get
<span class="math inline">\(\frac{\alpha - 2}{\alpha} = \frac{40^{2}}{1800}\)</span>. Thus, <span class="math inline">\(\alpha = 18.02\)</span> and <span class="math inline">\(\theta = 680.72\)</span>.<br />
<strong>b.</strong> The 95-th percentile, <span class="math inline">\(\pi_{0.95}\)</span>, satisfies the equation
<span class="math display">\[
F_{X}\left( \pi_{0.95} \right) = 1 - \left( \frac{680.72}{\pi_{0.95} + 680.72} \right)^{18.02} = 0.95.
\]</span>
Thus, <span class="math inline">\(\pi_{0.95} = 122.96\)</span>.</p>
</div>
<hr />
</div>
<div id="S:LS:Weibull" class="section level3 hasAnchor" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Weibull Distribution<a href="ChapSeverity.html#S:LS:Weibull" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="#" class="tooltip" style="color:green"><em>Weibull distribution</em><span style="font-size:8pt">A positively skewed continuous distribution with 2 parameters that can have an increasing or decreasing hazard function depending on the shape parameter</span></a>, named after the Swedish physicist Waloddi Weibull (1887-1979) is widely used in reliability, life data analysis, weather forecasts and general insurance claims. Truncated data arise frequently in insurance studies. The Weibull distribution has been used to model excess of loss treaty over automobile insurance as well as earthquake inter-arrival times.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the Weibull distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\theta\)</span> if its <em>pdf</em> is given by
<span class="math display">\[
f_{X}\left( x \right) = \frac{\alpha}{\theta}\left( \frac{x}{\theta} \right)^{\alpha - 1} \exp \left(- \left( \frac{x}{\theta} \right)^{\alpha}\right) \ \ \ x &gt; 0,\ \alpha &gt; 0,\ \theta &gt; 0.
\]</span>
The two panels in Figure <a href="ChapSeverity.html#fig:Weibullpdf">4.5</a> demonstrate the effects of the scale and shape parameters on the Weibull density function.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Weibullpdf"></span>
<img src="LossDataAnalytics_files/figure-html/Weibullpdf-1.png" alt="Weibull Densities. The left-hand panel is with shape=3 and varying scale. The right-hand panel is with scale=100 and varying shape." width="120%" />
<p class="caption">
Figure 4.5: <strong>Weibull Densities</strong>. The left-hand panel is with shape=3 and varying scale. The right-hand panel is with scale=100 and varying shape.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Weibull.1" href="javascript:togglecode('toggleCode.Weibull.1','displayCode.Weibull.1');"><i><strong>R Code for Weibull Density Plots</strong></i></a>
</h5>
<div id="toggleCode.Weibull.1" style="display: none">
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="ChapSeverity.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>))</span>
<span id="cb39-2"><a href="ChapSeverity.html#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="ChapSeverity.html#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Varying Scale Weibull Densities</span></span>
<span id="cb39-4"><a href="ChapSeverity.html#cb39-4" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">400</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb39-5"><a href="ChapSeverity.html#cb39-5" aria-hidden="true" tabindex="-1"></a>scaleparam <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">50</span>, <span class="dv">200</span>, <span class="dv">50</span>)</span>
<span id="cb39-6"><a href="ChapSeverity.html#cb39-6" aria-hidden="true" tabindex="-1"></a>shapeparam <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">1.5</span>, <span class="dv">3</span>, <span class="fl">0.5</span>)</span>
<span id="cb39-7"><a href="ChapSeverity.html#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(z, <span class="fu">dweibull</span>(z, <span class="at">shape =</span> <span class="dv">3</span>, <span class="at">scale =</span> scaleparam[<span class="dv">1</span>]), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weibull density&quot;</span>)</span>
<span id="cb39-8"><a href="ChapSeverity.html#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(scaleparam)) {</span>
<span id="cb39-9"><a href="ChapSeverity.html#cb39-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(z, <span class="fu">dweibull</span>(z, <span class="at">shape =</span> <span class="dv">3</span>, <span class="at">scale =</span> scaleparam[k]), <span class="at">col =</span> k)</span>
<span id="cb39-10"><a href="ChapSeverity.html#cb39-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb39-11"><a href="ChapSeverity.html#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;scale=50&quot;</span>, <span class="st">&quot;scale=100&quot;</span>, <span class="st">&quot;scale=150&quot;</span>, <span class="st">&quot;scale=200&quot;</span>), <span class="at">lty =</span> <span class="dv">1</span>,</span>
<span id="cb39-12"><a href="ChapSeverity.html#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span>
<span id="cb39-13"><a href="ChapSeverity.html#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="ChapSeverity.html#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Varying Shape Weibull Densities</span></span>
<span id="cb39-15"><a href="ChapSeverity.html#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(z, <span class="fu">dweibull</span>(z, <span class="at">shape =</span> shapeparam[<span class="dv">1</span>], <span class="at">scale =</span> <span class="dv">100</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.012</span>), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb39-16"><a href="ChapSeverity.html#cb39-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Weibull density&quot;</span>)</span>
<span id="cb39-17"><a href="ChapSeverity.html#cb39-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span><span class="fu">length</span>(shapeparam)) {</span>
<span id="cb39-18"><a href="ChapSeverity.html#cb39-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(z, <span class="fu">dweibull</span>(z, <span class="at">shape =</span> shapeparam[k], <span class="at">scale =</span> <span class="dv">100</span>), <span class="at">col =</span> k)</span>
<span id="cb39-19"><a href="ChapSeverity.html#cb39-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb39-20"><a href="ChapSeverity.html#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;shape=1.5&quot;</span>, <span class="st">&quot;shape=2&quot;</span>, <span class="st">&quot;shape=2.5&quot;</span>, <span class="st">&quot;shape=3&quot;</span>), <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>)</span></code></pre></div>
</div>
<p>The distribution function of the Weibull distribution is given by
<span class="math display">\[
F_{X}\left( x \right) = 1 - \exp\left(- \left( \frac{x}{\theta} \right)^{\alpha}~\right)  \ \ \ x &gt;  0,\ \alpha &gt;  0,\ \theta &gt; 0.
\]</span></p>
<p>It can be easily seen that the shape parameter <span class="math inline">\(\alpha\)</span> describes the shape of the hazard function of the Weibull distribution. The hazard function is a decreasing function when <span class="math inline">\(\alpha &lt; 1\)</span> (heavy tailed distribution), constant when <span class="math inline">\(\alpha = 1\)</span> and increasing when <span class="math inline">\(\alpha &gt; 1\)</span> (light tailed distribution). This behavior of the hazard function makes the Weibull distribution a suitable model for a wide variety of phenomena such as weather forecasting, electrical and industrial engineering, insurance modeling, and financial risk analysis.</p>
<p>The <span class="math inline">\(k\)</span>-th raw moment of the Weibull distributed random variable is given by
<span class="math display">\[
\mathrm{E}\left( X^{k} \right) = \theta^{k}~\Gamma\left( 1 + \frac{k}{\alpha} \right) .
\]</span></p>
<p>The mean and variance are given by
<span class="math display">\[
\mathrm{E}\left( X \right) = \theta~\Gamma\left( 1 + \frac{1}{\alpha} \right)
\]</span>
and
<span class="math display">\[
\mathrm{Var}(X)= \theta^{2}\left( \Gamma\left( 1 + \frac{2}{\alpha} \right)  - \left\lbrack \Gamma\left( 1 + \frac{1}{\alpha} \right) \right\rbrack  ^{2}\right),
\]</span>
respectively.</p>
<p><strong>Example 4.2.2.</strong>
Suppose that the probability distribution of the lifetime of AIDS patients (in months) from the time of diagnosis is described by the Weibull distribution with shape parameter 1.2 and scale parameter 33.33.</p>
<ol style="list-style-type: lower-alpha">
<li>Find the probability that a randomly selected person from this population survives at least 12 months.</li>
<li>A random sample of 10 patients will be selected from this population. What is the probability that at most two will die within one year of diagnosis.</li>
<li>Find the 99-th percentile of the distribution of lifetimes.</li>
</ol>
<h5 style="text-align: center;">
<a id="displayExample.4.2.2" href="javascript:toggleEX('toggleExample.4.2.2','displayExample.4.2.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.2.2" style="display: none">
<p><strong>Solution.</strong></p>
<p><strong>a.</strong> Let <span class="math inline">\(X\)</span> be the lifetime of AIDS patients (in months) having a Weibull distribution with parameters <span class="math inline">\(\left( 1.2,33.33 \right)\)</span>. We have,</p>
<p><span class="math display">\[
\Pr \left( X \geq 12 \right) = S_{X} \left( 12 \right) = e^{- \left( \frac{12}{33.33} \right)^{1.2}} = 0.746.
\]</span></p>
<p><strong>b.</strong> Let <span class="math inline">\(Y\)</span> be the number of patients who die within one year of diagnosis. Then, <span class="math inline">\(Y\sim Bin\left( 10,\ 0.254 \right)\)</span> and <span class="math inline">\(\Pr\left( Y \leq 2 \right) = 0.514.\)</span></p>
<p><strong>c.</strong> Let <span class="math inline">\(\pi_{0.99}\)</span> denote the 99-th percentile of this distribution. Then,
<span class="math display">\[
S_{X}\left( \pi_{0.99} \right) = \exp\left\{- \left( \frac{\pi_{0.99}}{33.33} \right)^{1.2}\right\} = 0.01.
\]</span>
Solving for <span class="math inline">\(\pi_{0.99}\)</span>, we get <span class="math inline">\(\pi_{0.99} = 118.99\)</span>.</p>
</div>
<hr />
</div>
<div id="the-generalized-beta-distribution-of-the-second-kind" class="section level3 hasAnchor" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> The Generalized Beta Distribution of the Second Kind<a href="ChapSeverity.html#the-generalized-beta-distribution-of-the-second-kind" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="#" class="tooltip" style="color:green"><em>Generalized Beta Distribution of the Second Kind</em><span style="font-size:8pt">A 4-parameter flexible distribution that encompasses many common distributions</span></a> (<em>GB2</em>) was introduced by <span class="citation">G. Venter (<a href="#ref-venter1983transformed" role="doc-biblioref">1983</a>)</span> in the context of insurance loss modeling and by <span class="citation">McDonald (<a href="#ref-mcdonald1984some" role="doc-biblioref">1984</a>)</span> as an income and wealth distribution. It is a four-parameter, very flexible, distribution that can model positively as well as negatively skewed distributions.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the <em>GB2</em> distribution with parameters <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\alpha_2\)</span> if its <em>pdf</em> is given by</p>
<p><span class="math display" id="eq:GB2Distn">\[\begin{equation}
f_{X}\left( x \right) = \frac{(x/\theta)^{\alpha_2/\sigma}}{x \sigma~\mathrm{B}\left( \alpha_1,\alpha_2\right)\left\lbrack 1 + \left( x/\theta \right)^{1/\sigma} \right\rbrack^{\alpha_1 + \alpha_2}} \ \ \ \text{for } x &gt; 0,
\tag{4.3}
\end{equation}\]</span></p>
<p><span class="math inline">\(\sigma,\theta,\alpha_1,\alpha_2 &gt; 0\)</span>, and where the beta function <span class="math inline">\(\mathrm{B}\left( \alpha_1,\alpha_2 \right)\)</span> is defined as</p>
<p><span class="math display">\[
\mathrm{B}\left( \alpha_1,\alpha_2\right) = \int_{0}^{1}{t^{\alpha_1 - 1}\left( 1 - t \right)^{\alpha_2 - 1}}~ dt.
\]</span></p>
<p>The <em>GB2</em> provides a model for heavy as well as light tailed data. It includes the exponential, gamma, Weibull, Burr, Lomax, F, chi-square, Rayleigh, lognormal and log-logistic as special or limiting cases. For example, by setting the parameters <span class="math inline">\(\sigma = \alpha_1 = \alpha_2 = 1\)</span>, the <em>GB2</em> reduces to the log-logistic distribution. When <span class="math inline">\(\sigma = 1\)</span> and <span class="math inline">\(\alpha_2 \rightarrow \infty\)</span>, it reduces to the gamma distribution, and when <span class="math inline">\(\alpha = 1\)</span> and <span class="math inline">\(\alpha_2 \rightarrow \infty\)</span>, it reduces to the Weibull distribution.</p>
<p>A <em>GB2</em> random variable can be constructed as follows. Suppose that <span class="math inline">\(G_1\)</span> and <span class="math inline">\(G_2\)</span> are independent random variables where <span class="math inline">\(G_i\)</span> has a gamma distribution with shape parameter <span class="math inline">\(\alpha_i\)</span> and scale parameter 1. Then, one can show that the random variable <span class="math inline">\(X = \theta \left(\frac{G_1}{G_2}\right)^{\sigma}\)</span> has a <em>GB2</em> distribution with <em>pdf</em> summarized in equation <a href="ChapSeverity.html#eq:GB2Distn">(4.3)</a>. This theoretical result has several implications. For example, when the moments exist, one can show that the <span class="math inline">\(k\)</span>-th raw moment of the <em>GB2</em> distributed random variable is given by</p>
<p><span class="math display">\[
\mathrm{E}\left( X^{k} \right) = \frac{\theta^{k}~\mathrm{B}\left( \alpha_1 +k \sigma,\alpha_2 - k \sigma \right)}{\mathrm{B}\left( \alpha_1,\alpha_2 \right)}, \ \ \ k &gt; 0.
\]</span></p>
<p>As will be described in Section <a href="ChapSeverity.html#S:LossSev:Raising">4.3.3</a>, the <em>GB2</em> is also related to an <span class="math inline">\(F\)</span>-distribution, a result that can be useful in simulation and residual analysis.</p>
<p>Earlier applications of the <em>GB2</em> were on income data and more recently have been used to model long-tailed claims data (Section <a href="ChapPortMgt.html#S:Tails">13.2</a> describes different interpretations of the descriptor long-tail). The <em>GB2</em> has been used to model different types of automobile insurance claims, severity of fire losses, as well as medical insurance claim data.</p>
<div id="surveyElement32">

</div>
<div id="surveyResult32">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz32.1" href="javascript:toggleQuiz
('display.Quiz32.2','display.Quiz32.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz32.2" style="display: none">
<p id="Quiz32Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz32.js">
</script>
</div>
</div>
<div id="MethodsCreation" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Methods of Creating New Distributions<a href="ChapSeverity.html#MethodsCreation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Understand connections among the distributions</li>
<li>Give insights into when a distribution is preferred when compared to alternatives</li>
<li>Provide foundations for creating new distributions</li>
</ul>
<hr />
<div id="functions-of-random-variables-and-their-distributions" class="section level3 hasAnchor" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Functions of Random Variables and their Distributions<a href="ChapSeverity.html#functions-of-random-variables-and-their-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Section <a href="ChapSeverity.html#S:ContinuousDistn">4.2</a> we discussed some elementary known distributions. In this section we discuss means of creating new parametric probability distributions from existing ones. Specifically, let <span class="math inline">\(X\)</span> be a continuous random variable with a known <em>pdf</em> <span class="math inline">\(f_{X}(x)\)</span> and distribution function <span class="math inline">\(F_{X}(x)\)</span>. We are interested in the distribution of <span class="math inline">\(Y = g\left( X \right)\)</span>, where <span class="math inline">\(g(X)\)</span> is a one-to-one <a href="#" class="tooltip" style="color:green"><em>transformation</em><span style="font-size:8pt">A function or method that turns one distribution into another</span></a> defining a new random variable <span class="math inline">\(Y\)</span>. In this section we apply the following techniques for creating new families of distributions: (a) multiplication by a constant (b) raising to a power, (c) exponentiation and (d) mixing.</p>
</div>
<div id="multiplication-by-a-constant" class="section level3 hasAnchor" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Multiplication by a Constant<a href="ChapSeverity.html#multiplication-by-a-constant" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If claim data show change over time then such transformation can be useful to adjust for inflation. If the level of inflation is positive then claim costs are rising, and if it is negative then costs are falling. To adjust for inflation we multiply the cost <span class="math inline">\(X\)</span> by 1+ inflation rate (negative inflation is deflation). To account for currency impact on claim costs we also use a transformation to apply currency conversion from a base to a counter currency.</p>
<p>Consider the transformation <span class="math inline">\(Y = cX\)</span>, where <span class="math inline">\(c &gt; 0\)</span>, then the distribution function of <span class="math inline">\(Y\)</span> is given by
<span class="math display">\[
F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( cX \leq y \right) = \Pr\left( X \leq \frac{y}{c} \right) = F_{X}\left( \frac{y}{c} \right).
\]</span>
Using the chain rule for differentiation, the <em>pdf</em> of interest <span class="math inline">\(f_{Y}(y)\)</span> can be written as
<span class="math display">\[
f_{Y}\left( y \right) = \frac{1}{c}f_{X}\left( \frac{y}{c} \right).
\]</span>
Suppose that <span class="math inline">\(X\)</span> belongs to a certain set of <a href="#" class="tooltip" style="color:green"><em>parametric distributions</em><span style="font-size:8pt">Probability distribution defined by a fixed set of parameters</span></a> and define a rescaled version <span class="math inline">\(Y\  = \ cX\)</span>, <span class="math inline">\(c\  &gt; \ 0\)</span>. If <span class="math inline">\(Y\)</span> is in the same set of distributions then the distribution is said to be a <a href="#" class="tooltip" style="color:green"><em>scale distribution</em><span style="font-size:8pt">A distribution with the property that multiplying all values by a constant leads to the same distribution family with only the scale parameter changed</span></a>. When a member of a scale distribution is multiplied by a constant <span class="math inline">\(c\)</span> (<span class="math inline">\(c &gt; 0\)</span>), the scale parameter for this scale distribution meets two conditions:</p>
<ul>
<li>The parameter is changed by multiplying by <span class="math inline">\(c\)</span>;</li>
<li>All other parameters remain unchanged.</li>
</ul>
<p><strong>Example 4.3.1. Actuarial Exam Question.</strong>
Losses of Eiffel Auto Insurance are denoted in Euro currency and follow a lognormal distribution with <span class="math inline">\(\mu = 8\)</span> and <span class="math inline">\(\sigma = 2\)</span>. Given that 1 euro <span class="math inline">\(=\)</span> 1.3 dollars, find the set of lognormal parameters which describe the distribution of Eiffels losses in dollars.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.1" href="javascript:toggleEX('toggleExample.4.3.1','displayExample.4.3.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.1" style="display: none">
<p><strong>Solution.</strong></p>
<p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> denote the aggregate losses of Eiffel Auto Insurance in euro currency and dollars respectively. As <span class="math inline">\(Y = 1.3X\)</span>, we have,
<span class="math display">\[
F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( 1.3X \leq y \right) = \Pr\left( X \leq \frac{y}{1.3} \right) = F_{X}\left( \frac{y}{1.3} \right).
\]</span></p>
<p><span class="math inline">\(X\)</span> follows a lognormal distribution with parameters <span class="math inline">\(\mu = 8\)</span> and <span class="math inline">\(\sigma = 2\)</span>. The <em>pdf</em> of <span class="math inline">\(X\)</span> is given by
<span class="math display">\[
f_{X}\left( x \right) = \frac{1}{x \sigma \sqrt{2\pi}}\exp \left\{- \frac{1}{2}\left( \frac{\log x - \mu}{\sigma} \right)^{2}\right\} \ \ \ \text{for } x &gt; 0.
\]</span>
As <span class="math inline">\(\left| \frac{dx}{dy} \right| = \frac{1}{1.3}\)</span>, the <em>pdf</em> of interest <span class="math inline">\(f_{Y}(y)\)</span> is</p>
<p><span class="math display">\[
\begin{array}{ll}
f_{Y}\left( y \right) &amp; = \frac{1}{1.3}f_{X}\left( \frac{y}{1.3} \right) \\
&amp;= \frac{1}{1.3}\frac{1.3}{y \sigma \sqrt{2\pi}}\exp \left\{- \frac{1}{2}\left( \frac{\log\left( y/1.3 \right) - \mu}{\sigma} \right)^{2}\right\} \\
&amp;= \frac{1}{y \sigma\sqrt{2\pi}}\exp \left\{- \frac{1}{2}\left( \frac{\log y - \left( \log 1.3 + \mu \right)}{\sigma} \right)^{2}\right\}.
\end{array}
\]</span>
Then <span class="math inline">\(Y\)</span> follows a lognormal distribution with parameters <span class="math inline">\(\log 1.3 + \mu = 8.26\)</span> and <span class="math inline">\(\sigma = 2.00\)</span>. If we let <span class="math inline">\(\mu = \log(m)\)</span> then it can be easily seen that <span class="math inline">\(m = e^{\mu}\)</span> is the scale parameter which was multiplied by 1.3 while <span class="math inline">\(\sigma\)</span> is the shape parameter that remained unchanged.</p>
</div>
<hr />
<p><strong>Example 4.3.2. Actuarial Exam Question.</strong>
Demonstrate that the gamma distribution is a scale distribution.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.2" href="javascript:toggleEX('toggleExample.4.3.2','displayExample.4.3.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.2" style="display: none">
<p><strong>Solution.</strong></p>
<p>Let <span class="math inline">\(X\sim Ga(\alpha,\theta)\)</span> and <span class="math inline">\(Y = cX\)</span>. As <span class="math inline">\(\left| \frac{dx}{dy} \right| = \frac{1}{c}\)</span>, then</p>
<p><span class="math display">\[
f_{Y}\left( y \right) = \frac{1}{c}f_{X}\left( \frac{y}{c} \right) = \frac{\left( \frac{y}{c\theta} \right)^{\alpha}}{y~\Gamma\left( \alpha \right)}\exp \left( - \frac{y}{c\theta} \right)  .
\]</span>
We can see that <span class="math inline">\(Y\sim Ga(\alpha,c\theta)\)</span> indicating that gamma is a scale distribution and <span class="math inline">\(\theta\)</span> is a scale parameter.</p>
<p>Using the same approach you can demonstrate that other distributions introduced in Section <a href="ChapSeverity.html#S:ContinuousDistn">4.2</a> are also scale distributions. In actuarial modeling, working with a scale distribution is very convenient because it allows to incorporate the effect of inflation and to accommodate changes in the currency unit.</p>
</div>
<hr />
</div>
<div id="S:LossSev:Raising" class="section level3 hasAnchor" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> Raising to a Power<a href="ChapSeverity.html#S:LossSev:Raising" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Section <a href="ChapSeverity.html#S:LS:Weibull">4.2.3</a> we talked about the flexibility of the Weibull distribution in fitting <a href="#" class="tooltip" style="color:green"><em>reliability data</em><span style="font-size:8pt">A dataset consisting of failure times for failed units and run times for units still functioning</span></a>. Looking to the origins of the Weibull distribution, we recognize that the Weibull is a <a href="#" class="tooltip" style="color:green"><em>power transformation</em><span style="font-size:8pt">A transformation type that involves raising a random variable to a power</span></a> of the exponential distribution. This is an application of another type of transformation which involves raising the random variable to a power.</p>
<p>Consider the transformation <span class="math inline">\(Y = X^{\tau}\)</span>, where <span class="math inline">\(\tau &gt; 0\)</span>, then the distribution function of <span class="math inline">\(Y\)</span> is given by</p>
<p><span class="math display">\[
F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( X^{\tau} \leq y \right) = \Pr\left( X \leq y^{1/ \tau} \right) = F_{X}\left( y^{1/ \tau} \right).
\]</span></p>
<p>Hence, the <em>pdf</em> of interest <span class="math inline">\(f_{Y}(y)\)</span> can be written as
<span class="math display">\[
f_{Y}(y) = \frac{1}{\tau} y^{(1/ \tau) - 1} f_{X}\left( y^{1/ \tau} \right).
\]</span>
On the other hand, if <span class="math inline">\(\tau &lt; 0\)</span>, then the distribution function of <span class="math inline">\(Y\)</span> is given by
<span class="math display">\[
F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( X^{\tau} \leq y \right) = \Pr\left( X \geq y^{1/ \tau} \right) = 1 - F_{X}\left( y^{1/ \tau} \right),
\]</span>
and</p>
<p><span class="math display">\[
f_{Y}(y) = \left| \frac{1}{\tau} \right|{y^{(1/ \tau) - 1}f}_{X}\left( y^{1/ \tau} \right).
\]</span></p>
<p><strong>Example 4.3.3.</strong>
We assume that <span class="math inline">\(X\)</span> follows the exponential distribution with mean <span class="math inline">\(\theta\)</span> and consider the transformed variable <span class="math inline">\(Y = X^{\tau}\)</span>. Show that <span class="math inline">\(Y\)</span> follows the Weibull distribution when <span class="math inline">\(\tau\)</span> is positive and determine the parameters of the Weibull distribution.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.3" href="javascript:toggleEX('toggleExample.4.3.3','displayExample.4.3.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.3" style="display: none">
<p><strong>Solution.</strong></p>
<p>As <span class="math inline">\(X\)</span> follows the exponential distribution with mean <span class="math inline">\(\theta\)</span>, we have
<span class="math display">\[
f_{X}(x) = \frac{1}{\theta}e^{- x/ \theta} \ \ \ \, x &gt; 0.
\]</span>
Solving for <em>x</em> yields <span class="math inline">\(x = y^{1/\tau}\)</span>. Taking the derivative, we have</p>
<p><span class="math display">\[
\left| \frac{dx}{dy} \right| = \frac{1}{\tau}{y^{\frac{1}{\tau}-1}}.
\]</span>
Thus,</p>
<p><span class="math display">\[
f_{Y}\left( y \right) = \frac{1}{\tau}{y^{\frac{1}{\tau} - 1}f}_{X}\left( y^{\frac{1}{\tau}} \right) \\
= \frac{1}{\tau \theta }y^{\frac{1}{\tau} - 1}e^{- \frac{y^{\frac{1}{\tau}}}{\theta}} = \frac{\alpha}{\beta}\left( \frac{y}{\beta} \right)^{\alpha - 1}e^{- \left( y/ \beta \right)^{\alpha}}.
\]</span>
where <span class="math inline">\(\alpha = \frac{1}{\tau}\)</span> and <span class="math inline">\(\beta = \theta^{\tau}\)</span>. Then, <span class="math inline">\(Y\)</span> follows the Weibull distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\beta\)</span>.</p>
</div>
<hr />
<p><strong>Special Case. Relating a <em>GB2</em> to an <span class="math inline">\(F\)</span>- Distribution.</strong> We can use tranforms such as multiplication by a constant and raising to a power to verify that the <em>GB2</em> distribution is related to an <span class="math inline">\(F\)</span>-distribution, a distribution widely used in applied statistics.</p>
<h5 style="text-align: center;">
<a id="displayTheory.GB.1" href="javascript:toggleTheory('toggleTheory.GB.1','displayCode.GB.1');"><i><strong>Relating a GB2 to an F- Distribution</strong></i></a>
</h5>
<div id="toggleTheory.GB.1" style="display: none">
<hr />
<p>To see this relationship, we first note that <span class="math inline">\(\frac{1}{2} G_1\)</span> has a gamma distribution with shape parameter <span class="math inline">\(\alpha_1\)</span> and scale parameter <span class="math inline">\(0.5\)</span>. Readers with some background in applied statistics may also recognize this to be a <em>chi-square</em> distribution with degrees of freedom <span class="math inline">\(2\alpha_1\)</span>. The ratio of independent chi-squares has an <span class="math inline">\(F\)</span>-distribution. That is</p>
<p><span class="math display">\[
\frac{G_1}{G_2} = \frac{0.5G_1}{0.5G_2}  = F
\]</span></p>
<p>has an <span class="math inline">\(F\)</span>-distribution with numerator degrees of freedom <span class="math inline">\(2\alpha_1\)</span> and denominator degrees of freedom <span class="math inline">\(2\alpha_2\)</span>. Thus, a random variable <span class="math inline">\(X\)</span> with a <em>GB2</em> distribution can be expressed as <span class="math inline">\(X = \theta \left(\frac{G_1}{G_2}\right)^{\sigma}= \theta ~ F^{\sigma}\)</span>. With this, you can think of a <em>GB2</em> as a power <span class="math inline">\(F\)</span> or a generalized <span class="math inline">\(F\)</span>, as it is sometimes known in the literature.</p>
<p>Simulation, discussed in Chapter <a href="ChapSimulation.html#ChapSimulation">8</a>, provides a direct application of this result. Suppose we know how to simulate an outcome with an <span class="math inline">\(F-distribution\)</span> (that is easy to do using, for example, the <code>R</code> function <code>rf(n,df1,df2)</code>), say <span class="math inline">\(F\)</span>. Then we raise it to the power <span class="math inline">\(\sigma\)</span> and multiply it by <span class="math inline">\(\theta\)</span> so that <span class="math inline">\(\theta ~ F^{\sigma}\)</span> is an outcome that has a <em>GB2</em> distribution.</p>
<p>Residual analysis provides another direct application. Suppose we have an outcome, say <span class="math inline">\(X\)</span>, that we think comes from a <em>GB2</em> distribution. Then we can examine the transformed version <span class="math inline">\(X^{\ast} = \left(X/\theta\right)^{1/\sigma}\)</span>. If the original specification is correct, then <span class="math inline">\(X^{\ast}\)</span> has an <span class="math inline">\(F-\)</span> distribution and there are many well-known techniques, some described in Chapter <a href="ChapModelSelection.html#ChapModelSelection">6</a>, for verifying this assertion.</p>
<hr />
</div>
</div>
<div id="exponentiation" class="section level3 hasAnchor" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> Exponentiation<a href="ChapSeverity.html#exponentiation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The normal distribution is a very popular model for a wide number of applications and when the sample size is large, it can serve as an approximate distribution for other models. If the random variable <span class="math inline">\(X\)</span> has a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>, then <span class="math inline">\(Y = e^{X}\)</span> has a <a href="#" class="tooltip" style="color:green"><em>lognormal distribution</em><span style="font-size:8pt">A heavy-tailed, positively skewed 2-parameter continuous distribution such that the natural log of the random variable is normally distributed with the same parameter values</span></a> with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^{2}\)</span>. The lognormal random variable has a lower bound of zero, is positively skewed and has a long right tail. A lognormal distribution is commonly used to describe distributions of financial assets such as stock prices. It is also used in fitting claim amounts for automobile as well as health insurance. This is an example of another type of transformation which involves exponentiation.</p>
<p>In general, consider the transformation <span class="math inline">\(Y = e^{X}\)</span>. Then, the distribution function of <span class="math inline">\(Y\)</span> is given by</p>
<p><span class="math display">\[
F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( e^{X} \leq y \right) = \Pr\left( X \leq \log y \right) = F_{X}\left( \log y \right).
\]</span>
Taking derivatives, we see that the <em>pdf</em> of interest <span class="math inline">\(f_{Y}(y)\)</span> can be written as
<span class="math display">\[
f_{Y}(y) = \frac{1}{y}f_{X}\left( \log y \right).
\]</span>
As an important special case, suppose that <span class="math inline">\(X\)</span> is normally distributed with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Then, the distribution of <span class="math inline">\(Y = e^X\)</span> is</p>
<p><span class="math display">\[
f_{Y}(y) = \frac{1}{y}f_{X}\left( \log y \right)
= \frac{1}{y \sigma \sqrt{2 \pi}} \exp \left\{-\frac{1}{2}\left(\frac{ \log y - \mu}{\sigma}\right)^2\right\}.
\]</span>
This is known as a <em>lognormal</em> distribution.</p>
<p><strong>Example 4.3.4. Actuarial Exam Question.</strong>
Assume that <span class="math inline">\(X\)</span> has a uniform distribution on the interval <span class="math inline">\((0,\ c)\)</span> and define <span class="math inline">\(Y = e^{X}\)</span>. Find the distribution of <span class="math inline">\(Y\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.4" href="javascript:toggleEX('toggleExample.4.3.4','displayExample.4.3.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.4" style="display: none">
<p><strong>Solution.</strong></p>
<p>We begin with the <a href="#" class="tooltip" style="color:green"><em>cdf</em><span style="font-size:8pt">Cumulative distribution function</span></a> of <span class="math inline">\(Y\)</span>,
<span class="math display">\[
F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( e^{X} \leq y \right) = \Pr\left( X \leq \log y \right) = F_{X}\left( \log y \right).
\]</span>
Taking the derivative, we have,</p>
<p><span class="math display">\[
f_{Y}\left( y \right) = \frac{1}{y}f_{X}\left(\log y \right) = \frac{1}{cy} .
\]</span>
Since <span class="math inline">\(0 &lt; x &lt; c\)</span>, then <span class="math inline">\(1 &lt; y &lt; e^{c}\)</span>.</p>
</div>
<hr />
</div>
<div id="finite-mixtures" class="section level3 hasAnchor" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> Finite Mixtures<a href="ChapSeverity.html#finite-mixtures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Mixture distributions represent a useful way of modeling data that are drawn from a <a href="#" class="tooltip" style="color:green"><em>heterogeneous population</em><span style="font-size:8pt">A dataset where the subpopulations are represented by separate distinct distributions</span></a>. This parent population can be
thought to be divided into multiple subpopulations with distinct distributions.</p>
<div id="two-point-mixture" class="section level4 hasAnchor" number="4.3.5.1">
<h4><span class="header-section-number">4.3.5.1</span> Two-point Mixture<a href="ChapSeverity.html#two-point-mixture" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If the underlying phenomenon is diverse and can actually be described as two phenomena representing two subpopulations with different modes, we can construct the two-point mixture random variable <span class="math inline">\(X\)</span>. Given random variables <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>, with <em>pdf</em>s <span class="math inline">\(f_{X_{1}}\left( x \right)\)</span> and <span class="math inline">\(f_{X_{2}}\left( x \right)\)</span> respectively, the <em>pdf</em> of <span class="math inline">\(X\)</span> is the weighted average of the component <em>pdf</em> <span class="math inline">\(f_{X_{1}}\left( x \right)\)</span> and <span class="math inline">\(f_{X_{2}}\left( x \right)\)</span>. The <em>pdf</em> and distribution function of <span class="math inline">\(X\)</span> are given by
<span class="math display">\[f_{X}\left( x \right) = af_{X_{1}}\left( x \right) + \left( 1 - a \right)f_{X_{2}}\left( x \right),\]</span>
and
<span class="math display">\[F_{X}\left( x \right) = aF_{X_{1}}\left( x \right) + \left( 1 - a \right)F_{X_{2}}\left( x \right),\]</span></p>
<p>for <span class="math inline">\(0 &lt; a &lt;1\)</span>, where the <a href="#" class="tooltip" style="color:green"><em>mixing parameters</em><span style="font-size:8pt">Proportion weight given to each subpopulation in a mixture</span></a> <span class="math inline">\(a\)</span> and <span class="math inline">\((1 - a)\)</span> represent the proportions of data points that fall under each of the two subpopulations respectively. This weighted average can be applied to a number of other distribution related quantities. The <em>k</em>-th raw moment and moment generating function of <span class="math inline">\(X\)</span> are given by
<span class="math inline">\(\mathrm{E}\left( X^{k} \right) = a\mathrm{E}\left( X_{1}^{K} \right) + \left( 1 - a \right)\mathrm{E}\left( X_{2}^{k} \right)\)</span>,
and
<span class="math display">\[M_{X}(t) = aM_{X_{1}}(t) + \left( 1 - a \right)M_{X_{2}}(t),\]</span> respectively.</p>
<p><strong>Example 4.3.5. Actuarial Exam Question.</strong>
A collection of insurance policies consists of two types. 25% of policies are Type 1 and 75% of policies are Type 2. For a policy of Type 1, the loss amount per year follows an exponential distribution with mean 200, and for a policy of Type 2, the loss amount per year follows a Pareto distribution with parameters <span class="math inline">\(\alpha=3\)</span> and <span class="math inline">\(\theta=200\)</span>. For a policy chosen at random from the entire collection of both types of policies, find the probability that the annual loss will be less than 100, and find the average loss.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.5" href="javascript:toggleEX('toggleExample.4.3.5','displayExample.4.3.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.5" style="display: none">
<p><strong>Solution.</strong></p>
<p>The two types of losses are the random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. <span class="math inline">\(X_1\)</span> has an exponential distribution with mean 100, so <span class="math inline">\(F_{X_1}\left(100\right)=1-e^{-\frac{100}{200}}=0.393\)</span>. <span class="math inline">\(X_2\)</span> has a Pareto distribution with parameters <span class="math inline">\(\alpha=3\)</span> and <span class="math inline">\(\theta=200\)</span>, so <span class="math inline">\(F_{X_1}\left(100\right)=1-\left(\frac{200}{100+200}\right)^3=0.704\)</span>. Hence, <span class="math inline">\(F_X\left(100\right)=\left(0.25\times0.393\right)+\left(0.75\times0.704\right)=0.626\)</span>.</p>
<p>The average loss is given by
<span class="math display">\[\mathrm{E}\left(X\right)=0.25\mathrm{E}\left(X_1\right)+0.75\mathrm{E}\left(X_2\right)=\left(0.25\times200\right)+\left(0.75\times100\right)=125\]</span>.</p>
</div>
<hr />
</div>
<div id="k-point-mixture" class="section level4 hasAnchor" number="4.3.5.2">
<h4><span class="header-section-number">4.3.5.2</span> <em>k</em>-point Mixture<a href="ChapSeverity.html#k-point-mixture" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In case of finite mixture distributions, the random variable of interest <span class="math inline">\(X\)</span> has a probability <span class="math inline">\(p_{i}\)</span> of being drawn from homogeneous subpopulation <span class="math inline">\(i\)</span>, where <span class="math inline">\(i = 1,2,\ldots,k\)</span> and <span class="math inline">\(k\)</span> is the initially specified number of subpopulations in our mixture. The mixing parameter <span class="math inline">\(p_{i}\)</span> represents the proportion of observations from subpopulation <span class="math inline">\(i\)</span>. Consider the random variable <span class="math inline">\(X\)</span> generated from <span class="math inline">\(k\)</span> distinct subpopulations, where subpopulation <span class="math inline">\(i\)</span> is modeled by the continuous distribution <span class="math inline">\(f_{X_{i}}\left( x \right)\)</span>. The probability distribution of <span class="math inline">\(X\)</span> is given by
<span class="math display">\[f_{X}\left( x \right) = \sum_{i = 1}^{k}{p_{i}f_{X_{i}}\left( x \right)},\]</span>
where <span class="math inline">\(0 &lt; p_{i} &lt; 1\)</span> and <span class="math inline">\(\sum_{i = 1}^{k} p_{i} = 1\)</span>.</p>
<p>This model is often referred to as a <a href="#" class="tooltip" style="color:green"><em>finite mixture</em><span style="font-size:8pt">A mixture distribution with a finite k number of subpopulations</span></a> or a <span class="math inline">\(k\)</span>-point mixture. The distribution function, <span class="math inline">\(r\)</span>-th raw moment and moment generating functions of the <span class="math inline">\(k\)</span>-th point mixture are given as</p>
<p><span class="math display">\[F_{X}\left( x \right) = \sum_{i = 1}^{k}{p_{i}F_{X_{i}}\left( x \right)},\]</span>
<span class="math display">\[\mathrm{E}\left( X^{r} \right) = \sum_{i = 1}^{k}{p_{i}\mathrm{E}\left( X_{i}^{r} \right)}, \ \ \ \text{and}\]</span>
<span class="math display">\[M_{X}(t) = \sum_{i = 1}^{k}{p_{i}M_{X_{i}}(t)},\]</span> respectively.</p>
<p><strong>Example 4.3.6. Actuarial Exam Question.</strong>
<span class="math inline">\(Y_{1}\)</span> is a mixture of <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> with mixing weights <span class="math inline">\(a\)</span> and <span class="math inline">\((1 - a)\)</span>. <span class="math inline">\(Y_{2}\)</span> is a mixture of <span class="math inline">\(X_{3}\)</span> and <span class="math inline">\(X_{4}\)</span> with mixing weights <span class="math inline">\(b\)</span> and <span class="math inline">\((1 - b)\)</span>. <span class="math inline">\(Z\)</span> is a mixture of <span class="math inline">\(Y_{1}\)</span> and <span class="math inline">\(Y_{2}\)</span> with mixing weights <span class="math inline">\(c\)</span> and <span class="math inline">\((1 - c)\)</span>.</p>
<p>Show that <span class="math inline">\(Z\)</span> is a mixture of <span class="math inline">\(X_{1}\)</span>, <span class="math inline">\(X_{2}\)</span>, <span class="math inline">\(X_{3}\)</span> and <span class="math inline">\(X_{4}\)</span>, and find the mixing weights.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.6" href="javascript:toggleEX('toggleExample.4.3.6','displayExample.4.3.6');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.6" style="display: none">
<p><strong>Solution.</strong>
Applying the formula for a mixed distribution, we get
<span class="math display">\[f_{Y_{1}}\left( x \right) = af_{X_{1}}\left( x \right) + \left( 1 - a \right)f_{X_{2}}\left( x \right)\]</span></p>
<p><span class="math display">\[f_{Y_{2}}\left( x \right) = bf_{X_{3}}\left( x \right) + \left( 1 - b \right)f_{X_{4}}\left( x \right)\]</span></p>
<p><span class="math display">\[f_{Z}\left( x \right) = cf_{Y_{1}}\left( x \right) + \left( 1 - c \right)f_{Y_{2}}\left( x \right)\]</span></p>
<p>Substituting the first two equations into the third, we get</p>
<p><span class="math display">\[f_{Z}\left( x \right) = c\left\lbrack af_{X_{1}}\left( x \right) + \left( 1 - a \right)f_{X_{2}}\left( x \right) \right\rbrack + \left( 1 - c \right)\left\lbrack bf_{X_{3}}\left( x \right) + \left( 1 - b \right)f_{X_{4}}\left( x \right) \right\rbrack\]</span></p>
<p><span class="math display">\[= caf_{X_{1}}\left( x \right) + c\left( 1 - a \right)f_{X_{2}}\left( x \right) + \left( 1 - c \right)bf_{X_{3}}\left( x \right) + (1 - c)\left( 1 - b \right)f_{X_{4}}\left( x \right)\]</span>.</p>
<p>Then, <span class="math inline">\(Z\)</span> is a mixture of <span class="math inline">\(X_{1}\)</span>, <span class="math inline">\(X_{2}\)</span>, <span class="math inline">\(X_{3}\)</span> and <span class="math inline">\(X_{4}\)</span>, with mixing weights <span class="math inline">\(\text{ca}\)</span>, <span class="math inline">\(c\left( 1 - a \right)\)</span>, <span class="math inline">\(\left( 1 - c \right)b\)</span> and <span class="math inline">\((1 - c)\left( 1 - b \right)\)</span>, respectively. It can be easily seen that the mixing weights sum to one.</p>
</div>
<hr />
</div>
</div>
<div id="continuous-mixtures" class="section level3 hasAnchor" number="4.3.6">
<h3><span class="header-section-number">4.3.6</span> Continuous Mixtures<a href="ChapSeverity.html#continuous-mixtures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A mixture with a very large number of subpopulations (<span class="math inline">\(k\)</span> goes to infinity) is often referred to as a <a href="#" class="tooltip" style="color:green"><em>continuous mixture</em><span style="font-size:8pt">A mixture distribution with an infinite number of subpopulations, where the mixing parameter is itself a continuous distribution</span></a>. In a continuous mixture, subpopulations are not distinguished by a discrete mixing parameter but by a continuous variable <span class="math inline">\(\Theta\)</span>, where <span class="math inline">\(\Theta\)</span> plays the role of <span class="math inline">\(p_{i}\)</span> in the finite mixture. Consider the random variable <span class="math inline">\(X\)</span> with a distribution depending on a parameter <span class="math inline">\(\Theta\)</span>, where <span class="math inline">\(\Theta\)</span> itself is a continuous random variable. This description yields the following model for <span class="math inline">\(X\)</span>
<span class="math display">\[
f_{X}\left( x \right) = \int_{-\infty}^{\infty}{f_{X}\left(x \left| \theta \right.  \right)g_{\Theta}( \theta )} d \theta ,
\]</span>
where <span class="math inline">\(f_{X}\left( x | \theta \right)\)</span> is the <a href="#" class="tooltip" style="color:green"><em>conditional distribution</em><span style="font-size:8pt">A probability distribution that applies to a subpopulation satisfying the condition</span></a> of <span class="math inline">\(X\)</span> at a particular value of <span class="math inline">\(\Theta=\theta\)</span> and <span class="math inline">\(g_{\Theta}\left( \theta \right)\)</span> is the probability statement made about the unknown parameter <span class="math inline">\(\theta\)</span>. In a Bayesian context (described in Section <a href="#S:MS:BayesInference"><strong>??</strong></a>), this is known as the <a href="#" class="tooltip" style="color:green"><em>prior distribution</em><span style="font-size:8pt">A probability distribution assigned prior to observing additional data</span></a> of <span class="math inline">\(\Theta\)</span> (the prior information or expert opinion to be used in the analysis).</p>
<p>The distribution function, <span class="math inline">\(k\)</span>-th raw moment and moment generating functions of the continuous mixture are given as</p>
<p><span class="math display">\[
F_{X}\left( x \right) = \int_{-\infty}^{\infty}{F_{X}\left(x \left| \theta \right.  \right) g_{\Theta}(\theta)} d \theta,
\]</span>
<span class="math display">\[
\mathrm{E}\left( X^{k} \right) = \int_{-\infty}^{\infty}{\mathrm{E}\left( X^{k}\left| \theta \right.  \right)g_{\Theta}(\theta)}d \theta,
\]</span>
<span class="math display">\[
M_{X}(t) = \mathrm{E}\left( e^{t X} \right) = \int_{-\infty}^{\infty}{\mathrm{E}\left( e^{ tx}\left| \theta \right.  \right)g_{\Theta}(\theta)}d \theta,
\]</span>
respectively.</p>
<p>The <span class="math inline">\(k\)</span>-th raw moment of the mixture distribution can be rewritten as
<span class="math display">\[
\mathrm{E}\left( X^{k} \right) = \int_{-\infty}^{\infty}{\mathrm{E}\left( X^{k}\left| \theta \right.  \right)g_{\Theta}(\theta)}d\theta ~=~ \mathrm{E}\left\lbrack \mathrm{E}\left( X^{k}\left| \Theta \right.  \right) \right\rbrack .
\]</span></p>
<p>Using the law of iterated expectations (see Appendix Chapter <a href="CAppB.html#CAppB">18</a>), we can define the mean and variance of <span class="math inline">\(X\)</span> as
<span class="math display">\[
\mathrm{E}\left( X \right) = \mathrm{E}\left\lbrack \mathrm{E}\left( X\left| \Theta \right.  \right) \right\rbrack
\]</span>
and
<span class="math display">\[
\mathrm{Var}\left( X \right) = \mathrm{E}\left\lbrack \mathrm{Var}\left( X\left| \Theta \right.  \right) \right\rbrack + \mathrm{Var}\left\lbrack \mathrm{E}\left( X\left| \Theta \right.  \right) \right\rbrack .
\]</span></p>
<p><strong>Example 4.3.7. Actuarial Exam Question.</strong>
<span class="math inline">\(X\)</span> has a normal distribution with a mean of <span class="math inline">\(\Lambda\)</span> and variance of 1. <span class="math inline">\(\Lambda\)</span> has a normal distribution with a mean of 1 and variance of 1. Find the mean and variance of <span class="math inline">\(X\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.7" href="javascript:toggleEX('toggleExample.4.3.7','displayExample.4.3.7');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.7" style="display: none">
<p><strong>Solution.</strong></p>
<p>X is a continuous mixture with mean</p>
<p><span class="math display">\[
\mathrm{E}\left(X\right)=\mathrm{E}\left[\mathrm{E}\left(X\middle|\Lambda\right)\right]=\mathrm{E}\left(\Lambda\right)=1 \text{ and } \mathrm{V}\left(X\right)=\mathrm{V}\left[\mathrm{E}\left(X\middle|\Lambda\right)\right]+\mathrm{E}\left[\mathrm{V}\left(X\middle|\Lambda\right)\right]=\mathrm{V}\left(\Lambda\right)+\mathrm{E}\left(1\right)=1+1=2.
\]</span></p>
</div>
<hr />
<p><strong>Example 4.3.8. Actuarial Exam Question.</strong>
Claim sizes, <span class="math inline">\(X\)</span>, are uniform on the interval <span class="math inline">\(\left(\Theta,\Theta+10\right)\)</span> for each policyholder. <span class="math inline">\(\Theta\)</span> varies by policyholder according to an exponential distribution with mean 5. Find the <a href="#" class="tooltip" style="color:green"><em>unconditional distribution</em><span style="font-size:8pt">A probability distribution independent of any another imposed conditions</span></a>, mean and variance of <span class="math inline">\(X\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.3.8" href="javascript:toggleEX('toggleExample.4.3.8','displayExample.4.3.8');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.3.8" style="display: none">
<p><strong>Solution.</strong></p>
<p>The conditional distribution of <span class="math inline">\(X\)</span> is <span class="math inline">\(f_{X}\left( x | \theta \right) = \frac{1}{10}\)</span> for <span class="math inline">\(\theta &lt; x &lt; \theta + 10\)</span>.
The prior distribution of <span class="math inline">\(\theta\)</span> is <span class="math inline">\(g_{\Theta}(\theta) = \frac{1}{5}e^{- \frac{\theta}{5}}\)</span> for <span class="math inline">\(0 &lt; \theta &lt; \infty\)</span>.</p>
<p>Multiplying and integrating yields the unconditional distribution of <span class="math inline">\(X\)</span></p>
<p><span class="math display">\[
f_{X}\left( x \right) = \int f_{X}\left( x |\theta \right) ~g_{\Theta}(\theta) d \theta .
\]</span></p>
<p>For this example, this is</p>
<p><span class="math display">\[
f_{X}\left( x \right) = \left\{ \begin{matrix}
\int_{0}^{x}{\frac{1}{50}e^{- \frac{\theta}{5}}d\theta = \frac{1}{10}\left( 1 - e^{- \frac{x}{5}} \right)} &amp; 0 \leq x \leq 10, \\
\int_{x - 10}^{x}{\frac{1}{50}e^{- \frac{\theta}{5}} d\theta} = \frac{1}{10}\left( e^{- \frac{\left( x - 10 \right)}{5}} - e^{- \frac{x}{5}} \right) &amp; 10 &lt; x &lt; \infty. \\
\end{matrix} \right.\
\]</span></p>
<p>One can use this to derive the mean and variance of the unconditional distribution. Alternatively, start with the conditional mean and variance of <span class="math inline">\(X\)</span>, given by</p>
<p><span class="math display">\[
\mathrm{E}\left(  X | \theta \right)= \frac{\theta + \theta + 10}{2} = \theta + 5
\]</span>
and
<span class="math display">\[
\mathrm{Var}\left(  X | \theta \right)= \frac{\left\lbrack \left( \theta + 10 \right) - \theta \right\rbrack^{2}}{12} = \frac{100}{12},
\]</span>
respectively. With these, the unconditional mean and variance of <span class="math inline">\(X\)</span> are given by</p>
<p><span class="math display">\[
\mathrm{E}\left( X \right) = \mathrm{E}\left\lbrack \mathrm{E}\left( X\left| \Theta \right.  \right) \right\rbrack = \mathrm{E}\left( \Theta + 5 \right) = \mathrm{E}\left( \Theta \right) + 5 = 5 + 5 = 10,
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\mathrm{Var}\left( X \right) = \mathrm{E}\left\lbrack V\left( X\left| \Theta \right.  \right) \right\rbrack + \mathrm{Var}\left\lbrack \mathrm{E}\left( X\left| \Theta \right.  \right) \right\rbrack \\
= \mathrm{E}\left( \frac{100}{12} \right) + \mathrm{Var}\left( \Theta + 5 \right) = 8.33 + \mathrm{Var}\left( \Theta \right) = 33.33.
\]</span></p>
</div>
<hr />
<div id="surveyElement33">

</div>
<div id="surveyResult33">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz33.1" href="javascript:toggleQuiz
('display.Quiz33.2','display.Quiz33.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz33.2" style="display: none">
<p id="Quiz33Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz33.js">
</script>
</div>
</div>
<div id="estimating-loss-distributions" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Estimating Loss Distributions<a href="ChapSeverity.html#estimating-loss-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Estimate moments, quantiles, and distributions without reference to a parametric distribution</li>
<li>Summarize the data graphically without reference to a parametric distribution</li>
<li>Determine measures that summarize deviations of a parametric from a nonparametric fit</li>
<li>Use nonparametric estimators to approximate parameters that can be used to start a parametric estimation procedure</li>
</ul>
<hr />
<div id="S:MS:NonParEst" class="section level3 hasAnchor" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> Nonparametric Estimation<a href="ChapSeverity.html#S:MS:NonParEst" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In Section <a href="ChapFrequency-Modeling.html#S:basic-frequency-distributions">3.2</a> for frequency and Section <a href="ChapSeverity.html#S:BasicQuantities">4.1</a> for severity, we learned how to summarize a distribution by computing means, variances, quantiles/percentiles, and so on. To approximate these summary measures using a dataset, one strategy is to:</p>
<ol style="list-style-type: lower-roman">
<li>assume a parametric form for a distribution, such as a negative binomial for frequency or a gamma distribution for severity,</li>
<li>estimate the parameters of that distribution, and then</li>
<li>use the distribution with the estimated parameters to calculate the desired summary measure.</li>
</ol>
<p>This is the <a href="#" class="tooltip" style="color:green"><em>parametric</em><span style="font-size:8pt">Distributional assumptions made on the population from which the data is drawn, with properties defined using parameters.</span></a> approach. Another strategy is to estimate the desired summary measure directly from the observations <em>without</em> reference to a parametric model. Not surprisingly, this is known as the
<a href="#" class="tooltip" style="color:green"><em>nonparametric</em><span style="font-size:8pt">No distributional assumptions are made on the population from which the data is drawn.</span></a> approach.</p>
<p>Let us start by considering the most basic type of <a href="#" class="tooltip" style="color:green"><em>sampling scheme</em><span style="font-size:8pt">How the data is obtained from the population and what data is observed.</span></a> and assume that observations are realizations from a set of random variables <span class="math inline">\(X_1, \ldots, X_n\)</span> that are <a href="#" class="tooltip" style="color:green"><em>iid</em><span style="font-size:8pt">Independent and identically distributed</span></a> draws from an unknown population distribution <span class="math inline">\(F(\cdot)\)</span>. An equivalent way of saying this is that <span class="math inline">\(X_1, \ldots, X_n\)</span>, is a <em>random sample</em> (with replacement) from <span class="math inline">\(F(\cdot)\)</span>. To see how this works, we now describe nonparametric estimators of many important measures that summarize a distribution.</p>
<div id="empirical-distribution-function" class="section level4 hasAnchor" number="4.4.1.1">
<h4><span class="header-section-number">4.4.1.1</span> Empirical Distribution Function<a href="ChapSeverity.html#empirical-distribution-function" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We have seen how to compute nonparametric estimators of the <span class="math inline">\(k\)</span>th moment <span class="math inline">\(\mathrm{E~} [X^k]\)</span>. In the same way, for any known function <span class="math inline">\(\mathrm{g}(\cdot)\)</span>, we can estimate <span class="math inline">\(\mathrm{E~} [\mathrm{g}(X)]\)</span> using <span class="math inline">\(n^{-1}\sum_{i=1}^n \mathrm{g}(X_i)\)</span>.</p>
<p>Now consider the function <span class="math inline">\(\mathrm{g}(X) = I(X \le x)\)</span> for a fixed <span class="math inline">\(x\)</span>. Here, the notation <span class="math inline">\(I(\cdot)\)</span> is the <a href="#" class="tooltip" style="color:green"><em>indicator</em><span style="font-size:8pt">A categorical variable that has only two groups. the numerical values are usually taken to be one to indicate the presence of an attribute, and zero otherwise. another name for a binary variable.</span></a> function; it returns 1 if the event <span class="math inline">\((\cdot)\)</span> is true and 0 otherwise. Note that now the random variable <span class="math inline">\(\mathrm{g}(X)\)</span> has Bernoulli distribution (a binomial distribution with <span class="math inline">\(n=1\)</span>). We can use this distribution to readily calculate quantities such as the mean and the variance. For example, for this choice of <span class="math inline">\(\mathrm{g}(\cdot)\)</span>, the expected value is <span class="math inline">\(\mathrm{E~} [I(X \le x)] = \Pr(X \le x) = F(x)\)</span>, the distribution function evaluated at <span class="math inline">\(x\)</span>. Using the <a href="#" class="tooltip" style="color:green"><em>analog principle</em><span style="font-size:8pt"></span></a>, we define the nonparametric estimator of the distribution function</p>
<p><span class="math display">\[
\begin{aligned}
F_n(x)
&amp;=  \frac{1}{n} \sum_{i=1}^n I\left(X_i \le x\right) \\
&amp;=  \frac{\text{number of observations less than or equal to }x}{n} .
\end{aligned}
\]</span>
As <span class="math inline">\(F_n(\cdot)\)</span> is based on only observations and does not assume a parametric family for the distribution, it is nonparametric and also known as the <a href="#" class="tooltip" style="color:green"><em>empirical distribution function</em><span style="font-size:8pt">The empirical distribution is a non-parametric estimate of the underlying distribution of a random variable. it directly uses the data observations to construct the distribution, with each observed data point in a size-n sample having probability 1/n.</span></a>. It is also known as the <em>empirical cumulative distribution function</em> and, in <code>R</code>, one can use the <code>ecdf(.)</code> function to compute it.</p>
<p><strong>Example 5.1.1. Toy Data Set</strong>. To illustrate, consider a fictitious, or toy, data set of <span class="math inline">\(n=10\)</span> observations. Determine the empirical distribution function.</p>
<p><span class="math display">\[
{\small
\begin{array}{c|cccccccccc}
\hline
i &amp;1&amp;2&amp;3&amp;4&amp;5&amp;6&amp;7&amp;8&amp;9&amp;10 \\
X_i&amp; 10 &amp;15 &amp;15 &amp;15 &amp;20 &amp;23 &amp;23 &amp;23 &amp;23 &amp;30\\
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.1" href="javascript:toggleEX('toggleExample.5.1.1','displayExample.5.1.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.1" style="display: none">
<p>You should check that the sample mean is <span class="math inline">\(\overline{X} = 19.7\)</span> and that the sample variance is <span class="math inline">\(s^2 =34.45556\)</span>. The corresponding empirical distribution function is</p>
<p><span class="math display">\[
\begin{aligned}
F_n(x) &amp;=
\left\{
\begin{array}{ll}
0 &amp; \text{ for }\ x&lt;10 \\
0.1 &amp; \text{ for }\ 10 \leq x&lt;15 \\
0.4 &amp; \text{ for }\ 15 \leq x&lt;20 \\
0.5 &amp; \text{ for }\ 20 \leq x&lt;23 \\
0.9 &amp; \text{ for }\ 23 \leq x&lt;30 \\
1 &amp; \text{ for }\ x \geq 30,
\end{array}
\right.\end{aligned}
\]</span></p>
<p>as shown in Figure <a href="ChapSeverity.html#fig:EDFToy">4.6</a>. The empirical distribution is generally discrete and continuous from the right.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:EDFToy"></span>
<img src="LossDataAnalytics_files/figure-html/EDFToy-1.png" alt="Empirical Distribution Function of a Toy Example" width="60%" />
<p class="caption">
Figure 4.6: <strong>Empirical Distribution Function of a Toy Example</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Toy.4f" href="javascript:togglecode('toggleCode.Toy.4f','displayCode.Toy.4f');"><i><strong>Show R Code</strong></i></a>
</h5>
<div id="toggleCode.Toy.4f" style="display: none">
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="ChapSeverity.html#cb40-1" aria-hidden="true" tabindex="-1"></a>(xExample <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="fu">rep</span>(<span class="dv">15</span>, <span class="dv">3</span>), <span class="dv">20</span>, <span class="fu">rep</span>(<span class="dv">23</span>, <span class="dv">4</span>), <span class="dv">30</span>))</span>
<span id="cb40-2"><a href="ChapSeverity.html#cb40-2" aria-hidden="true" tabindex="-1"></a>PercentilesxExample <span class="ot">&lt;-</span> <span class="fu">ecdf</span>(xExample)</span>
<span id="cb40-3"><a href="ChapSeverity.html#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(PercentilesxExample, <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>)</span></code></pre></div>
</div>
</div>
<hr />
</div>
<div id="S:MS:Density" class="section level4 hasAnchor" number="4.4.1.2">
<h4><span class="header-section-number">4.4.1.2</span> Density Estimators<a href="ChapSeverity.html#S:MS:Density" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>Discrete Variable.</strong> When the random variable is discrete, estimating the probability mass function <span class="math inline">\(f(x) = \Pr(X=x)\)</span> is straightforward. We simply use the sample average, defined to be</p>
<p><span class="math display">\[
f_n(x) = \frac{1}{n} \sum_{i=1}^n I(X_i = x),
\]</span></p>
<p>which is the proportion of the sample equal to <span class="math inline">\(x\)</span>.</p>
<p><strong>Continuous Variable within a Group.</strong> For a continuous random variable, consider a discretized formulation in which the domain of <span class="math inline">\(F(\cdot)\)</span> is partitioned by constants <span class="math inline">\(\{c_0 &lt; c_1 &lt; \cdots &lt; c_k\}\)</span> into intervals of the form <span class="math inline">\([c_{j-1}, c_j)\)</span>, for <span class="math inline">\(j=1, \ldots, k\)</span>. The data observations are thus grouped by the intervals into which they fall. Then, we might use the basic definition of the empirical mass function, or a variation such as
<span class="math display">\[f_n(x) = \frac{n_j}{n \times (c_j - c_{j-1})}  \ \ \ \ \ \ c_{j-1} \le x &lt; c_j,\]</span>
where <span class="math inline">\(n_j\)</span> is the number of observations (<span class="math inline">\(X_i\)</span>) that fall into the interval <span class="math inline">\([c_{j-1}, c_j)\)</span>.</p>
<p><strong>Continuous Variable (not grouped).</strong> Extending this notion to instances where we observe individual data, note that we can always create arbitrary groupings and use this formula. More formally, let <span class="math inline">\(b&gt;0\)</span> be a small positive constant, known as a <a href="#" class="tooltip" style="color:green"><em>bandwidth</em><span style="font-size:8pt">A small positive constant that defines the width of the steps and the degree of smoothing.</span></a>, and define a density estimator to be</p>
<p><span class="math display" id="eq:KDF">\[\begin{equation}
f_n(x) = \frac{1}{2nb} \sum_{i=1}^n I(x-b &lt; X_i \le x + b)
\tag{4.4}
\end{equation}\]</span></p>
<h5 style="text-align: center;">
<a id="displayTheory.kernel.1" href="javascript:toggleTheory('toggleTheory.kernel.1','displayCode.kernel.1');"><i><strong>Show A Snippet of Theory</strong></i></a>
</h5>
<div id="toggleTheory.kernel.1" style="display: none">
<hr />
<p><strong>Snippet of Theory.</strong> The idea is that the estimator <span class="math inline">\(f_n(x)\)</span> in equation <a href="ChapSeverity.html#eq:KDF">(4.4)</a> is the average over <span class="math inline">\(n\)</span> <em>iid</em> realizations of a random variable with mean</p>
<p><span class="math display">\[
\begin{aligned}
\mathrm{E~ } \left[\frac{1}{2b} I(x-b &lt; X \le x + b)\right] &amp;=  \frac{1}{2b}\left(F(x+b)-F(x-b)\right) \\
&amp; \rightarrow  F^{\prime}(x) = f(x),
\end{aligned}
\]</span></p>
<p>as <span class="math inline">\(b\rightarrow 0\)</span>. That is, <span class="math inline">\(f_n(x)\)</span> is an <a href="#" class="tooltip" style="color:green"><em>asymptotically unbiased</em><span style="font-size:8pt"></span></a> estimator of <span class="math inline">\(f(x)\)</span> (its expectation approaches the true value as sample size increases to infinity). This development assumes some smoothness of <span class="math inline">\(F(\cdot)\)</span>, in particular, twice differentiability at <span class="math inline">\(x\)</span>, but makes no assumptions on the form of the distribution function <span class="math inline">\(F\)</span>. Because of this, the density estimator <span class="math inline">\(f_n\)</span> is said to be <em>nonparametric</em>.</p>
<hr />
</div>
<p>More generally, define the <a href="#" class="tooltip" style="color:green"><em>kernel density estimator</em><span style="font-size:8pt">A nonparametric estimator of the density function of a random variable.</span></a> of the <a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt">Probability density function</span></a> at <span class="math inline">\(x\)</span> as</p>
<p><span class="math display" id="eq:kernelDens">\[\begin{equation}
f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right) ,
\tag{4.5}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(w\)</span> is a probability density function centered about 0. Note that equation <a href="ChapSeverity.html#eq:KDF">(4.4)</a> is a special case of the kernel density estimator where <span class="math inline">\(w(x) = \frac{1}{2}I(-1 &lt; x \le 1)\)</span>, also known as the <em>uniform kernel</em>. Other popular choices are shown in <a href="#tab:5.1">Table 5.1</a>.</p>
<p><a id=tab:5.1></a></p>
<p>Table 5.1. <strong>Popular Kernel Choices</strong></p>
<p><span class="math display">\[
{\small
\begin{matrix}
\begin{array}{l|cc}
\hline
\text{Kernel} &amp;  w(x) \\
\hline
\text{Uniform } &amp;  \frac{1}{2}I(-1 &lt; x \le 1) \\
\text{Triangle} &amp;  (1-|x|)\times I(|x| \le 1) \\
\text{Epanechnikov} &amp; \frac{3}{4}(1-x^2) \times I(|x| \le 1) \\
\text{Gaussian} &amp; \phi(x) \\
\hline
\end{array}\end{matrix}
}
\]</span></p>
<p>Here, <span class="math inline">\(\phi(\cdot)\)</span> is the standard normal density function. As we will see in the following example, the choice of bandwidth <span class="math inline">\(b\)</span> comes with a <a href="#" class="tooltip" style="color:green"><em>bias-variance tradeoff</em><span style="font-size:8pt">The tradeoff between model simplicity (underfitting; high bias) and flexibility (overfitting; high variance).</span></a> between matching local distributional features and reducing the volatility.</p>
<hr />
<p><strong>Example 5.1.4. Property Fund.</strong>
Figure <a href="ChapSeverity.html#fig:Density2">4.7</a> shows a histogram (with shaded gray rectangles) of logarithmic property claims from 2010. The (blue) thick curve represents a Gaussian kernel density where the bandwidth was selected automatically using an ad hoc rule based on the sample size and volatility of these data. For this dataset, the bandwidth turned out to be <span class="math inline">\(b=0.3255\)</span>. For comparison, the (red) dashed curve represents the density estimator with a bandwidth equal to 0.1 and the green smooth curve uses a bandwidth of 1. As anticipated, the smaller bandwidth (0.1) indicates taking local averages over less data so that we get a better idea of the local average, but at the price of higher volatility. In contrast, the larger bandwidth (1) smooths out local fluctuations, yielding a smoother curve that may miss perturbations in the local average. For actuarial applications, we mainly use the kernel density estimator to get a quick visual impression of the data. From this perspective, you can simply use the default ad hoc rule for bandwidth selection, knowing that you have the ability to change it depending on the situation at hand.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Density2"></span>
<img src="LossDataAnalytics_files/figure-html/Density2-1.png" alt="Histogram of Logarithmic Property Claims with Superimposed Kernel Density Estimators" width="70%" />
<p class="caption">
Figure 4.7: <strong>Histogram of Logarithmic Property Claims with Superimposed Kernel Density Estimators</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.kpdf" href="javascript:togglecode('toggleCode.kpdf','displayCode.kpdf');"><i><strong>Show R Code</strong></i></a>
</h5>
<div id="toggleCode.kpdf" style="display: none">
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="ChapSeverity.html#cb41-1" aria-hidden="true" tabindex="-1"></a>ClaimLev <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Data/CLAIMLEVEL.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>); <span class="co">#nrow(ClaimLev); # 6258</span></span>
<span id="cb41-2"><a href="ChapSeverity.html#cb41-2" aria-hidden="true" tabindex="-1"></a>ClaimData<span class="ot">&lt;-</span><span class="fu">subset</span>(ClaimLev,Year<span class="sc">==</span><span class="dv">2010</span>);     <span class="co">#2010 subset</span></span>
<span id="cb41-3"><a href="ChapSeverity.html#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Density Comparison</span></span>
<span id="cb41-4"><a href="ChapSeverity.html#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,.<span class="dv">35</span>),<span class="at">xlab=</span><span class="st">&quot;Log Expenditures&quot;</span>, <span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">col=</span><span class="st">&quot;lightgray&quot;</span>)</span>
<span id="cb41-5"><a href="ChapSeverity.html#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim)), <span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lwd=</span><span class="fl">2.5</span>)</span>
<span id="cb41-6"><a href="ChapSeverity.html#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">bw=</span><span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb41-7"><a href="ChapSeverity.html#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(<span class="fu">log</span>(ClaimData<span class="sc">$</span>Claim), <span class="at">bw=</span>.<span class="dv">1</span>), <span class="at">col=</span><span class="st">&quot;red&quot;</span>, <span class="at">lty=</span><span class="dv">3</span>)</span>
<span id="cb41-8"><a href="ChapSeverity.html#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;b=0.3255 (default)&quot;</span>, <span class="st">&quot;b=0.1&quot;</span>, <span class="st">&quot;b=1.0&quot;</span>), <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">1</span>), <span class="at">lwd=</span><span class="fu">c</span>(<span class="fl">2.5</span>,<span class="dv">1</span>,<span class="dv">1</span>),</span>
<span id="cb41-9"><a href="ChapSeverity.html#cb41-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">col=</span><span class="fu">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;green&quot;</span>), <span class="at">cex=</span><span class="dv">1</span>)</span>
<span id="cb41-10"><a href="ChapSeverity.html#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co">#density(log(ClaimData$Claim))$bw   ##default bandwidth</span></span></code></pre></div>
</div>
<hr />
<p>Nonparametric density estimators, such as the kernel estimator, are regularly used in practice. The concept can also be extended to give smooth versions of an empirical distribution function. Given the definition of the kernel density estimator, the <em>kernel estimator of the distribution function</em> can be found as</p>
<p><span class="math display">\[
\begin{aligned}
\tilde{F}_n(x) = \frac{1}{n} \sum_{i=1}^n W\left(\frac{x-X_i}{b}\right).\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(W\)</span> is the distribution function associated with the kernel density <span class="math inline">\(w\)</span>. To illustrate, for the uniform kernel, we have <span class="math inline">\(w(y) = \frac{1}{2}I(-1 &lt; y \le 1)\)</span>, so</p>
<p><span class="math display">\[
\begin{aligned}
W(y) =
\begin{cases}
0 &amp;            y&lt;-1\\
\frac{y+1}{2}&amp; -1 \le y &lt; 1 \\
1 &amp; y \ge 1 \\
\end{cases}\end{aligned} .
\]</span></p>
<hr />
<p><strong>Example 5.1.5. Actuarial Exam Question.</strong></p>
<p>You study five lives to estimate the time from the onset of a disease to death. The times to death are:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
2 &amp; 3 &amp; 3 &amp; 3 &amp; 7  \\
\end{array}
\]</span></p>
<p>Using a triangular kernel with bandwidth <span class="math inline">\(2\)</span>, calculate the density function estimate at 2.5.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.5" href="javascript:toggleEX('toggleExample.5.1.5','displayExample.5.1.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.5" style="display: none">
<p><strong>Solution.</strong>
For the kernel density estimate, we have
<span class="math display">\[f_n(x) = \frac{1}{nb} \sum_{i=1}^n w\left(\frac{x-X_i}{b}\right),\]</span>
where <span class="math inline">\(n=5\)</span>, <span class="math inline">\(b=2\)</span>, and <span class="math inline">\(x=2.5\)</span>. For the triangular kernel, <span class="math inline">\(w(x) = (1-|x|)\times I(|x| \le 1)\)</span>. Thus,</p>
<p><span class="math display">\[
\begin{array}{c|c|c}
\hline
X_i &amp; \frac{x-X_i}{b} &amp; w\left(\frac{x-X_i}{b} \right) \\
\hline
2 &amp; \frac{2.5-2}{2}=\frac{1}{4} &amp;  (1-\frac{1}{4})(1) = \frac{3}{4} \\
\hline
3 &amp; &amp; \\
3 &amp; \frac{2.5-3}{2}=\frac{-1}{4} &amp; \left(1-\left| \frac{-1}{4} \right| \right)(1) = \frac{3}{4} \\
3 &amp; &amp; \\
\hline
7 &amp; \frac{2.5-7}{2}=-2.25 &amp; (1-|-2.25|)(0) = 0\\
\hline
\end{array}
\]</span></p>
<p>Then the kernel density estimate at <span class="math inline">\(x=2.5\)</span> is <span class="math display">\[f_n(2.5) = \frac{1}{5(2)}\left( \frac{3}{4} + (3) \frac{3}{4} + 0 \right) = \frac{3}{10}\]</span></p>
</div>
<hr />
</div>
</div>
<div id="parametric-estimation" class="section level3 hasAnchor" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Parametric Estimation<a href="ChapSeverity.html#parametric-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="maximum-likelihood-estimators-for-complete-data" class="section level3 hasAnchor" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Maximum Likelihood Estimators for Complete Data<a href="ChapSeverity.html#maximum-likelihood-estimators-for-complete-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Up to this point, the chapter has focused on parametric distributions that are commonly used in insurance applications. However, to be useful in applied work, these distributions must use realistic values for the parameters and for this we turn to data. At a foundational level, we assume that the analyst has available a random sample <span class="math inline">\(X_1, \ldots, X_n\)</span> from a distribution with distribution function <span class="math inline">\(F_X\)</span> (for brevity, we sometimes drop the subscript <span class="math inline">\(X\)</span>). As is common, we use the vector <span class="math inline">\(\boldsymbol \theta\)</span> to denote the set of parameters for <span class="math inline">\(F\)</span>. This basic sample scheme is reviewed in Appendix Section <a href="CAppA.html#S:AppA:BASIC">17.1</a>. Although basic, this sampling scheme provides the foundations for understanding more complex schemes that are regularly used in practice, and so it is important to master the basics.</p>
<p>Before drawing from a distribution, we consider potential outcomes summarized by the random variable <span class="math inline">\(X_i\)</span> (here, <span class="math inline">\(i\)</span> is 1, 2, , <span class="math inline">\(n\)</span>). After the draw, we observe <span class="math inline">\(x_i\)</span>. Notationally, we use uppercase roman letters for random variables and lower case ones for realizations. We have seen this set-up already in Section <a href="ChapFrequency-Modeling.html#S:estimating-frequency-distributions">3.4</a>, where we used
<span class="math inline">\(\Pr(X_1 =x_1, \ldots, X_n=x_n)\)</span> to quantify the likelihood of drawing a sample <span class="math inline">\(\{x_1, \ldots, x_n\}\)</span>. With continuous data, we use the joint probability density function instead of joint probabilities. With the independence assumption, the joint <em>pdf</em> may be written as the product of pdfs. Thus, we define the <strong>likelihood</strong> to be</p>
<p><span class="math display" id="eq:Likelihood">\[\begin{equation}
L(\boldsymbol \theta) = \prod_{i=1}^n f(x_i) .
\tag{4.6}
\end{equation}\]</span></p>
<p>From the notation, note that we consider this to be a function of the parameters in <span class="math inline">\(\boldsymbol \theta\)</span>, with the data <span class="math inline">\(\{x_1, \ldots, x_n\}\)</span> held fixed. The maximum likelihood estimator is that value of the parameters in <span class="math inline">\(\boldsymbol \theta\)</span> that maximize <span class="math inline">\(L(\boldsymbol \theta)\)</span>.</p>
<p>From calculus, we know that maximizing a function produces the same results as maximizing the logarithm of a function (this is because the logarithm is a monotone function). Because we get the same results, to ease computational considerations, it is common to consider the <strong>logarithmic likelihood</strong>, denoted as</p>
<p><span class="math display" id="eq:Loglikelihood">\[\begin{equation}
l(\boldsymbol \theta) = \log L(\boldsymbol \theta) = \sum_{i=1}^n \log f(x_i) .
\tag{4.7}
\end{equation}\]</span></p>
<p>Appendix Section <a href="CAppA.html#S:AppA:MLE">17.2.2</a> reviews the foundations of maximum likelihood estimation with more mathematical details in Appendix Chapter <a href="CAppC.html#CAppC">19</a>.</p>
<p><strong>Example 4.5.1. Actuarial Exam Question.</strong> You are given the following five observations: 521, 658, 702, 819, 1217. You use the single-parameter Pareto with distribution function:</p>
<p><span class="math display">\[
F(x) = 1- \left(\frac{500}{x}\right)^{\alpha}, ~~~~ x&gt;500 .
\]</span></p>
<p>With <span class="math inline">\(n=5\)</span>, the log-likelihood function is
<span class="math display">\[
l(\alpha) =  \sum_{i=1}^5 \log f(x_i;\alpha ) =  5 \alpha \log 500 + 5 \log \alpha
-(\alpha+1) \sum_{i=1}^5 \log x_i.
\]</span></p>
<p>Figure <a href="ChapSeverity.html#fig:LoglikeOnePareto">4.8</a> shows the logarithmic likelihood as a function of the parameter <span class="math inline">\(\alpha\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:LoglikeOnePareto"></span>
<img src="LossDataAnalytics_files/figure-html/LoglikeOnePareto-1.png" alt="Logarithmic Likelihood for a One-Parameter Pareto" width="60%" />
<p class="caption">
Figure 4.8: <strong>Logarithmic Likelihood for a One-Parameter Pareto</strong>
</p>
</div>
<p>We can determine the maximum value of the logarithmic likelihood by taking derivatives and setting it equal to zero.
This yields
<span class="math display">\[
\begin{array}{ll}
\frac{ \partial}{\partial \alpha } l(\alpha ) &amp;=    5  \log 500 + 5 / \alpha -  \sum_{i=1}^5 \log x_i
=_{set} 0 \Rightarrow \\
\hat{\alpha}_{MLE} &amp;= \frac{5}{\sum_{i=1}^5 \log x_i - 5  \log 500 } = 2.453 .
\end{array}
\]</span></p>
<p>Naturally, there are many problems where it is not practical to use hand calculations for optimization. Fortunately there are many statistical routines available such as the <code>R</code> function <code>optim</code>.</p>
<h5 style="text-align: center;">
<a id="displayCode.optim.1" href="javascript:togglecode('toggleCode.optim.1','displayCode.optim.1');"><i><strong>R Code for Optimization</strong></i></a>
</h5>
<div id="toggleCode.optim.1" style="display: none">
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="ChapSeverity.html#cb42-1" aria-hidden="true" tabindex="-1"></a>c1 <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">521</span>) <span class="sc">+</span> <span class="fu">log</span>(<span class="dv">658</span>) <span class="sc">+</span> <span class="fu">log</span>(<span class="dv">702</span>) <span class="sc">+</span> <span class="fu">log</span>(<span class="dv">819</span>) <span class="sc">+</span> <span class="fu">log</span>(<span class="dv">1217</span>)</span>
<span id="cb42-2"><a href="ChapSeverity.html#cb42-2" aria-hidden="true" tabindex="-1"></a>nloglike <span class="ot">&lt;-</span> <span class="cf">function</span>(alpha) {</span>
<span id="cb42-3"><a href="ChapSeverity.html#cb42-3" aria-hidden="true" tabindex="-1"></a>    <span class="sc">-</span>(<span class="dv">5</span> <span class="sc">*</span> alpha <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">500</span>) <span class="sc">+</span> <span class="dv">5</span> <span class="sc">*</span> <span class="fu">log</span>(alpha) <span class="sc">-</span> (alpha <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">*</span> c1)</span>
<span id="cb42-4"><a href="ChapSeverity.html#cb42-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb42-5"><a href="ChapSeverity.html#cb42-5" aria-hidden="true" tabindex="-1"></a>MLE <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="at">par =</span> <span class="dv">1</span>, <span class="at">fn =</span> nloglike)<span class="sc">$</span>par</span></code></pre></div>
<hr />
</div>
<p>This code confirms our hand calculation result where the maximum likelihood estimator is <span class="math inline">\(\alpha_{MLE} =\)</span> 2.453125.</p>
<hr />
<p>We present a few additional examples to illustrate how actuaries fit a parametric distribution model to a set of claim data using maximum likelihood.</p>
<p><strong>Example 4.5.2. Actuarial Exam Question.</strong>
Consider a random sample of claim amounts: 8000 10000 12000 15000. You assume that claim amounts follow an inverse exponential distribution, with parameter <span class="math inline">\(\theta\)</span>. Calculate the maximum likelihood estimator for <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.5.2" href="javascript:toggleEX('toggleExample.4.5.2','displayExample.4.5.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.5.2" style="display: none">
<p><strong>Solution.</strong></p>
<p>The <em>pdf</em> is
<span class="math display">\[f_{X}\left( x \right) = \frac{\theta e^{- \frac{\theta}{x}}}{x^{2}}, \]</span>
where <span class="math inline">\(x &gt; 0\)</span>.</p>
<p>The likelihood function, <span class="math inline">\(L\left( \theta \right)\)</span>, can be viewed as the probability of the observed data, written as a function of the models parameter <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[
L\left( \theta \right) = \prod_{i = 1}^{4}{f_{X_{i}}\left( x_{i} \right)} = \frac{\theta^{4}e^{- \theta\sum_{i = 1}^{4}\frac{1}{x_{i}}}}{\prod_{i = 1}^{4}x_{i}^{2}}.
\]</span></p>
<p>The log-likelihood function, <span class="math inline">\(\log L \left( \theta \right)\)</span>, is the sum of the individual logarithms</p>
<p><span class="math display">\[
\log L \left( \theta \right) = 4 \log \theta - \theta\sum_{i = 1}^{4}\frac{1}{x_{i}} - 2\sum_{i = 1}^{4}\log x_{i} .
\]</span></p>
<p>Taking a derivative, we have</p>
<p><span class="math display">\[
\frac{d \log L \left( \theta \right)}{d \theta} = \frac{4}{\theta} - \sum_{i = 1}^{4}\frac{1}{x_{i}}.
\]</span></p>
<p>The maximum likelihood estimator of <span class="math inline">\(\theta\)</span>, denoted by <span class="math inline">\(\hat{\theta}\)</span>, is the solution to the equation</p>
<p><span class="math display">\[
\frac{4}{\hat{\theta}} - \sum_{i = 1}^{4}{\frac{1}{x_{i}} = 0}.
\]</span></p>
<p>Thus,
<span class="math inline">\(\hat{\theta} = \frac{4}{\sum_{i = 1}^{4}\frac{1}{x_{i}}} = 10,667.\)</span></p>
<p>The second derivative of <span class="math inline">\(\log L \left( \theta \right)\)</span> is given by</p>
<p><span class="math display">\[
\frac{d^{2}\log L\left( \theta \right)}{d\theta^{2}} = \frac{- 4}{\theta^{2}}.
\]</span></p>
<p>Evaluating the second derivative of the loglikelihood function at <span class="math inline">\(\hat{\theta} = 10,667\)</span> gives a negative value, indicating <span class="math inline">\(\hat{\theta}\)</span> as the value that maximizes the loglikelihood function.</p>
</div>
<hr />
<p><strong>Example 4.5.3. Actuarial Exam Question.</strong>
A random sample of size 6 is from a lognormal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. The sample values are</p>
<p><span class="math display">\[
200 \ \ \ 3000 \ \ \ 8000 \ \ \ 60000 \ \ \ 60000 \ \ \ 160000.
\]</span></p>
<p>Calculate the maximum likelihood estimator for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.5.3" href="javascript:toggleEX('toggleExample.4.5.3','displayExample.4.5.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.5.3" style="display: none">
<p><strong>Solution.</strong></p>
<p>The <em>pdf</em> is</p>
<p><span class="math display">\[
f_{X}\left( x \right) = \frac{1}{x \sigma \sqrt{2\pi}}\exp\left( - \frac{1}{2}\left( \frac{\log x - \mu}{\sigma} \right)^{2} \right),
\]</span></p>
<p>where <span class="math inline">\(x &gt; 0\)</span>.</p>
<p>The likelihood function, <span class="math inline">\(L\left( \mu,\sigma \right)\)</span>, is the product of the <em>pdf</em> for each data point.</p>
<p><span class="math display">\[
L\left( \mu,\sigma \right) = \prod_{i = 1}^{6}{f_{X_{i}}\left( x_{i} \right)} = \frac{1}{\sigma^{6}\left( 2\pi \right)^{3}\prod_{i = 1}^{6}x_{i}}\exp\left( - \frac{1}{2}\sum_{i = 1}^{6}\left( \frac{\log x_{i} - \mu}{\sigma} \right)^{2}\right).
\]</span></p>
<p>Taking a logarithm yields the loglikelihood function, <span class="math inline">\(\log L \left( \mu,\sigma \right)\)</span>, which is the sum of the individual logarithms.</p>
<p><span class="math display">\[
\log L\left( \mu,\sigma \right)
= - 6 \log \sigma - 3 \log \left( 2\pi \right) - \sum_{i = 1}^{6}\log x_{i} - \frac{1}{2}\sum_{i = 1}^{6}\left( \frac{\log x_{i} - \mu}{\sigma} \right)^{2}.
\]</span></p>
<p>The first partial derivatives are</p>
<p><span class="math display">\[
\begin{array}{ll}
\frac{\partial \log L\left( \mu,\sigma \right)}{\partial\mu} &amp;= \frac{1}{\sigma^{2}}\sum_{i = 1}^{6}\left( \log x_{i} - \mu \right) \\
\frac{\partial \log L\left( \mu,\sigma \right)}{\partial\sigma} &amp;= \frac{- 6}{\sigma} + \frac{1}{\sigma^{3}}\sum_{i = 1}^{6}\left( \log x_{i} - \mu \right)^{2}.
\end{array}
\]</span></p>
<p>The maximum likelihood estimators of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, denoted by <span class="math inline">\(\hat{\mu}\)</span> and <span class="math inline">\(\hat{\sigma}\)</span>, are the solutions to the equations</p>
<p><span class="math display">\[
\begin{array}{ll}
\frac{1}{{\hat{\sigma}}^{2}}\sum_{i = 1}^{6}\left( \log x_{i} - \hat{\mu} \right) &amp;= 0 \\
\frac{- 6}{\hat{\sigma}} + \frac{1}{{\hat{\sigma}}^{3}}\sum_{i = 1}^{6}\left( \log x_{i} - \hat{\mu} \right)^{2} &amp;= 0 .
\end{array}
\]</span></p>
<p>These yield the estimates</p>
<p><span class="math display">\[
\hat{\mu} = \frac{\sum_{i = 1}^{6}{\log x_{i}}}{6} = 9.38 \ \ \ \text{and} \ \ \
{\hat{\sigma}}^{2} = \frac{\sum_{i = 1}^{6}\left( \log x_{i} - \hat{\mu} \right)^{2}}{6} = 5.12 .
\]</span></p>
<p>To check that these estimates maximize, and do not minimize, the likelihood, you may also wish to compute the second partial derivatives. These are</p>
<p><span class="math display">\[
\frac{\partial^{2}\log L\left( \mu,\sigma \right)}{\partial\mu^{2}} = \frac{- 6}{\sigma^{2}}, \ \ \ \
\frac{\partial^{2}\log L\left( \mu,\sigma \right)}{\partial\mu\partial\sigma} = \frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}\left( \log x_{i} - \mu \right)
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\frac{\partial^{2}\log L\left( \mu,\sigma \right)}{\partial\sigma^{2}} = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}\left( \log x_{i} - \mu \right)^{2} .
\]</span></p>
</div>
<hr />
<p>Two follow-up questions rely on large sample properties that you may have seen in an earlier course. Appendix Chapter <a href="CAppC.html#CAppC">19</a> reviews the definition of the likelihood function, introduces its properties, reviews the maximum likelihood estimators, extends their large-sample properties to the case where there are multiple parameters in the model, and reviews statistical inference based on maximum likelihood estimators. In the solutions of these examples we derive the asymptotic variance of maximum-likelihood estimators of the model parameters. We use the delta method to derive the asymptotic variances of functions of these parameters.</p>
<p><strong>Example 4.5.2 - Follow - Up.</strong> Refer to <strong>Example 4.5.2.</strong></p>
<ol style="list-style-type: lower-alpha">
<li>Approximate the variance of the maximum likelihood estimator.</li>
<li>Determine an approximate 95% confidence interval for <span class="math inline">\(\theta\)</span>.</li>
<li>Determine an approximate 95% confidence interval for <span class="math inline">\(\Pr \left( X \leq 9,000 \right).\)</span></li>
</ol>
<h5 style="text-align: center;">
<a id="displayExample.4.5.2a" href="javascript:toggleEX('toggleExample.4.5.2a','displayExample.4.5.2a');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.5.2a" style="display: none">
<p><strong>Solution.</strong></p>
<p><strong>a.</strong> Taking reciprocal of negative expectation of the second derivative of <span class="math inline">\(\log L \left( \theta \right)\)</span>, we obtain an estimate of the variance of <span class="math inline">\(\hat{\theta}\)</span>,
<span class="math inline">\(\widehat{Var}\left( \hat{\theta} \right) = \left. \ \left\lbrack E\left( \frac{d^{2}\log L \left( \theta \right)}{d\theta^{2}} \right) \right\rbrack^{- 1} \right|_{\theta = \hat{\theta}} = \frac{{\hat{\theta}}^{2}}{4} = 28,446,222\)</span>.</p>
<p>It should be noted that as the sample size <span class="math inline">\(n \rightarrow \infty\)</span>, the distribution of the maximum likelihood estimator <span class="math inline">\(\hat{\theta}\)</span> converges to a normal distribution with mean <span class="math inline">\(\theta\)</span> and variance <span class="math inline">\(\hat{V}\left( \hat{\theta} \right)\)</span>. The approximate confidence interval in this example is based on the assumption of normality, despite the small sample size, only for the purpose of illustration.</p>
<p><strong>b.</strong> The 95% confidence interval for <span class="math inline">\(\theta\)</span> is given by</p>
<p><span class="math display">\[
10,667 \pm 1.96\sqrt{28,446,222} = \left( 213.34,\ 21120.66 \right).
\]</span></p>
<p><strong>c.</strong> The distribution function of <span class="math inline">\(X\)</span> is <span class="math inline">\(F\left( x \right) = 1 - e^{- \frac{x}{\theta}}\)</span>. Then, the maximum likelihood estimate of <span class="math inline">\(g_{\Theta}(\theta) = F\left( 9,000 \right)\)</span> is</p>
<p><span class="math display">\[
g\left( \hat{\theta} \right) = 1 - e^{- \frac{9,000}{10,667}} = 0.57.
\]</span></p>
<p>We use the delta method to approximate the variance of <span class="math inline">\(g\left( \hat{\theta} \right)\)</span>.
<span class="math display">\[\frac{\text{dg}\left( \theta \right)}{d \theta} = {- \frac{9000}{\theta^{2}}e}^{- \frac{9000}{\theta}}.\]</span></p>
<p><span class="math inline">\(\widehat{Var}\left\lbrack g\left( \hat{\theta} \right) \right\rbrack = \left( - {\frac{9000}{{\hat{\theta}}^{2}}e}^{- \frac{9000}{\hat{\theta}}} \right)^{2}\hat{V}\left( \hat{\theta} \right) = 0.0329\)</span>.</p>
<p>The 95% confidence interval for <span class="math inline">\(F\left( 9000 \right)\)</span> is given by
<span class="math display">\[
0.57 \pm 1.96\sqrt{0.0329} = \left( 0.214,\ 0.926 \right).
\]</span></p>
</div>
<hr />
<p><strong>Example 4.5.3 - Follow - Up.</strong> Refer to <strong>Example 4.5.3.</strong></p>
<ol style="list-style-type: lower-alpha">
<li>Estimate the <a href="#" class="tooltip" style="color:green"><em>covariance matrix</em><span style="font-size:8pt">Matrix where the (i,j)^th element represents the covariance between the ith and jth random variables</span></a> of the maximum likelihood estimator.</li>
<li>Determine approximate 95% confidence intervals for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</li>
<li>Determine an approximate 95% confidence interval for the mean of the lognormal distribution.</li>
</ol>
<h5 style="text-align: center;">
<a id="displayExample.4.5.3a" href="javascript:toggleEX('toggleExample.4.5.3a','displayExample.4.5.3a');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.5.3a" style="display: none">
<p><strong>a.</strong> To derive the covariance matrix of the <a href="#" class="tooltip" style="color:green"><em>mle</em><span style="font-size:8pt">Maximum likelihood estimate</span></a> we need to find the expectations of the second derivatives. Since the random variable <span class="math inline">\(X\)</span> is from a lognormal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, then <span class="math inline">\(\log X\)</span> is normally distributed with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>.</p>
<p><span class="math display">\[
\mathrm{E}\left( \frac{\partial^{2}\text{log L}\left( \mu,\sigma \right)}{\partial\mu^{2}} \right) = \mathrm{E}\left( \frac{- 6}{\sigma^{2}} \right) = \frac{- 6}{\sigma^{2}} ,
\]</span></p>
<p><span class="math display">\[
\mathrm{E}\left( \frac{\partial^{2}\text{log L}\left( \mu,\sigma \right)}{\partial\mu\partial\sigma} \right) = \frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}{\mathrm{E}\left( \log x_{i} - \mu \right)} = \frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}\left\lbrack \mathrm{E}\left( \log x_{i} \right) - \mu \right\rbrack = \frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}\left( \mu - \mu \right) = 0,
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\mathrm{E}\left( \frac{\partial^{2}\text{log L}\left( \mu,\sigma \right)}{\partial\sigma^{2}} \right) = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}{\mathrm{E}\left( \log x_{i} - \mu \right)}^{2} = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}{\mathrm{Var}\left( \log x_{i} \right) = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}{\sigma^{2} = \frac{- 12}{\sigma^{2}}}} .
\]</span></p>
<p>Using the negatives of these expectations we obtain the Fisher information matrix</p>
<p><span class="math display">\[
\begin{bmatrix}
\frac{6}{\sigma^{2}} &amp; 0 \\
0 &amp; \frac{12}{\sigma^{2}} \\
\end{bmatrix}.
\]</span></p>
<p>The covariance matrix, <span class="math inline">\(\Sigma\)</span>, is the inverse of the Fisher information matrix</p>
<p><span class="math display">\[
\Sigma = \begin{bmatrix}
\frac{\sigma^{2}}{6} &amp; 0 \\
0 &amp; \frac{\sigma^{2}}{12} \\
\end{bmatrix}.
\]</span></p>
<p>The estimated matrix is given by</p>
<p><span class="math display">\[
\hat{\Sigma} = \begin{bmatrix}
0.8533 &amp; 0 \\
0 &amp; 0.4267 \\
\end{bmatrix}.
\]</span></p>
<p><strong>b.</strong> The 95% confidence interval for <span class="math inline">\(\mu\)</span> is given by <span class="math inline">\(9.38 \pm 1.96\sqrt{0.8533} = \left( 7.57,\ 11.19 \right)\)</span>.</p>
<p>The 95% confidence interval for <span class="math inline">\(\sigma^{2}\)</span> is given by <span class="math inline">\(5.12 \pm 1.96\sqrt{0.4267} = \left( 3.84,\ 6.40 \right)\)</span>.</p>
<p><strong>c.</strong> The mean of <em>X</em> is <span class="math inline">\(\exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span>. Then, the maximum likelihood estimate of</p>
<p><span class="math display">\[
g\left( \mu,\sigma \right) = \exp\left( \mu + \frac{\sigma^{2}}{2} \right)
\]</span></p>
<p>is</p>
<p><span class="math display">\[
g\left( \hat{\mu},\hat{\sigma} \right) = \exp\left( \hat{\mu} + \frac{{\hat{\sigma}}^{2}}{2} \right) = 153,277.
\]</span></p>
<p>We use the delta method to approximate the variance of the mle <span class="math inline">\(g\left( \hat{\mu},\hat{\sigma} \right)\)</span>.</p>
<p><span class="math inline">\(\frac{\partial g\left( \mu,\sigma \right)}{\partial\mu} = \exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span>
and
<span class="math inline">\(\frac{\partial g\left( \mu,\sigma \right)}{\partial\sigma} = \sigma \exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span>.</p>
<p>Using the delta method, the approximate variance of
<span class="math inline">\(g\left( \hat{\mu},\hat{\sigma} \right)\)</span> is given by</p>
<p><span class="math display">\[
\left. \ \widehat{Var}\left( g\left( \hat{\mu},\hat{\sigma} \right) \right) = \begin{bmatrix}
\frac{\partial g\left( \mu,\sigma \right)}{\partial\mu} &amp; \frac{\partial g\left( \mu,\sigma \right)}{\partial\sigma} \\
\end{bmatrix}\Sigma\begin{bmatrix}
\frac{\partial g\left( \mu,\sigma \right)}{\partial\mu} \\
\frac{\partial g\left( \mu,\sigma \right)}{\partial\sigma} \\
\end{bmatrix} \right|_{\mu = \hat{\mu},\sigma = \hat{\sigma}} \\
= \begin{bmatrix}
153,277 &amp; 346,826 \\
\end{bmatrix}\begin{bmatrix}
0.8533 &amp; 0 \\
0 &amp; 0.4267 \\
\end{bmatrix}\begin{bmatrix}
153,277 \\
346,826 \\
\end{bmatrix} \\
= 71,374,380,000 .
\]</span></p>
<p>The 95% confidence interval for <span class="math inline">\(\exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span> is given by</p>
<p><span class="math display">\[
153277 \pm 1.96\sqrt{71,374,380,000} = \left( - 370356,\ 676910 \right).
\]</span></p>
<p>Since the mean of the lognormal distribution cannot be negative, we should replace the negative lower limit in the previous interval by a zero.</p>
</div>
<hr />
<p><strong>Example 4.5.4. Wisconsin Property Fund.</strong> To see how maximum likelihood estimators work with real data, we return to the 2010 claims data introduced in Section <a href="ChapIntro.html#S:LGPIF">1.3</a>.</p>
<p>The following snippet of code shows how to fit the exponential, gamma, Pareto, lognormal, and <span class="math inline">\(GB2\)</span> models. For consistency, the code employs the <code>R</code> package <code>VGAM</code>. The acronym stands for <em>Vector Generalized Linear and Additive Models</em>; as suggested by the name, this package can do far more than fit these models although it suffices for our purposes. The one exception is the <span class="math inline">\(GB2\)</span> density which is not widely used outside of insurance applications; however, we can code this density and compute maximum likelihood estimators using the <code>optim</code> general purpose optimizer.</p>
<h5 style="text-align: center;">
<a id="displayExample.4.5.4" href="javascript:toggleEX('toggleExample.4.5.4','displayExample.4.5.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.4.5.4" style="display: none">
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="ChapSeverity.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(VGAM)</span>
<span id="cb43-2"><a href="ChapSeverity.html#cb43-2" aria-hidden="true" tabindex="-1"></a>claim_lev <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;Data/CLAIMLEVEL.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>) </span>
<span id="cb43-3"><a href="ChapSeverity.html#cb43-3" aria-hidden="true" tabindex="-1"></a>claim_data <span class="ot">&lt;-</span> <span class="fu">subset</span>(claim_lev, Year <span class="sc">==</span> <span class="dv">2010</span>); </span>
<span id="cb43-4"><a href="ChapSeverity.html#cb43-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-5"><a href="ChapSeverity.html#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference assuming a GB2 Distribution - this is more complicated</span></span>
<span id="cb43-6"><a href="ChapSeverity.html#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="co"># The likelihood function of GB2 distribution (negative for optimization)</span></span>
<span id="cb43-7"><a href="ChapSeverity.html#cb43-7" aria-hidden="true" tabindex="-1"></a>lik_gb2 <span class="ot">&lt;-</span> <span class="cf">function</span> (param) {</span>
<span id="cb43-8"><a href="ChapSeverity.html#cb43-8" aria-hidden="true" tabindex="-1"></a>  a_1 <span class="ot">&lt;-</span> param[<span class="dv">1</span>]</span>
<span id="cb43-9"><a href="ChapSeverity.html#cb43-9" aria-hidden="true" tabindex="-1"></a>  a_2 <span class="ot">&lt;-</span> param[<span class="dv">2</span>]</span>
<span id="cb43-10"><a href="ChapSeverity.html#cb43-10" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> param[<span class="dv">3</span>]</span>
<span id="cb43-11"><a href="ChapSeverity.html#cb43-11" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">&lt;-</span> param[<span class="dv">4</span>]</span>
<span id="cb43-12"><a href="ChapSeverity.html#cb43-12" aria-hidden="true" tabindex="-1"></a>  yt <span class="ot">&lt;-</span> (<span class="fu">log</span>(claim_data<span class="sc">$</span>Claim) <span class="sc">-</span> mu) <span class="sc">/</span> sigma</span>
<span id="cb43-13"><a href="ChapSeverity.html#cb43-13" aria-hidden="true" tabindex="-1"></a>  logexpyt <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(yt <span class="sc">&gt;</span> <span class="dv">23</span>, yt, <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(yt)))</span>
<span id="cb43-14"><a href="ChapSeverity.html#cb43-14" aria-hidden="true" tabindex="-1"></a>  logdens <span class="ot">&lt;-</span> a_1 <span class="sc">*</span> yt <span class="sc">-</span> <span class="fu">log</span>(sigma) <span class="sc">-</span> <span class="fu">log</span>(<span class="fu">beta</span>(a_1,a_2)) <span class="sc">-</span> </span>
<span id="cb43-15"><a href="ChapSeverity.html#cb43-15" aria-hidden="true" tabindex="-1"></a>    (a_1<span class="sc">+</span>a_2) <span class="sc">*</span> logexpyt <span class="sc">-</span> <span class="fu">log</span>(claim_data<span class="sc">$</span>Claim) </span>
<span id="cb43-16"><a href="ChapSeverity.html#cb43-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="sc">-</span><span class="fu">sum</span>(logdens))</span>
<span id="cb43-17"><a href="ChapSeverity.html#cb43-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb43-18"><a href="ChapSeverity.html#cb43-18" aria-hidden="true" tabindex="-1"></a><span class="co"># &quot;optim&quot; is a general purpose minimization function</span></span>
<span id="cb43-19"><a href="ChapSeverity.html#cb43-19" aria-hidden="true" tabindex="-1"></a>gb2_bop <span class="ot">&lt;-</span> <span class="fu">optim</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>), lik_gb2, <span class="at">method =</span> <span class="fu">c</span>(<span class="st">&quot;L-BFGS-B&quot;</span>), </span>
<span id="cb43-20"><a href="ChapSeverity.html#cb43-20" aria-hidden="true" tabindex="-1"></a>                 <span class="at">lower =</span> <span class="fu">c</span>(<span class="fl">0.01</span>, <span class="fl">0.01</span>, <span class="sc">-</span><span class="dv">500</span>, <span class="fl">0.01</span>), </span>
<span id="cb43-21"><a href="ChapSeverity.html#cb43-21" aria-hidden="true" tabindex="-1"></a>                 <span class="at">upper =</span> <span class="fu">c</span>(<span class="dv">500</span>, <span class="dv">500</span>, <span class="dv">500</span>, <span class="dv">500</span>), <span class="at">hessian =</span> <span class="cn">TRUE</span>)</span>
<span id="cb43-22"><a href="ChapSeverity.html#cb43-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Nonparametric Plot</span></span>
<span id="cb43-23"><a href="ChapSeverity.html#cb43-23" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(<span class="fu">log</span>(claim_data<span class="sc">$</span>Claim)), <span class="at">main =</span> <span class="st">&quot;&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Log Expenditures&quot;</span>,</span>
<span id="cb43-24"><a href="ChapSeverity.html#cb43-24" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span> ,<span class="fl">0.37</span>))</span>
<span id="cb43-25"><a href="ChapSeverity.html#cb43-25" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">15</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb43-26"><a href="ChapSeverity.html#cb43-26" aria-hidden="true" tabindex="-1"></a><span class="co">#Exponential</span></span>
<span id="cb43-27"><a href="ChapSeverity.html#cb43-27" aria-hidden="true" tabindex="-1"></a>fit.exp <span class="ot">&lt;-</span> <span class="fu">vglm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, exponential, <span class="at">data =</span> claim_data)</span>
<span id="cb43-28"><a href="ChapSeverity.html#cb43-28" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">=</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.exp))</span>
<span id="cb43-29"><a href="ChapSeverity.html#cb43-29" aria-hidden="true" tabindex="-1"></a>fexp_ex <span class="ot">&lt;-</span> <span class="fu">dgamma</span>(<span class="fu">exp</span>(x), <span class="at">scale =</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fu">coef</span>(fit.exp)), <span class="at">shape =</span> <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">exp</span>(x)</span>
<span id="cb43-30"><a href="ChapSeverity.html#cb43-30" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, fexp_ex, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">lty =</span><span class="dv">2</span>)</span>
<span id="cb43-31"><a href="ChapSeverity.html#cb43-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference assuming a gamma distribution</span></span>
<span id="cb43-32"><a href="ChapSeverity.html#cb43-32" aria-hidden="true" tabindex="-1"></a>fit.gamma <span class="ot">&lt;-</span> <span class="fu">vglm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> gamma2, <span class="at">data =</span> claim_data)</span>
<span id="cb43-33"><a href="ChapSeverity.html#cb43-33" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.gamma)[<span class="dv">1</span>]) <span class="sc">/</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.gamma)[<span class="dv">2</span>])  <span class="co"># theta = mu / alpha</span></span>
<span id="cb43-34"><a href="ChapSeverity.html#cb43-34" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.gamma)[<span class="dv">2</span>]) </span>
<span id="cb43-35"><a href="ChapSeverity.html#cb43-35" aria-hidden="true" tabindex="-1"></a>fgamma_ex <span class="ot">&lt;-</span> <span class="fu">dgamma</span>(<span class="fu">exp</span>(x), <span class="at">shape =</span> alpha, <span class="at">scale =</span> theta) <span class="sc">*</span> <span class="fu">exp</span>(x)</span>
<span id="cb43-36"><a href="ChapSeverity.html#cb43-36" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, fgamma_ex, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">lty =</span><span class="dv">3</span>)</span>
<span id="cb43-37"><a href="ChapSeverity.html#cb43-37" aria-hidden="true" tabindex="-1"></a><span class="co">#Pareto</span></span>
<span id="cb43-38"><a href="ChapSeverity.html#cb43-38" aria-hidden="true" tabindex="-1"></a>fit.pareto <span class="ot">&lt;-</span> <span class="fu">vglm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, paretoII, <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">data =</span> claim_data)</span>
<span id="cb43-39"><a href="ChapSeverity.html#cb43-39" aria-hidden="true" tabindex="-1"></a>fpareto_ex <span class="ot">&lt;-</span> <span class="fu">dparetoII</span>(<span class="fu">exp</span>(x), <span class="at">loc =</span> <span class="dv">0</span>, <span class="at">shape =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">2</span>]), </span>
<span id="cb43-40"><a href="ChapSeverity.html#cb43-40" aria-hidden="true" tabindex="-1"></a>                        <span class="at">scale =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.pareto)[<span class="dv">1</span>])) <span class="sc">*</span> <span class="fu">exp</span>(x)</span>
<span id="cb43-41"><a href="ChapSeverity.html#cb43-41" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, fpareto_ex, <span class="at">col =</span> <span class="st">&quot;purple&quot;</span>)</span>
<span id="cb43-42"><a href="ChapSeverity.html#cb43-42" aria-hidden="true" tabindex="-1"></a><span class="co"># Lognormal</span></span>
<span id="cb43-43"><a href="ChapSeverity.html#cb43-43" aria-hidden="true" tabindex="-1"></a>fit.LN <span class="ot">&lt;-</span> <span class="fu">vglm</span>(Claim <span class="sc">~</span> <span class="dv">1</span>, <span class="at">family =</span> lognormal, <span class="at">data =</span> claim_data)</span>
<span id="cb43-44"><a href="ChapSeverity.html#cb43-44" aria-hidden="true" tabindex="-1"></a>flnorm_ex <span class="ot">&lt;-</span> <span class="fu">dlnorm</span>(<span class="fu">exp</span>(x), <span class="at">mean =</span> <span class="fu">coef</span>(fit.LN)[<span class="dv">1</span>],</span>
<span id="cb43-45"><a href="ChapSeverity.html#cb43-45" aria-hidden="true" tabindex="-1"></a>                    <span class="at">sd =</span> <span class="fu">exp</span>(<span class="fu">coef</span>(fit.LN)[<span class="dv">2</span>])) <span class="sc">*</span> <span class="fu">exp</span>(x)</span>
<span id="cb43-46"><a href="ChapSeverity.html#cb43-46" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, flnorm_ex, <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>)</span>
<span id="cb43-47"><a href="ChapSeverity.html#cb43-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Density for GB II</span></span>
<span id="cb43-48"><a href="ChapSeverity.html#cb43-48" aria-hidden="true" tabindex="-1"></a>gb2_density <span class="ot">&lt;-</span> <span class="cf">function</span> (x) {</span>
<span id="cb43-49"><a href="ChapSeverity.html#cb43-49" aria-hidden="true" tabindex="-1"></a>  a_1 <span class="ot">&lt;-</span> gb2_bop<span class="sc">$</span>par[<span class="dv">1</span>]</span>
<span id="cb43-50"><a href="ChapSeverity.html#cb43-50" aria-hidden="true" tabindex="-1"></a>  a_2 <span class="ot">&lt;-</span> gb2_bop<span class="sc">$</span>par[<span class="dv">2</span>]</span>
<span id="cb43-51"><a href="ChapSeverity.html#cb43-51" aria-hidden="true" tabindex="-1"></a>  mu <span class="ot">&lt;-</span> gb2_bop<span class="sc">$</span>par[<span class="dv">3</span>]</span>
<span id="cb43-52"><a href="ChapSeverity.html#cb43-52" aria-hidden="true" tabindex="-1"></a>  sigma <span class="ot">&lt;-</span> gb2_bop<span class="sc">$</span>par[<span class="dv">4</span>]</span>
<span id="cb43-53"><a href="ChapSeverity.html#cb43-53" aria-hidden="true" tabindex="-1"></a>  xt <span class="ot">&lt;-</span> (<span class="fu">log</span>(x) <span class="sc">-</span> mu) <span class="sc">/</span> sigma</span>
<span id="cb43-54"><a href="ChapSeverity.html#cb43-54" aria-hidden="true" tabindex="-1"></a>  logexpxt <span class="ot">&lt;-</span> <span class="fu">ifelse</span> (xt <span class="sc">&gt;</span> <span class="dv">23</span>, yt, <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(xt)))</span>
<span id="cb43-55"><a href="ChapSeverity.html#cb43-55" aria-hidden="true" tabindex="-1"></a>  logdens <span class="ot">&lt;-</span> a_1 <span class="sc">*</span> xt <span class="sc">-</span> <span class="fu">log</span>(sigma) <span class="sc">-</span> <span class="fu">log</span>(<span class="fu">beta</span>(a_1, a_2)) <span class="sc">-</span> </span>
<span id="cb43-56"><a href="ChapSeverity.html#cb43-56" aria-hidden="true" tabindex="-1"></a>    (a_1<span class="sc">+</span>a_2) <span class="sc">*</span> logexpxt <span class="sc">-</span><span class="fu">log</span>(x) </span>
<span id="cb43-57"><a href="ChapSeverity.html#cb43-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(logdens)</span>
<span id="cb43-58"><a href="ChapSeverity.html#cb43-58" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb43-59"><a href="ChapSeverity.html#cb43-59" aria-hidden="true" tabindex="-1"></a>fGB2_ex <span class="ot">=</span> <span class="fu">gb2_density</span>(<span class="fu">exp</span>(x)) <span class="sc">*</span> <span class="fu">exp</span>(x)</span>
<span id="cb43-60"><a href="ChapSeverity.html#cb43-60" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, fGB2_ex, <span class="at">col=</span><span class="st">&quot;green&quot;</span>)</span>
<span id="cb43-61"><a href="ChapSeverity.html#cb43-61" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="fu">c</span>(<span class="st">&quot;log(Expend)&quot;</span>, <span class="st">&quot;Exponential&quot;</span>, <span class="st">&quot;Gamma&quot;</span>, <span class="st">&quot;Pareto&quot;</span>, </span>
<span id="cb43-62"><a href="ChapSeverity.html#cb43-62" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&quot;Lognormal&quot;</span>, <span class="st">&quot;GB2&quot;</span>), <span class="at">cex=</span><span class="fl">0.8</span>,</span>
<span id="cb43-63"><a href="ChapSeverity.html#cb43-63" aria-hidden="true" tabindex="-1"></a>       <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="co">#4 is &quot;longdash&quot;</span></span>
<span id="cb43-64"><a href="ChapSeverity.html#cb43-64" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>,<span class="st">&quot;blue&quot;</span>,<span class="st">&quot;purple&quot;</span>,<span class="st">&quot;lightblue&quot;</span>,<span class="st">&quot;green&quot;</span>))</span></code></pre></div>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:MLEComparea"></span>
<img src="LossDataAnalytics_files/figure-html/MLEComparea-1.png" alt="Density Comparisons for the Wisconsin Property Fund" width="672" />
<p class="caption">
Figure 4.9: <strong>Density Comparisons for the Wisconsin Property Fund</strong>
</p>
</div>
<p>Results from the fitting exercise are summarized in Figure <a href="ChapSeverity.html#fig:MLEComparea">4.9</a>. Here, the black longdash curve is a smoothed histogram of the actual data (that we will introduce in Section <a href="#S:MS:NonParInf"><strong>??</strong></a>); the other curves are parametric curves where the parameters are computed via maximum likelihood. We see poor fits in the red dashed line from the exponential distribution fit and the blue dotted line from the gamma distribution fit. Fits of the other curves, Pareto, lognormal, and GB2, all seem to provide reasonably good fits to the actual data. Chapter <a href="ChapModelSelection.html#ChapModelSelection">6</a> describes in more detail the principles of model selection.</p>
<hr />
<div id="starting-values" class="section level4 hasAnchor" number="4.4.3.1">
<h4><span class="header-section-number">4.4.3.1</span> Starting Values<a href="ChapSeverity.html#starting-values" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The method of moments and percentile matching are nonparametric estimation methods that provide alternatives to maximum likelihood. Generally, maximum likelihood is the preferred technique because it employs data more efficiently. (See Appendix Chapter <a href="CAppC.html#CAppC">19</a> for precise definitions of efficiency.) However, methods of moments and percentile matching are useful because they are easier to interpret and therefore allow the actuary or analyst to explain procedures to others. Additionally, the numerical estimation procedure (e.g.if performed in <code>R</code>) for the maximum likelihood is iterative and requires starting values to begin the recursive process. Although many problems are robust to the choice of the starting values, for some complex situations, it can be important to have a starting value that is close to the (unknown) optimal value. Method of moments and percentile matching are techniques that can produce desirable estimates without a serious computational investment and can thus be used as a <em>starting value</em> for computing maximum likelihood.</p>
</div>
<div id="method-of-moments" class="section level4 hasAnchor" number="4.4.3.2">
<h4><span class="header-section-number">4.4.3.2</span> Method of Moments<a href="ChapSeverity.html#method-of-moments" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Under the <a href="#" class="tooltip" style="color:green"><em>method of moments</em><span style="font-size:8pt">The estimation of population parameters by approximating parametric moments using empirical sample moments.</span></a>, we approximate the moments of the parametric distribution using the empirical (nonparametric) moments described in Section <a href="#S:MS:MomentEstimator"><strong>??</strong></a>. We can then algebraically solve for the parameter estimates.</p>
<hr />
<p><strong>Example 5.1.9. Property Fund.</strong>
For the 2010 property fund, there are <span class="math inline">\(n=1,377\)</span> individual claims (in thousands of dollars) with</p>
<p><span class="math display">\[m_1 = \frac{1}{n} \sum_{i=1}^n X_i = 26.62259 \ \ \ \
\text{and} \ \ \ \
m_2 = \frac{1}{n} \sum_{i=1}^n X_i^2 = 136154.6 .\]</span>
Fit the parameters of the gamma and Pareto distributions using the method of moments.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.9" href="javascript:toggleEX('toggleExample.5.1.9','displayExample.5.1.9');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.9" style="display: none">
<p><strong>Solution.</strong>
To fit a gamma distribution, we have <span class="math inline">\(\mu_1 = \alpha \theta\)</span> and <span class="math inline">\(\mu_2^{\prime} = \alpha(\alpha+1) \theta^2\)</span>. Equating the two yields the method of moments estimators, easy algebra shows that</p>
<p><span class="math display">\[\alpha = \frac{\mu_1^2}{\mu_2^{\prime}-\mu_1^2}  \ \ \ \text{and} \ \ \  \theta = \frac{\mu_2^{\prime}-\mu_1^2}{\mu_1}.\]</span></p>
<p>Thus, the method of moment estimators are</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\alpha} &amp;=  \frac{26.62259^2}{136154.6-26.62259^2} = 0.005232809 \\
\hat{\theta} &amp;=  \frac{136154.6-26.62259^2}{26.62259} = 5,087.629.
\end{aligned}
\]</span></p>
<p>For comparison, the maximum likelihood values turn out to be <span class="math inline">\(\hat{\alpha}_{MLE} = 0.2905959\)</span> and <span class="math inline">\(\hat{\theta}_{MLE} = 91.61378\)</span>, so there are big discrepancies between the two estimation procedures. This is one indication, as we have seen before, that the gamma model fits poorly.</p>
<p>In contrast, now assume a Pareto distribution so that <span class="math inline">\(\mu_1 = \theta/(\alpha -1)\)</span> and <span class="math inline">\(\mu_2^{\prime} = 2\theta^2/((\alpha-1)(\alpha-2) )\)</span>. Note that this expression for <span class="math inline">\(\mu_2^{\prime}\)</span> is only valid for <span class="math inline">\(\alpha&gt;2\)</span>. Easy algebra shows</p>
<p><span class="math display">\[\alpha = 1+ \frac{\mu_2^{\prime}}{\mu_2^{\prime}-\mu_1^2} \ \ \ \
\text{and} \ \ \ \ \
\theta = (\alpha-1)\mu_1.\]</span></p>
<p>Thus, the method of moment estimators are</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\alpha} &amp;=  1+ \frac{136154.6}{136154.6-26,62259^2} = 2.005233 \\
\hat{\theta} &amp;=  (2.005233-1) \cdot 26.62259 = 26.7619
\end{aligned}
\]</span></p>
<p>The maximum likelihood values turn out to be <span class="math inline">\(\hat{\alpha}_{MLE} = 0.9990936\)</span> and <span class="math inline">\(\hat{\theta}_{MLE} = 2.2821147\)</span>. It is interesting that <span class="math inline">\(\hat{\alpha}_{MLE}&lt;1\)</span>; for the Pareto distribution, recall that <span class="math inline">\(\alpha &lt;1\)</span> means that the mean is infinite. This is another indication that the property claims data set is a long tail distribution.</p>
</div>
<hr />
<p>As the above example suggests, there is flexibility with the method of moments. For example, we could have matched the second and third moments instead of the first and second, yielding different estimators. Furthermore, there is no guarantee that a solution will exist for each problem. For data that are censored or truncated, matching moments is possible for a few problems but, in general, this is a more difficult scenario. Finally, for distributions where the moments do not exist or are infinite, method of moments is not available. As an alternative, one can use the percentile matching technique.</p>
</div>
<div id="percentile-matching" class="section level4 hasAnchor" number="4.4.3.3">
<h4><span class="header-section-number">4.4.3.3</span> Percentile Matching<a href="ChapSeverity.html#percentile-matching" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Under <a href="#" class="tooltip" style="color:green"><em>percentile matching</em><span style="font-size:8pt">The estimation of population parameters by approximating parametric percentiles using empirical quantiles.</span></a>, we approximate the quantiles or percentiles of the parametric distribution using the empirical (nonparametric) quantiles or percentiles described in Section <a href="ChapSeverity.html#S:MS:QuantileEstimator">4.1.2.1</a>.</p>
<hr />
<p><strong>Example 5.1.10. Property Fund.</strong>
For the 2010 property fund, we illustrate matching on quantiles. In particular, the Pareto distribution is intuitively pleasing because of the closed-form solution for the quantiles. Recall that the distribution function for the Pareto distribution is
<span class="math display">\[F(x) = 1 - \left(\frac{\theta}{x+\theta}\right)^{\alpha}.\]</span>
Easy algebra shows that we can express the quantile as</p>
<p><span class="math display">\[F^{-1}(q) = \theta \left( (1-q)^{-1/\alpha} -1 \right).\]</span>
for a fraction <span class="math inline">\(q\)</span>, <span class="math inline">\(0&lt;q&lt;1\)</span>.</p>
<p>Determine estimates of the Pareto distribution parameters using the 25th and 95th empirical quantiles.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.10" href="javascript:toggleEX('toggleExample.5.1.10','displayExample.5.1.10');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.10" style="display: none">
<p><strong>Solution.</strong></p>
<p>The 25th percentile (the first quartile) turns out to be <span class="math inline">\(0.78853\)</span> and the 95th percentile is <span class="math inline">\(50.98293\)</span> (both in thousands of dollars). With two equations
<span class="math display">\[0.78853 = \theta \left( 1- (1-.25)^{-1/\alpha} \right) \ \ \ \ \text{and} \ \ \ \ 50.98293 = \theta \left( 1- (1-.75)^{-1/\alpha} \right)\]</span>
and two unknowns, the solution is
<span class="math display">\[\hat{\alpha} = 0.9412076 \ \ \ \ \ \text{and} \ \ \ \
\hat{\theta} = 2.205617 .\]</span>
We remark here that a numerical routine is required for these solutions as no analytic solution is available. Furthermore, recall that the <a href="#" class="tooltip" style="color:green"><em>maximum likelihood estimates</em><span style="font-size:8pt"></span></a> are <span class="math inline">\(\hat{\alpha}_{MLE} = 0.9990936\)</span> and <span class="math inline">\(\hat{\theta}_{MLE} = 2.2821147\)</span>, so the percentile matching provides a better approximation for the Pareto distribution than the method of moments.</p>
</div>
<hr />
<p><strong>Example 5.1.11. Actuarial Exam Question.</strong>
You are given:</p>
<ol style="list-style-type: lower-roman">
<li>Losses follow a loglogistic distribution with cumulative distribution function:
<span class="math display">\[F(x) = \frac{\left(x/\theta\right)^{\gamma}}{1+\left(x/\theta\right)^{\gamma}}\]</span></li>
<li>The sample of losses is:</li>
</ol>
<p><span class="math display">\[
\begin{array}{ccccccccccc}
10 &amp;35 &amp;80 &amp;86 &amp;90 &amp;120 &amp;158 &amp;180 &amp;200 &amp;210 &amp;1500 \\
\end{array}
\]</span></p>
<p>Calculate the estimate of <span class="math inline">\(\theta\)</span> by percentile matching, using the 40th and 80th empirically smoothed percentile estimates.</p>
<h5 style="text-align: center;">
<a id="displayExample.5.1.11" href="javascript:toggleEX('toggleExample.5.1.11','displayExample.5.1.11');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.5.1.11" style="display: none">
<p><strong>Solution.</strong>
With 11 observations, we have <span class="math inline">\(j=\lfloor(n+1)q\rfloor = \lfloor 12(0.4) \rfloor = \lfloor 4.8\rfloor=4\)</span> and <span class="math inline">\(h=(n+1)q-j = 12(0.4)-4=0.8\)</span>. By interpolation, the 40th empirically smoothed percentile estimate is <span class="math inline">\(\hat{\pi}_{0.4} = (1-h) X_{(j)} + h X_{(j+1)} = 0.2(86)+0.8(90)=89.2\)</span>.</p>
<p>Similarly, for the 80th empirically smoothed percentile estimate, we have <span class="math inline">\(12(0.8)=9.6\)</span> so the estimate is <span class="math inline">\(\hat{\pi}_{0.8} = 0.4(200)+0.6(210)=206\)</span>.</p>
<p>Using the loglogistic cumulative distribution, we need to solve the following two equations for parameters <span class="math inline">\({\hat{\theta}}\)</span> and <span class="math inline">\({\hat{\gamma}}\)</span>:
<span class="math display">\[
0.4=\frac{(89.2/{\hat{\theta}})^{\hat{\gamma}}}{1+(89.2/{\hat{\theta}})^{\hat{\gamma}}} \ \ \ \text{and} \ \ \ \   0.8=\frac{(206/{\hat{\theta}})^{\hat{\gamma}}}{1+(206/{\hat{\theta}})^{\hat{\gamma}}} .
\]</span></p>
<p>Solving for each parenthetical expression gives <span class="math inline">\(\frac{2}{3}=(89.2/\theta)^{\hat{\gamma}}\)</span> and <span class="math inline">\(4=(206/{\hat{\theta}})^{\hat{\gamma}}\)</span>. Taking the ratio of the second equation to the first gives <span class="math inline">\(6=(206/89.2)^{\hat{\gamma}}\Rightarrow {\hat{\gamma}}=\frac{\log(6)}{\log(206/89.2)} = 2.1407\)</span>. Then <span class="math inline">\(4^{1/2.1407}=206/{\hat{\theta}} \Rightarrow {\hat{\theta}}=107.8\)</span>.</p>
</div>
<hr />
<p>Like the method of moments, percentile matching is almost too flexible in the sense that estimators can vary depending on different percentiles chosen. For example, one actuary may use estimation on the 25th and 95th percentiles whereas another uses the 20th and 80th percentiles. In general estimated parameters will differ and there is no compelling reason to prefer one over the other. Also as with the method of moments, percentile matching is appealing because it provides a technique that can be readily applied in selected situations and has an intuitive basis. Although most actuarial applications use maximum likelihood estimators, it can be convenient to have alternative approaches such as method of moments and percentile matching available.</p>
<div id="surveyElement41">

</div>
<div id="surveyResult41">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz41.1" href="javascript:toggleQuiz
('display.Quiz41.2','display.Quiz41.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz41.2" style="display: none">
<p id="Quiz41Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz41.js">
</script>
</div>
</div>
</div>
<div id="LM-further-reading-and-resources" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Further Resources and Contributors<a href="ChapSeverity.html#LM-further-reading-and-resources" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="contributors-3" class="section level4 unnumbered hasAnchor">
<h4>Contributors<a href="ChapSeverity.html#contributors-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Zeinab Amin</strong>, The American University in Cairo, is the principal author of this chapter. Email: <a href="mailto:zeinabha@aucegypt.edu" class="email">zeinabha@aucegypt.edu</a> for chapter comments and suggested improvements.</li>
<li>Many helpful comments have been provided by Hirokazu (Iwahiro) Iwasawa, <a href="mailto:iwahiro@bb.mbn.or.jp" class="email">iwahiro@bb.mbn.or.jp</a> .</li>
<li>Other chapter reviewers include: Rob Erhardt, Samuel Kolins, Tatjana Miljkovic, Michelle Xia, and Jorge Yslas.</li>
</ul>
</div>
<div id="exercises-1" class="section level4 unnumbered hasAnchor">
<h4>Exercises<a href="ChapSeverity.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Here are a set of exercises that guide the viewer through some of the theoretical foundations of <strong>Loss Data Analytics</strong>. Each tutorial is based on one or more questions from the professional actuarial examinations  typically the Society of Actuaries Exam C/STAM.</p>
<p style="text-align: center;">
<a href="http://www.ssc.wisc.edu/~jfrees/loss-data-analytics/chapter-3-modeling-loss-severity/loss-data-analytics-severity-problems/">Severity Distribution Guided Tutorials</a>
</p>
</div>
<div id="further-readings-and-references-1" class="section level4 unnumbered hasAnchor">
<h4>Further Readings and References<a href="ChapSeverity.html#further-readings-and-references-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Notable contributions include: <span class="citation">Cummins and Derrig (<a href="#ref-cummins1991managing" role="doc-biblioref">2012</a>)</span>, <span class="citation">Edward W. Frees and Valdez (<a href="#ref-frees2008hierarchical" role="doc-biblioref">2008</a>)</span>, <span class="citation">Klugman, Panjer, and Willmot (<a href="#ref-klugman2012" role="doc-biblioref">2012</a>)</span>, <span class="citation">Kreer et al. (<a href="#ref-kreer2015goodness" role="doc-biblioref">2015</a>)</span>, <span class="citation">McDonald (<a href="#ref-mcdonald1984some" role="doc-biblioref">1984</a>)</span>, <span class="citation">McDonald and Xu (<a href="#ref-mcdonald1995generalization" role="doc-biblioref">1995</a>)</span>, <span class="citation">Tevet (<a href="#ref-tevet2016applying" role="doc-biblioref">2016</a>)</span>, and <span class="citation">G. Venter (<a href="#ref-venter1983transformed" role="doc-biblioref">1983</a>)</span>.</p>

</div>
</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-cummins1991managing" class="csl-entry">
Cummins, J. David, and Richard A. Derrig. 2012. <em>Managing the Insolvency Risk of Insurance Companies: Proceedings of the Second International Conference on Insurance Solvency</em>. Vol. 12. Springer Science &amp; Business Media.
</div>
<div id="ref-frees2008hierarchical" class="csl-entry">
. 2008. <span>Hierarchical Insurance Claims Modeling.</span> <em>Journal of the American Statistical Association</em> 103 (484): 145769.
</div>
<div id="ref-klugman2012" class="csl-entry">
Klugman, Stuart A., Harry H. Panjer, and Gordon E. Willmot. 2012. <em>Loss Models: From Data to Decisions</em>. John Wiley &amp; Sons.
</div>
<div id="ref-kreer2015goodness" class="csl-entry">
Kreer, Markus, Aye Kzlers, Anthony W Thomas, and Alfredo D Egdio dos Reis. 2015. <span>Goodness-of-Fit Tests and Applications for Left-Truncated Weibull Distributions to Non-Life Insurance.</span> <em>European Actuarial Journal</em> 5 (1): 13963.
</div>
<div id="ref-mcdonald1984some" class="csl-entry">
McDonald, James B. 1984. <span>Some Generalized Functions for the Size Distribution of Income.</span> <em>Econometrica: Journal of the Econometric Society</em>, 64763.
</div>
<div id="ref-mcdonald1995generalization" class="csl-entry">
McDonald, James B, and Yexiao J Xu. 1995. <span>A Generalization of the Beta Distribution with Applications.</span> <em>Journal of Econometrics</em> 66 (1-2): 13352.
</div>
<div id="ref-tevet2016applying" class="csl-entry">
Tevet, Dan. 2016. <span>Applying Generalized Linear Models to Insurance Data.</span> <em>Predictive Modeling Applications in Actuarial Science: Volume 2, Case Studies in Insurance</em>, 39.
</div>
<div id="ref-venter1983transformed" class="csl-entry">
Venter, Gary. 1983. <span>Transformed Beta and Gamma Distributions and Aggregate Losses.</span> In <em>Proceedings of the Casualty Actuarial Society</em>, 70:289308. 133 &amp; 134.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ChapFrequency-Modeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ChapClaimSeverity.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["LossDataAnalytics.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
